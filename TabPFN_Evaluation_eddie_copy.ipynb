{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyOWE29WgcCO"
      },
      "source": [
        "# Intro\n",
        "This is a notebook for doing evaluations for TabPFN's\n",
        "\n",
        "You will need to run each of the following steps to initialize all the classes and functions but for the most part you can ignore these unless you want to dig in deeper.\n",
        "\n",
        "The important note is that after running **Setup** you **must** restart your colab environment (top left, Runtime, restart runtime OR `ctrl+M .`)\n",
        "\n",
        "The most relevant section for just running and experimenting is the **Experiment** section. You'll find any plots generated by using the _folder_ icon on the left and looking in `./plots`.\n",
        "\n",
        "If you aren't aware `ctrl + ]` will fold all cells while `ctrl + [` will expand them all. You can also find the table of contents on the left for an easier time navigating.\n",
        "\n",
        "**In order to get the fastest predictions you need to enable GPUs for the notebook:**\n",
        "* Navigate to Edit→Notebook Settings\n",
        "* select GPU from the Hardware Accelerator drop-down\n",
        "(https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=oM_8ELnJq_wd)\n",
        "\n",
        "**Note:**\n",
        "The markers on the legend for the plots seems to not render, this may be due to some matplotlib version. If required, please try the most up-to-date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KJBB86PXrXD"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjxVPUQxXmNY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "from eval_utils import Results\n",
        "from __future__ import annotations\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import openml\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "152\n",
            "153\n",
            "1240\n",
            "1352\n",
            "1353\n",
            "1355\n",
            "1356\n",
            "1359\n",
            "1361\n",
            "1362\n",
            "41000\n",
            "41671\n"
          ]
        }
      ],
      "source": [
        "def filer_df(df):\n",
        "    columns = df.columns\n",
        "    df = df.fillna(0)\n",
        "    too_easy_dids = []\n",
        "    for index, row in df.iterrows():\n",
        "        try:\n",
        "            dataset_id = int(row[\"dataset_id\"])\n",
        "        except:\n",
        "            continue\n",
        "        if dataset_id == 0:\n",
        "            continue\n",
        "        if bool(int(row[\"too_easy\"])) and int(row[\"Remove\"]) != 1 and int(row[\"Redundant\"]) != 1:\n",
        "            prefix_to_skip = [\"BNG\", \"RandomRBF\", \"GTSRB\", \"CovPokElec\", \"PCam\"]\n",
        "            if not (np.any([row[\"dataset_name\"].startswith(prefix) for prefix in\n",
        "                                    prefix_to_skip]) or \"mnist\" in row[\"dataset_name\"].lower() or \"image\" in row[\n",
        "                                \"dataset_name\"].lower() or \"cifar\" in row[\"dataset_name\"].lower() or row[\"dataset_id\"] == 1414):\n",
        "                too_easy_dids.append((dataset_id))\n",
        "    return too_easy_dids\n",
        "    # openml_list = openml.datasets.list_datasets([dataset_id])\n",
        "\n",
        "    # if openml_list[dataset_id][\"NumberOfClasses\"] != 0.0:\n",
        "    #     all_bool = []\n",
        "    #     for i in range(5, 18):\n",
        "    #         all_bool.append(bool(int(row[columns[i]])))\n",
        "    #     if any(all_bool):\n",
        "    #         continue\n",
        "    #     # print(type(int(row[\"score_hbgt\"] )))\n",
        "    #     if bool(int(row[\"too_easy\"])):\n",
        "    #         score_logistic = float(row[\"score_logistic\"].replace(',', '.') if isinstance(row[\"score_logistic\"], str) else row[\"score_logistic\"])\n",
        "    #         score_hbgt = float(row[\"score_hbgt\"].replace(',', '.') if isinstance(row[\"score_hbgt\"], str) else row[\"score_hbgt\"])\n",
        "    #         if score_logistic >= 1.05 * score_hbgt:\n",
        "    #             print(dataset_id) #, print(row[\"too_easy\"]))\n",
        "    # if row[\"too_easy\"]:\n",
        "\n",
        "df = pd.read_csv(\"Datasets tabular data benchmark - numerical_classif-2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "indices = [\"method\", \"seed\"]\n",
        "headers = [\"metric\", \"dataset\"]\n",
        "df = pd.read_csv(\"result.csv\", index_col=[0,1], header=[0,1])\n",
        "# new_df = df.groupby([\"method\"]).mean().T.reset_index()[df.groupby([\"method\"]).mean().T.reset_index()[\"metric\"] == \"acc\"]#  # .plot(\"scatter\", x=\"dataset\") #.groupby(\"metric\") #.groupby(\"dataset\") #.mean().T # [\"acc\"].reset_index() # .plot()\n",
        "# .plot(kind=\"scatter\", x=\"dataset\", y=\"acc\")\n",
        "# plt.save_fig(\"~/TabPFN/acc.png\")\n",
        "# import matplotlib.pyplot as plt\n",
        "# ax = df.groupby([\"method\"]).mean()[\"acc\"].T.plot()\n",
        "# plt.save_fig(\"~/TabPFN/acc.png\")\n",
        "# plt.save_figure(\"~/TabPFN/acc.png\")\n",
        "# plt.savefig(\"~/TabPFN/acc.png\")\n",
        "# plt.savefig(\"./TabPFN/acc.png\")\n",
        "# plt.savefig(\"./important/acc.png\")\n",
        "results = Results(df)\n",
        "\n",
        "datasets_logistic = [\"Hyperplane_10_1E-3\", \"Hyperplane_10_1E-4\", \"AirlinesCodrnaAdult\", \"BNG(anneal,1000,5)\", \"BNG(anneal,1000,10)\", \"BNG(anneal,5000,5)\", \"BNG(anneal,5000,10)\", \"BNG(anneal,10000,10)\", \"BNG(anneal.ORIG,1000,5)\", \"BNG(anneal.ORIG,1000,10)\", \"jungle_chess_2pcs_endgame_panther_elephant\", \"microaggregation2\"]\n",
        "datasets_selected = [dataset for dataset in results.datasets if dataset not in datasets_logistic]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_average_rank_table(results: Results):\n",
        "    datasets = results.datasets\n",
        "    metrics = sorted(results.metrics, reverse=True)\n",
        "    # print(results.methods)\n",
        "    df = results.df\n",
        "    results_rank = {}\n",
        "    results_score = {}\n",
        "    for metric in metrics:\n",
        "        if \"time\" in metric:\n",
        "            continue\n",
        "        metric_df = df[metric]\n",
        "        dataset_rank_dfs = []\n",
        "        dataset_mean_dfs = []\n",
        "        for dataset in datasets:\n",
        "            if dataset not in metric_df.columns:\n",
        "                continue\n",
        "            dataset_rank_df = metric_df[dataset].groupby('method').mean().rank(ascending=False)\n",
        "            dataset_rank_dfs.append(dataset_rank_df)\n",
        "            dataset_mean_dfs.append(metric_df[dataset])\n",
        "\n",
        "        results_rank[metric] = pd.concat(dataset_rank_dfs).groupby(\"method\").mean()\n",
        "        \n",
        "        results_score[metric] = pd.concat(dataset_mean_dfs).groupby(\"method\").mean()\n",
        "    score_df = pd.DataFrame(results_score).reset_index()\n",
        "    rank_df = pd.DataFrame(results_rank).reset_index()\n",
        "    final_table = rank_df.merge(score_df, on=\"method\", suffixes=[\" Mean Rank\", \" Mean Score\"]).T\n",
        "    final_table.columns = final_table.iloc[0]\n",
        "    final_table = final_table.iloc[1:]\n",
        "    return final_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_datasets_ranks = get_average_rank_table(results)\n",
        "too_easy_datasets_ranks = get_average_rank_table(results.at(dataset=datasets_logistic))\n",
        "selected_datasets_ranks = get_average_rank_table(results.at(dataset=datasets_selected))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pprint(df):\n",
        "    for column in df:\n",
        "        df[column] = df[column].astype('float').round(decimals=2)\n",
        "\n",
        "    print(df.to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Too easy (13 datasets from old csv) + grinzstjan et al\n",
            "|                          |   decision_tree |   hist_gradient_boosting |   logistic |   mlp |   rf |\n",
            "|:-------------------------|----------------:|-------------------------:|-----------:|------:|-----:|\n",
            "| roc Mean Rank            |            4.19 |                     1.81 |       4.11 |  3.04 | 1.85 |\n",
            "| ece Mean Rank            |            1.33 |                     4.3  |       3.26 |  2.52 | 3.59 |\n",
            "| cross_entropy Mean Rank  |            1.37 |                     4.48 |       2.37 |  3.19 | 3.59 |\n",
            "| brier_score Mean Rank    |            1.37 |                     4.48 |       2.63 |  2.44 | 4.07 |\n",
            "| acc Mean Rank            |            4.22 |                     1.56 |       3.43 |  3.76 | 2.04 |\n",
            "| roc Mean Score           |            0.69 |                     0.8  |       0.72 |  0.75 | 0.81 |\n",
            "| ece Mean Score           |            0.29 |                     0.04 |       0.07 |  0.14 | 0.04 |\n",
            "| cross_entropy Mean Score |           16.98 |                     0.68 |       0.81 |  2.65 | 0.72 |\n",
            "| brier_score Mean Score   |            0.57 |                     0.29 |       0.38 |  0.44 | 0.29 |\n",
            "| acc Mean Score           |            0.71 |                     0.8  |       0.73 |  0.72 | 0.8  |\n",
            "\n",
            "\n",
            "\n",
            "Too easy (13 datasets from old csv)\n",
            "|                          |   decision_tree |   hist_gradient_boosting |   logistic |   mlp |   rf |\n",
            "|:-------------------------|----------------:|-------------------------:|-----------:|------:|-----:|\n",
            "| roc Mean Rank            |            3.83 |                     2.5  |       4.25 |  2.5  | 1.92 |\n",
            "| ece Mean Rank            |            1.33 |                     4.08 |       3    |  2.25 | 4.33 |\n",
            "| cross_entropy Mean Rank  |            1.75 |                     4.08 |       2.08 |  4.08 | 3    |\n",
            "| brier_score Mean Rank    |            1.33 |                     4.17 |       3    |  2.58 | 3.92 |\n",
            "| acc Mean Rank            |            4.58 |                     1.79 |       2.5  |  3.58 | 2.54 |\n",
            "| roc Mean Score           |            0.6  |                     0.68 |       0.62 |  0.66 | 0.71 |\n",
            "| ece Mean Score           |            0.35 |                     0.06 |       0.1  |  0.18 | 0.05 |\n",
            "| cross_entropy Mean Score |            8.92 |                     1.07 |       1.15 |  2.78 | 1.12 |\n",
            "| brier_score Mean Score   |            0.7  |                     0.36 |       0.42 |  0.51 | 0.36 |\n",
            "| acc Mean Score           |            0.65 |                     0.76 |       0.73 |  0.69 | 0.76 |\n",
            "\n",
            "\n",
            "\n",
            "grinzstjan et al\n",
            "|                          |   decision_tree |   hist_gradient_boosting |   logistic |   mlp |   rf |\n",
            "|:-------------------------|----------------:|-------------------------:|-----------:|------:|-----:|\n",
            "| roc Mean Rank            |            4.47 |                     1.27 |       4    |  3.47 | 1.8  |\n",
            "| ece Mean Rank            |            1.33 |                     4.47 |       3.47 |  2.73 | 3    |\n",
            "| cross_entropy Mean Rank  |            1.07 |                     4.8  |       2.6  |  2.47 | 4.07 |\n",
            "| brier_score Mean Rank    |            1.4  |                     4.73 |       2.33 |  2.33 | 4.2  |\n",
            "| acc Mean Rank            |            3.93 |                     1.37 |       4.17 |  3.9  | 1.63 |\n",
            "| roc Mean Score           |            0.77 |                     0.9  |       0.8  |  0.82 | 0.9  |\n",
            "| ece Mean Score           |            0.23 |                     0.02 |       0.04 |  0.1  | 0.04 |\n",
            "| cross_entropy Mean Score |           23.43 |                     0.36 |       0.53 |  2.56 | 0.4  |\n",
            "| brier_score Mean Score   |            0.47 |                     0.23 |       0.35 |  0.38 | 0.24 |\n",
            "| acc Mean Score           |            0.77 |                     0.83 |       0.72 |  0.75 | 0.83 |\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nToo easy (13 datasets from old csv) + grinzstjan et al\")\n",
        "pprint(all_datasets_ranks)\n",
        "print(\"\\n\\n\\nToo easy (13 datasets from old csv)\")\n",
        "pprint(too_easy_datasets_ranks)\n",
        "print(\"\\n\\n\\ngrinzstjan et al\")\n",
        "pprint(selected_datasets_ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>method</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>hist_gradient_boosting</th>\n",
              "      <th>logistic</th>\n",
              "      <th>mlp</th>\n",
              "      <th>rf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>acc Mean Rank</th>\n",
              "      <td>3.933333</td>\n",
              "      <td>1.366667</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.633333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brier_score Mean Rank</th>\n",
              "      <td>1.4</td>\n",
              "      <td>4.733333</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cross_entropy Mean Rank</th>\n",
              "      <td>1.066667</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.466667</td>\n",
              "      <td>4.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ece Mean Rank</th>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.466667</td>\n",
              "      <td>3.466667</td>\n",
              "      <td>2.733333</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roc Mean Rank</th>\n",
              "      <td>4.466667</td>\n",
              "      <td>1.266667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.466667</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time Mean Rank</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.866667</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>1.866667</td>\n",
              "      <td>1.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acc Mean Score</th>\n",
              "      <td>0.765674</td>\n",
              "      <td>0.830999</td>\n",
              "      <td>0.724789</td>\n",
              "      <td>0.747256</td>\n",
              "      <td>0.82884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brier_score Mean Score</th>\n",
              "      <td>0.468644</td>\n",
              "      <td>0.232313</td>\n",
              "      <td>0.35002</td>\n",
              "      <td>0.37789</td>\n",
              "      <td>0.238986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cross_entropy Mean Score</th>\n",
              "      <td>23.427463</td>\n",
              "      <td>0.361268</td>\n",
              "      <td>0.531119</td>\n",
              "      <td>2.555888</td>\n",
              "      <td>0.400683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ece Mean Score</th>\n",
              "      <td>0.234318</td>\n",
              "      <td>0.022265</td>\n",
              "      <td>0.042985</td>\n",
              "      <td>0.104066</td>\n",
              "      <td>0.038526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roc Mean Score</th>\n",
              "      <td>0.765776</td>\n",
              "      <td>0.898772</td>\n",
              "      <td>0.804081</td>\n",
              "      <td>0.82117</td>\n",
              "      <td>0.89578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time Mean Score</th>\n",
              "      <td>0.360274</td>\n",
              "      <td>0.617343</td>\n",
              "      <td>1.006473</td>\n",
              "      <td>2.305166</td>\n",
              "      <td>1.330709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "method                   decision_tree hist_gradient_boosting  logistic  \\\n",
              "acc Mean Rank                 3.933333               1.366667  4.166667   \n",
              "brier_score Mean Rank              1.4               4.733333  2.333333   \n",
              "cross_entropy Mean Rank       1.066667                    4.8       2.6   \n",
              "ece Mean Rank                 1.333333               4.466667  3.466667   \n",
              "roc Mean Rank                 4.466667               1.266667       4.0   \n",
              "time Mean Rank                     5.0               3.866667  2.333333   \n",
              "acc Mean Score                0.765674               0.830999  0.724789   \n",
              "brier_score Mean Score        0.468644               0.232313   0.35002   \n",
              "cross_entropy Mean Score     23.427463               0.361268  0.531119   \n",
              "ece Mean Score                0.234318               0.022265  0.042985   \n",
              "roc Mean Score                0.765776               0.898772  0.804081   \n",
              "time Mean Score               0.360274               0.617343  1.006473   \n",
              "\n",
              "method                         mlp        rf  \n",
              "acc Mean Rank                  3.9  1.633333  \n",
              "brier_score Mean Rank     2.333333       4.2  \n",
              "cross_entropy Mean Rank   2.466667  4.066667  \n",
              "ece Mean Rank             2.733333       3.0  \n",
              "roc Mean Rank             3.466667       1.8  \n",
              "time Mean Rank            1.866667  1.933333  \n",
              "acc Mean Score            0.747256   0.82884  \n",
              "brier_score Mean Score     0.37789  0.238986  \n",
              "cross_entropy Mean Score  2.555888  0.400683  \n",
              "ece Mean Score            0.104066  0.038526  \n",
              "roc Mean Score             0.82117   0.89578  \n",
              "time Mean Score           2.305166  1.330709  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_datasets_ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "headers = [\"metric\", \"dataset\"]\n",
        "indices = [\n",
        "    \"method\",\n",
        "    \"optimization_metric\",\n",
        "    \"optimization_time\",\n",
        "    \"eval_position\",\n",
        "    \"split\",\n",
        "]\n",
        "\n",
        "if Path(\"predefined_results.csv\").exists():\n",
        "    df = pd.read_csv(\n",
        "        \"predefined_results.csv\",\n",
        "        index_col=list(range(len(indices))),\n",
        "        header=list(range(len(headers))),\n",
        "    )\n",
        "    result = Results(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = [dataset.name for dataset in test_datasets]\n",
        "all_datasets_ranks = get_average_rank_table(results=result.at(method=['xgb', 'xgb_default', 'logistic'], dataset=datasets))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|                          |   logistic |   xgb |   xgb_default |\n",
            "|:-------------------------|-----------:|------:|--------------:|\n",
            "| roc Mean Rank            |       2.03 |  1.5  |          2.47 |\n",
            "| ece Mean Rank            |       2.2  |  2.43 |          1.37 |\n",
            "| cross_entropy Mean Rank  |       2.13 |  2.17 |          1.7  |\n",
            "| brier_score Mean Rank    |       2.23 |  2.4  |          1.37 |\n",
            "| acc Mean Rank            |       1.87 |  1.67 |          2.47 |\n",
            "| roc Mean Score           |       0.88 |  0.89 |          0.87 |\n",
            "| ece Mean Score           |       0.05 |  0.06 |          0.11 |\n",
            "| cross_entropy Mean Score |       0.77 |  1.09 |          0.81 |\n",
            "| brier_score Mean Score   |       0.25 |  0.25 |          0.29 |\n",
            "| acc Mean Score           |       0.81 |  0.82 |          0.8  |\n"
          ]
        }
      ],
      "source": [
        "pprint(all_datasets_ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = result.at(method=['xgb', 'xgb_default', 'logistic'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>method</th>\n",
              "      <th>logistic</th>\n",
              "      <th>xgb</th>\n",
              "      <th>xgb_default</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dataset</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Australian</th>\n",
              "      <td>129.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>241.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Australian.1</th>\n",
              "      <td>308.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>117.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CPMP-2015-runtime-classification</th>\n",
              "      <td>140.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>338.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CPMP-2015-runtime-classification.1</th>\n",
              "      <td>319.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>166.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CastMetal1</th>\n",
              "      <td>110.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>228.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wine.1</th>\n",
              "      <td>264.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wisconsin</th>\n",
              "      <td>73.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wisconsin.1</th>\n",
              "      <td>252.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>92.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xd6</th>\n",
              "      <td>56.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>172.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xd6.1</th>\n",
              "      <td>235.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>358 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "method                              logistic    xgb  xgb_default\n",
              "dataset                                                         \n",
              "Australian                             129.0   90.0        241.0\n",
              "Australian.1                           308.0  293.0        117.0\n",
              "CPMP-2015-runtime-classification       140.0  148.0        338.0\n",
              "CPMP-2015-runtime-classification.1     319.0  338.0        166.0\n",
              "CastMetal1                             110.0   79.0        228.0\n",
              "...                                      ...    ...          ...\n",
              "wine.1                                 264.0  315.0         68.0\n",
              "wisconsin                               73.0  115.0        316.0\n",
              "wisconsin.1                            252.0  306.0         92.0\n",
              "xd6                                     56.0    3.0        172.0\n",
              "xd6.1                                  235.0  185.0         67.0\n",
              "\n",
              "[358 rows x 3 columns]"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.df.groupby(['method']).mean().T.groupby('dataset').mean().rank()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metric            roc         time\n",
            "method                            \n",
            "logistic     0.822176  1099.557547\n",
            "xgb          0.845246  3607.387348\n",
            "xgb_default  0.834545     0.154738\n",
            "metric       cross_entropy         time\n",
            "method                                 \n",
            "logistic          0.612036  1099.557547\n",
            "xgb               1.441325  3607.387348\n",
            "xgb_default       0.650814     0.154738\n",
            "metric            acc         time\n",
            "method                            \n",
            "logistic     0.776886  1099.557547\n",
            "xgb          0.806110  3607.387348\n",
            "xgb_default  0.795503     0.154738\n",
            "metric       brier_score         time\n",
            "method                               \n",
            "logistic        0.292556  1099.557547\n",
            "xgb             0.289524  3607.387348\n",
            "xgb_default     0.309512     0.154738\n",
            "metric            ece         time\n",
            "method                            \n",
            "logistic     0.082374  1099.557547\n",
            "xgb          0.110097  3607.387348\n",
            "xgb_default  0.128083     0.154738\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for metric in result.metrics:\n",
        "    if \"time\" in metric:\n",
        "        continue\n",
        "    df_work = result.at(metric=[metric, \"time\"]).df\n",
        "    df_work = df_work.groupby([\"method\"]).mean().T.groupby(\"metric\").mean().T\n",
        "    print(df_work.groupby('method').agg({metric:'mean', 'time': 'mean'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>Australian</th>\n",
              "      <th>Australian.1</th>\n",
              "      <th>CPMP-2015-runtime-classification</th>\n",
              "      <th>CPMP-2015-runtime-classification.1</th>\n",
              "      <th>CastMetal1</th>\n",
              "      <th>CastMetal1.1</th>\n",
              "      <th>CostaMadre1</th>\n",
              "      <th>CostaMadre1.1</th>\n",
              "      <th>DiabeticMellitus</th>\n",
              "      <th>DiabeticMellitus.1</th>\n",
              "      <th>...</th>\n",
              "      <th>wdbc</th>\n",
              "      <th>wdbc.1</th>\n",
              "      <th>wholesale-customers</th>\n",
              "      <th>wholesale-customers.1</th>\n",
              "      <th>wine</th>\n",
              "      <th>wine.1</th>\n",
              "      <th>wisconsin</th>\n",
              "      <th>wisconsin.1</th>\n",
              "      <th>xd6</th>\n",
              "      <th>xd6.1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>method</th>\n",
              "      <th>optimization_metric</th>\n",
              "      <th>optimization_time</th>\n",
              "      <th>eval_position</th>\n",
              "      <th>split</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">logistic</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">roc_auc</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">3600.0</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">1000</th>\n",
              "      <th>1</th>\n",
              "      <td>613.914799</td>\n",
              "      <td>1226.909134</td>\n",
              "      <td>775.920311</td>\n",
              "      <td>1551.128047</td>\n",
              "      <td>421.853064</td>\n",
              "      <td>843.036779</td>\n",
              "      <td>407.211615</td>\n",
              "      <td>813.743508</td>\n",
              "      <td>777.696352</td>\n",
              "      <td>1554.394453</td>\n",
              "      <td>...</td>\n",
              "      <td>543.924485</td>\n",
              "      <td>1086.850688</td>\n",
              "      <td>258.759768</td>\n",
              "      <td>516.569361</td>\n",
              "      <td>294.688015</td>\n",
              "      <td>588.376895</td>\n",
              "      <td>267.847537</td>\n",
              "      <td>535.051057</td>\n",
              "      <td>235.237406</td>\n",
              "      <td>469.614847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>589.891549</td>\n",
              "      <td>1178.875518</td>\n",
              "      <td>780.746264</td>\n",
              "      <td>1560.771072</td>\n",
              "      <td>397.386261</td>\n",
              "      <td>794.069302</td>\n",
              "      <td>378.779645</td>\n",
              "      <td>756.827239</td>\n",
              "      <td>788.442219</td>\n",
              "      <td>1575.886514</td>\n",
              "      <td>...</td>\n",
              "      <td>540.714172</td>\n",
              "      <td>1080.431572</td>\n",
              "      <td>256.036430</td>\n",
              "      <td>511.128121</td>\n",
              "      <td>296.052801</td>\n",
              "      <td>591.106497</td>\n",
              "      <td>264.383613</td>\n",
              "      <td>528.145582</td>\n",
              "      <td>236.866285</td>\n",
              "      <td>472.873348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>612.818930</td>\n",
              "      <td>1224.735065</td>\n",
              "      <td>795.636311</td>\n",
              "      <td>1590.579092</td>\n",
              "      <td>414.252712</td>\n",
              "      <td>827.754586</td>\n",
              "      <td>383.754950</td>\n",
              "      <td>766.797418</td>\n",
              "      <td>784.702520</td>\n",
              "      <td>1568.410817</td>\n",
              "      <td>...</td>\n",
              "      <td>532.645521</td>\n",
              "      <td>1064.305273</td>\n",
              "      <td>252.611457</td>\n",
              "      <td>504.296721</td>\n",
              "      <td>306.410961</td>\n",
              "      <td>611.828658</td>\n",
              "      <td>278.674514</td>\n",
              "      <td>556.791630</td>\n",
              "      <td>237.408116</td>\n",
              "      <td>473.941212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>590.000713</td>\n",
              "      <td>1179.082289</td>\n",
              "      <td>789.605132</td>\n",
              "      <td>1578.494482</td>\n",
              "      <td>397.971413</td>\n",
              "      <td>795.181490</td>\n",
              "      <td>382.200439</td>\n",
              "      <td>763.660421</td>\n",
              "      <td>783.425008</td>\n",
              "      <td>1565.856515</td>\n",
              "      <td>...</td>\n",
              "      <td>524.542130</td>\n",
              "      <td>1048.092646</td>\n",
              "      <td>243.200615</td>\n",
              "      <td>485.427569</td>\n",
              "      <td>298.822865</td>\n",
              "      <td>596.645730</td>\n",
              "      <td>264.640865</td>\n",
              "      <td>528.590085</td>\n",
              "      <td>230.862540</td>\n",
              "      <td>460.867303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>632.718499</td>\n",
              "      <td>1264.514705</td>\n",
              "      <td>809.276986</td>\n",
              "      <td>1617.837927</td>\n",
              "      <td>410.882772</td>\n",
              "      <td>820.967077</td>\n",
              "      <td>392.114489</td>\n",
              "      <td>783.457694</td>\n",
              "      <td>797.056117</td>\n",
              "      <td>1593.127149</td>\n",
              "      <td>...</td>\n",
              "      <td>484.468007</td>\n",
              "      <td>967.937393</td>\n",
              "      <td>250.930003</td>\n",
              "      <td>500.912407</td>\n",
              "      <td>290.721100</td>\n",
              "      <td>580.444063</td>\n",
              "      <td>270.132986</td>\n",
              "      <td>539.628750</td>\n",
              "      <td>261.732775</td>\n",
              "      <td>522.616818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">xgb</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">roc_auc</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">3600.0</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">1000</th>\n",
              "      <th>1</th>\n",
              "      <td>1801.446103</td>\n",
              "      <td>3601.965523</td>\n",
              "      <td>1805.960673</td>\n",
              "      <td>3611.208487</td>\n",
              "      <td>1803.162272</td>\n",
              "      <td>3605.605899</td>\n",
              "      <td>1801.152703</td>\n",
              "      <td>3601.684434</td>\n",
              "      <td>1800.898366</td>\n",
              "      <td>3600.799027</td>\n",
              "      <td>...</td>\n",
              "      <td>1801.267941</td>\n",
              "      <td>3601.543121</td>\n",
              "      <td>1800.605553</td>\n",
              "      <td>3600.263059</td>\n",
              "      <td>1803.309241</td>\n",
              "      <td>3605.618481</td>\n",
              "      <td>1802.687855</td>\n",
              "      <td>3604.747077</td>\n",
              "      <td>1800.723571</td>\n",
              "      <td>3600.447142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1802.198123</td>\n",
              "      <td>3603.473378</td>\n",
              "      <td>1814.881625</td>\n",
              "      <td>3629.048317</td>\n",
              "      <td>1801.859671</td>\n",
              "      <td>3602.962468</td>\n",
              "      <td>1800.791106</td>\n",
              "      <td>3600.914263</td>\n",
              "      <td>1801.287224</td>\n",
              "      <td>3601.590620</td>\n",
              "      <td>...</td>\n",
              "      <td>1800.801943</td>\n",
              "      <td>3600.607948</td>\n",
              "      <td>1800.771284</td>\n",
              "      <td>3600.590559</td>\n",
              "      <td>1802.209655</td>\n",
              "      <td>3603.419309</td>\n",
              "      <td>1801.553059</td>\n",
              "      <td>3602.590533</td>\n",
              "      <td>1800.570882</td>\n",
              "      <td>3600.141765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1802.597823</td>\n",
              "      <td>3604.292376</td>\n",
              "      <td>1801.483666</td>\n",
              "      <td>3602.265109</td>\n",
              "      <td>1802.012735</td>\n",
              "      <td>3603.419166</td>\n",
              "      <td>1800.705127</td>\n",
              "      <td>3600.650513</td>\n",
              "      <td>1801.146013</td>\n",
              "      <td>3601.296138</td>\n",
              "      <td>...</td>\n",
              "      <td>1801.953841</td>\n",
              "      <td>3602.923570</td>\n",
              "      <td>1802.131044</td>\n",
              "      <td>3603.318140</td>\n",
              "      <td>1803.372438</td>\n",
              "      <td>3605.745166</td>\n",
              "      <td>1800.583314</td>\n",
              "      <td>3600.620285</td>\n",
              "      <td>1800.760045</td>\n",
              "      <td>3600.520090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1801.582362</td>\n",
              "      <td>3602.222282</td>\n",
              "      <td>1802.677052</td>\n",
              "      <td>3604.631505</td>\n",
              "      <td>1800.973615</td>\n",
              "      <td>3601.263999</td>\n",
              "      <td>1801.451974</td>\n",
              "      <td>3602.177409</td>\n",
              "      <td>1800.756104</td>\n",
              "      <td>3600.514583</td>\n",
              "      <td>...</td>\n",
              "      <td>1800.947291</td>\n",
              "      <td>3600.899126</td>\n",
              "      <td>1800.795305</td>\n",
              "      <td>3600.627875</td>\n",
              "      <td>1800.979642</td>\n",
              "      <td>3600.959284</td>\n",
              "      <td>1802.590403</td>\n",
              "      <td>3604.593381</td>\n",
              "      <td>1801.590502</td>\n",
              "      <td>3602.181004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1802.397157</td>\n",
              "      <td>3603.862974</td>\n",
              "      <td>1803.184097</td>\n",
              "      <td>3605.649215</td>\n",
              "      <td>1800.631781</td>\n",
              "      <td>3600.489232</td>\n",
              "      <td>1801.172833</td>\n",
              "      <td>3601.617310</td>\n",
              "      <td>1800.692094</td>\n",
              "      <td>3600.385134</td>\n",
              "      <td>...</td>\n",
              "      <td>1801.046752</td>\n",
              "      <td>3601.096426</td>\n",
              "      <td>1801.396339</td>\n",
              "      <td>3601.832366</td>\n",
              "      <td>1802.854079</td>\n",
              "      <td>3604.709377</td>\n",
              "      <td>1803.101793</td>\n",
              "      <td>3605.569795</td>\n",
              "      <td>1801.252276</td>\n",
              "      <td>3601.504553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">xgb_default</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">roc_auc</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">3600.0</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">1000</th>\n",
              "      <th>1</th>\n",
              "      <td>0.489344</td>\n",
              "      <td>0.058844</td>\n",
              "      <td>0.459081</td>\n",
              "      <td>0.255354</td>\n",
              "      <td>0.384955</td>\n",
              "      <td>0.048248</td>\n",
              "      <td>0.347735</td>\n",
              "      <td>0.048388</td>\n",
              "      <td>0.517720</td>\n",
              "      <td>0.036097</td>\n",
              "      <td>...</td>\n",
              "      <td>0.526193</td>\n",
              "      <td>0.058583</td>\n",
              "      <td>0.486249</td>\n",
              "      <td>0.035869</td>\n",
              "      <td>0.517126</td>\n",
              "      <td>0.040350</td>\n",
              "      <td>0.344531</td>\n",
              "      <td>0.041625</td>\n",
              "      <td>0.520038</td>\n",
              "      <td>0.040076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.488106</td>\n",
              "      <td>0.057707</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>0.258400</td>\n",
              "      <td>0.376556</td>\n",
              "      <td>0.051234</td>\n",
              "      <td>0.395438</td>\n",
              "      <td>0.044294</td>\n",
              "      <td>0.507698</td>\n",
              "      <td>0.038778</td>\n",
              "      <td>...</td>\n",
              "      <td>0.522247</td>\n",
              "      <td>0.052878</td>\n",
              "      <td>0.489750</td>\n",
              "      <td>0.035786</td>\n",
              "      <td>0.520472</td>\n",
              "      <td>0.041244</td>\n",
              "      <td>0.303445</td>\n",
              "      <td>0.077886</td>\n",
              "      <td>0.519851</td>\n",
              "      <td>0.039703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.486208</td>\n",
              "      <td>0.059501</td>\n",
              "      <td>0.456195</td>\n",
              "      <td>0.246061</td>\n",
              "      <td>0.353117</td>\n",
              "      <td>0.054323</td>\n",
              "      <td>0.420595</td>\n",
              "      <td>0.053312</td>\n",
              "      <td>0.516195</td>\n",
              "      <td>0.035167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.510820</td>\n",
              "      <td>0.043816</td>\n",
              "      <td>0.481416</td>\n",
              "      <td>0.035344</td>\n",
              "      <td>0.518600</td>\n",
              "      <td>0.039698</td>\n",
              "      <td>0.291935</td>\n",
              "      <td>0.041778</td>\n",
              "      <td>0.520450</td>\n",
              "      <td>0.040901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.501598</td>\n",
              "      <td>0.061196</td>\n",
              "      <td>0.488059</td>\n",
              "      <td>0.254122</td>\n",
              "      <td>0.375621</td>\n",
              "      <td>0.050932</td>\n",
              "      <td>0.395998</td>\n",
              "      <td>0.050639</td>\n",
              "      <td>0.516227</td>\n",
              "      <td>0.037205</td>\n",
              "      <td>...</td>\n",
              "      <td>0.526247</td>\n",
              "      <td>0.058553</td>\n",
              "      <td>0.502130</td>\n",
              "      <td>0.058694</td>\n",
              "      <td>0.520226</td>\n",
              "      <td>0.040603</td>\n",
              "      <td>0.287268</td>\n",
              "      <td>0.040945</td>\n",
              "      <td>0.519798</td>\n",
              "      <td>0.039596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.500958</td>\n",
              "      <td>0.059335</td>\n",
              "      <td>0.456204</td>\n",
              "      <td>0.250391</td>\n",
              "      <td>0.415190</td>\n",
              "      <td>0.054517</td>\n",
              "      <td>0.420338</td>\n",
              "      <td>0.043058</td>\n",
              "      <td>0.517933</td>\n",
              "      <td>0.036339</td>\n",
              "      <td>...</td>\n",
              "      <td>0.524988</td>\n",
              "      <td>0.056150</td>\n",
              "      <td>0.494850</td>\n",
              "      <td>0.037380</td>\n",
              "      <td>0.520278</td>\n",
              "      <td>0.041077</td>\n",
              "      <td>0.321616</td>\n",
              "      <td>0.043746</td>\n",
              "      <td>0.520433</td>\n",
              "      <td>0.040865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 358 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "dataset                                                                 Australian  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       613.914799   \n",
              "                                                                2       589.891549   \n",
              "                                                                3       612.818930   \n",
              "                                                                4       590.000713   \n",
              "                                                                5       632.718499   \n",
              "xgb         roc_auc             3600.0            1000          1      1801.446103   \n",
              "                                                                2      1802.198123   \n",
              "                                                                3      1802.597823   \n",
              "                                                                4      1801.582362   \n",
              "                                                                5      1802.397157   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.489344   \n",
              "                                                                2         0.488106   \n",
              "                                                                3         0.486208   \n",
              "                                                                4         0.501598   \n",
              "                                                                5         0.500958   \n",
              "\n",
              "dataset                                                                Australian.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                 \n",
              "logistic    roc_auc             3600.0            1000          1       1226.909134   \n",
              "                                                                2       1178.875518   \n",
              "                                                                3       1224.735065   \n",
              "                                                                4       1179.082289   \n",
              "                                                                5       1264.514705   \n",
              "xgb         roc_auc             3600.0            1000          1       3601.965523   \n",
              "                                                                2       3603.473378   \n",
              "                                                                3       3604.292376   \n",
              "                                                                4       3602.222282   \n",
              "                                                                5       3603.862974   \n",
              "xgb_default roc_auc             3600.0            1000          1          0.058844   \n",
              "                                                                2          0.057707   \n",
              "                                                                3          0.059501   \n",
              "                                                                4          0.061196   \n",
              "                                                                5          0.059335   \n",
              "\n",
              "dataset                                                                CPMP-2015-runtime-classification  \\\n",
              "method      optimization_metric optimization_time eval_position split                                     \n",
              "logistic    roc_auc             3600.0            1000          1                            775.920311   \n",
              "                                                                2                            780.746264   \n",
              "                                                                3                            795.636311   \n",
              "                                                                4                            789.605132   \n",
              "                                                                5                            809.276986   \n",
              "xgb         roc_auc             3600.0            1000          1                           1805.960673   \n",
              "                                                                2                           1814.881625   \n",
              "                                                                3                           1801.483666   \n",
              "                                                                4                           1802.677052   \n",
              "                                                                5                           1803.184097   \n",
              "xgb_default roc_auc             3600.0            1000          1                              0.459081   \n",
              "                                                                2                              0.457611   \n",
              "                                                                3                              0.456195   \n",
              "                                                                4                              0.488059   \n",
              "                                                                5                              0.456204   \n",
              "\n",
              "dataset                                                                CPMP-2015-runtime-classification.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                                       \n",
              "logistic    roc_auc             3600.0            1000          1                             1551.128047   \n",
              "                                                                2                             1560.771072   \n",
              "                                                                3                             1590.579092   \n",
              "                                                                4                             1578.494482   \n",
              "                                                                5                             1617.837927   \n",
              "xgb         roc_auc             3600.0            1000          1                             3611.208487   \n",
              "                                                                2                             3629.048317   \n",
              "                                                                3                             3602.265109   \n",
              "                                                                4                             3604.631505   \n",
              "                                                                5                             3605.649215   \n",
              "xgb_default roc_auc             3600.0            1000          1                                0.255354   \n",
              "                                                                2                                0.258400   \n",
              "                                                                3                                0.246061   \n",
              "                                                                4                                0.254122   \n",
              "                                                                5                                0.250391   \n",
              "\n",
              "dataset                                                                 CastMetal1  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       421.853064   \n",
              "                                                                2       397.386261   \n",
              "                                                                3       414.252712   \n",
              "                                                                4       397.971413   \n",
              "                                                                5       410.882772   \n",
              "xgb         roc_auc             3600.0            1000          1      1803.162272   \n",
              "                                                                2      1801.859671   \n",
              "                                                                3      1802.012735   \n",
              "                                                                4      1800.973615   \n",
              "                                                                5      1800.631781   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.384955   \n",
              "                                                                2         0.376556   \n",
              "                                                                3         0.353117   \n",
              "                                                                4         0.375621   \n",
              "                                                                5         0.415190   \n",
              "\n",
              "dataset                                                                CastMetal1.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                 \n",
              "logistic    roc_auc             3600.0            1000          1        843.036779   \n",
              "                                                                2        794.069302   \n",
              "                                                                3        827.754586   \n",
              "                                                                4        795.181490   \n",
              "                                                                5        820.967077   \n",
              "xgb         roc_auc             3600.0            1000          1       3605.605899   \n",
              "                                                                2       3602.962468   \n",
              "                                                                3       3603.419166   \n",
              "                                                                4       3601.263999   \n",
              "                                                                5       3600.489232   \n",
              "xgb_default roc_auc             3600.0            1000          1          0.048248   \n",
              "                                                                2          0.051234   \n",
              "                                                                3          0.054323   \n",
              "                                                                4          0.050932   \n",
              "                                                                5          0.054517   \n",
              "\n",
              "dataset                                                                CostaMadre1  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       407.211615   \n",
              "                                                                2       378.779645   \n",
              "                                                                3       383.754950   \n",
              "                                                                4       382.200439   \n",
              "                                                                5       392.114489   \n",
              "xgb         roc_auc             3600.0            1000          1      1801.152703   \n",
              "                                                                2      1800.791106   \n",
              "                                                                3      1800.705127   \n",
              "                                                                4      1801.451974   \n",
              "                                                                5      1801.172833   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.347735   \n",
              "                                                                2         0.395438   \n",
              "                                                                3         0.420595   \n",
              "                                                                4         0.395998   \n",
              "                                                                5         0.420338   \n",
              "\n",
              "dataset                                                                CostaMadre1.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                  \n",
              "logistic    roc_auc             3600.0            1000          1         813.743508   \n",
              "                                                                2         756.827239   \n",
              "                                                                3         766.797418   \n",
              "                                                                4         763.660421   \n",
              "                                                                5         783.457694   \n",
              "xgb         roc_auc             3600.0            1000          1        3601.684434   \n",
              "                                                                2        3600.914263   \n",
              "                                                                3        3600.650513   \n",
              "                                                                4        3602.177409   \n",
              "                                                                5        3601.617310   \n",
              "xgb_default roc_auc             3600.0            1000          1           0.048388   \n",
              "                                                                2           0.044294   \n",
              "                                                                3           0.053312   \n",
              "                                                                4           0.050639   \n",
              "                                                                5           0.043058   \n",
              "\n",
              "dataset                                                                DiabeticMellitus  \\\n",
              "method      optimization_metric optimization_time eval_position split                     \n",
              "logistic    roc_auc             3600.0            1000          1            777.696352   \n",
              "                                                                2            788.442219   \n",
              "                                                                3            784.702520   \n",
              "                                                                4            783.425008   \n",
              "                                                                5            797.056117   \n",
              "xgb         roc_auc             3600.0            1000          1           1800.898366   \n",
              "                                                                2           1801.287224   \n",
              "                                                                3           1801.146013   \n",
              "                                                                4           1800.756104   \n",
              "                                                                5           1800.692094   \n",
              "xgb_default roc_auc             3600.0            1000          1              0.517720   \n",
              "                                                                2              0.507698   \n",
              "                                                                3              0.516195   \n",
              "                                                                4              0.516227   \n",
              "                                                                5              0.517933   \n",
              "\n",
              "dataset                                                                DiabeticMellitus.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                       \n",
              "logistic    roc_auc             3600.0            1000          1             1554.394453   \n",
              "                                                                2             1575.886514   \n",
              "                                                                3             1568.410817   \n",
              "                                                                4             1565.856515   \n",
              "                                                                5             1593.127149   \n",
              "xgb         roc_auc             3600.0            1000          1             3600.799027   \n",
              "                                                                2             3601.590620   \n",
              "                                                                3             3601.296138   \n",
              "                                                                4             3600.514583   \n",
              "                                                                5             3600.385134   \n",
              "xgb_default roc_auc             3600.0            1000          1                0.036097   \n",
              "                                                                2                0.038778   \n",
              "                                                                3                0.035167   \n",
              "                                                                4                0.037205   \n",
              "                                                                5                0.036339   \n",
              "\n",
              "dataset                                                                ...  \\\n",
              "method      optimization_metric optimization_time eval_position split  ...   \n",
              "logistic    roc_auc             3600.0            1000          1      ...   \n",
              "                                                                2      ...   \n",
              "                                                                3      ...   \n",
              "                                                                4      ...   \n",
              "                                                                5      ...   \n",
              "xgb         roc_auc             3600.0            1000          1      ...   \n",
              "                                                                2      ...   \n",
              "                                                                3      ...   \n",
              "                                                                4      ...   \n",
              "                                                                5      ...   \n",
              "xgb_default roc_auc             3600.0            1000          1      ...   \n",
              "                                                                2      ...   \n",
              "                                                                3      ...   \n",
              "                                                                4      ...   \n",
              "                                                                5      ...   \n",
              "\n",
              "dataset                                                                       wdbc  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       543.924485   \n",
              "                                                                2       540.714172   \n",
              "                                                                3       532.645521   \n",
              "                                                                4       524.542130   \n",
              "                                                                5       484.468007   \n",
              "xgb         roc_auc             3600.0            1000          1      1801.267941   \n",
              "                                                                2      1800.801943   \n",
              "                                                                3      1801.953841   \n",
              "                                                                4      1800.947291   \n",
              "                                                                5      1801.046752   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.526193   \n",
              "                                                                2         0.522247   \n",
              "                                                                3         0.510820   \n",
              "                                                                4         0.526247   \n",
              "                                                                5         0.524988   \n",
              "\n",
              "dataset                                                                     wdbc.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1      1086.850688   \n",
              "                                                                2      1080.431572   \n",
              "                                                                3      1064.305273   \n",
              "                                                                4      1048.092646   \n",
              "                                                                5       967.937393   \n",
              "xgb         roc_auc             3600.0            1000          1      3601.543121   \n",
              "                                                                2      3600.607948   \n",
              "                                                                3      3602.923570   \n",
              "                                                                4      3600.899126   \n",
              "                                                                5      3601.096426   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.058583   \n",
              "                                                                2         0.052878   \n",
              "                                                                3         0.043816   \n",
              "                                                                4         0.058553   \n",
              "                                                                5         0.056150   \n",
              "\n",
              "dataset                                                                wholesale-customers  \\\n",
              "method      optimization_metric optimization_time eval_position split                        \n",
              "logistic    roc_auc             3600.0            1000          1               258.759768   \n",
              "                                                                2               256.036430   \n",
              "                                                                3               252.611457   \n",
              "                                                                4               243.200615   \n",
              "                                                                5               250.930003   \n",
              "xgb         roc_auc             3600.0            1000          1              1800.605553   \n",
              "                                                                2              1800.771284   \n",
              "                                                                3              1802.131044   \n",
              "                                                                4              1800.795305   \n",
              "                                                                5              1801.396339   \n",
              "xgb_default roc_auc             3600.0            1000          1                 0.486249   \n",
              "                                                                2                 0.489750   \n",
              "                                                                3                 0.481416   \n",
              "                                                                4                 0.502130   \n",
              "                                                                5                 0.494850   \n",
              "\n",
              "dataset                                                                wholesale-customers.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                          \n",
              "logistic    roc_auc             3600.0            1000          1                 516.569361   \n",
              "                                                                2                 511.128121   \n",
              "                                                                3                 504.296721   \n",
              "                                                                4                 485.427569   \n",
              "                                                                5                 500.912407   \n",
              "xgb         roc_auc             3600.0            1000          1                3600.263059   \n",
              "                                                                2                3600.590559   \n",
              "                                                                3                3603.318140   \n",
              "                                                                4                3600.627875   \n",
              "                                                                5                3601.832366   \n",
              "xgb_default roc_auc             3600.0            1000          1                   0.035869   \n",
              "                                                                2                   0.035786   \n",
              "                                                                3                   0.035344   \n",
              "                                                                4                   0.058694   \n",
              "                                                                5                   0.037380   \n",
              "\n",
              "dataset                                                                       wine  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       294.688015   \n",
              "                                                                2       296.052801   \n",
              "                                                                3       306.410961   \n",
              "                                                                4       298.822865   \n",
              "                                                                5       290.721100   \n",
              "xgb         roc_auc             3600.0            1000          1      1803.309241   \n",
              "                                                                2      1802.209655   \n",
              "                                                                3      1803.372438   \n",
              "                                                                4      1800.979642   \n",
              "                                                                5      1802.854079   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.517126   \n",
              "                                                                2         0.520472   \n",
              "                                                                3         0.518600   \n",
              "                                                                4         0.520226   \n",
              "                                                                5         0.520278   \n",
              "\n",
              "dataset                                                                     wine.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       588.376895   \n",
              "                                                                2       591.106497   \n",
              "                                                                3       611.828658   \n",
              "                                                                4       596.645730   \n",
              "                                                                5       580.444063   \n",
              "xgb         roc_auc             3600.0            1000          1      3605.618481   \n",
              "                                                                2      3603.419309   \n",
              "                                                                3      3605.745166   \n",
              "                                                                4      3600.959284   \n",
              "                                                                5      3604.709377   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.040350   \n",
              "                                                                2         0.041244   \n",
              "                                                                3         0.039698   \n",
              "                                                                4         0.040603   \n",
              "                                                                5         0.041077   \n",
              "\n",
              "dataset                                                                  wisconsin  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       267.847537   \n",
              "                                                                2       264.383613   \n",
              "                                                                3       278.674514   \n",
              "                                                                4       264.640865   \n",
              "                                                                5       270.132986   \n",
              "xgb         roc_auc             3600.0            1000          1      1802.687855   \n",
              "                                                                2      1801.553059   \n",
              "                                                                3      1800.583314   \n",
              "                                                                4      1802.590403   \n",
              "                                                                5      1803.101793   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.344531   \n",
              "                                                                2         0.303445   \n",
              "                                                                3         0.291935   \n",
              "                                                                4         0.287268   \n",
              "                                                                5         0.321616   \n",
              "\n",
              "dataset                                                                wisconsin.1  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       535.051057   \n",
              "                                                                2       528.145582   \n",
              "                                                                3       556.791630   \n",
              "                                                                4       528.590085   \n",
              "                                                                5       539.628750   \n",
              "xgb         roc_auc             3600.0            1000          1      3604.747077   \n",
              "                                                                2      3602.590533   \n",
              "                                                                3      3600.620285   \n",
              "                                                                4      3604.593381   \n",
              "                                                                5      3605.569795   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.041625   \n",
              "                                                                2         0.077886   \n",
              "                                                                3         0.041778   \n",
              "                                                                4         0.040945   \n",
              "                                                                5         0.043746   \n",
              "\n",
              "dataset                                                                        xd6  \\\n",
              "method      optimization_metric optimization_time eval_position split                \n",
              "logistic    roc_auc             3600.0            1000          1       235.237406   \n",
              "                                                                2       236.866285   \n",
              "                                                                3       237.408116   \n",
              "                                                                4       230.862540   \n",
              "                                                                5       261.732775   \n",
              "xgb         roc_auc             3600.0            1000          1      1800.723571   \n",
              "                                                                2      1800.570882   \n",
              "                                                                3      1800.760045   \n",
              "                                                                4      1801.590502   \n",
              "                                                                5      1801.252276   \n",
              "xgb_default roc_auc             3600.0            1000          1         0.520038   \n",
              "                                                                2         0.519851   \n",
              "                                                                3         0.520450   \n",
              "                                                                4         0.519798   \n",
              "                                                                5         0.520433   \n",
              "\n",
              "dataset                                                                      xd6.1  \n",
              "method      optimization_metric optimization_time eval_position split               \n",
              "logistic    roc_auc             3600.0            1000          1       469.614847  \n",
              "                                                                2       472.873348  \n",
              "                                                                3       473.941212  \n",
              "                                                                4       460.867303  \n",
              "                                                                5       522.616818  \n",
              "xgb         roc_auc             3600.0            1000          1      3600.447142  \n",
              "                                                                2      3600.141765  \n",
              "                                                                3      3600.520090  \n",
              "                                                                4      3602.181004  \n",
              "                                                                5      3601.504553  \n",
              "xgb_default roc_auc             3600.0            1000          1         0.040076  \n",
              "                                                                2         0.039703  \n",
              "                                                                3         0.040901  \n",
              "                                                                4         0.039596  \n",
              "                                                                5         0.040865  \n",
              "\n",
              "[15 rows x 358 columns]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_work = result.at(metric=[\"roc\", \"time\"]).df\n",
        "df_work.T.groupby([\"dataset\"]).mean().T\n",
        "# df_work = df_work.groupby([\"method\"]).mean().T.groupby(\"metric\").mean().T\n",
        "# print(df_work.groupby('method').agg({metric:'mean', 'time': 'mean'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>metric</th>\n",
              "      <th>acc</th>\n",
              "      <th>brier_score</th>\n",
              "      <th>cross_entropy</th>\n",
              "      <th>ece</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>inference_time</th>\n",
              "      <th>roc</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>method</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>logistic</th>\n",
              "      <td>0.776886</td>\n",
              "      <td>0.292556</td>\n",
              "      <td>0.612036</td>\n",
              "      <td>0.082374</td>\n",
              "      <td>0.067362</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.822176</td>\n",
              "      <td>1099.557547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgb</th>\n",
              "      <td>0.806110</td>\n",
              "      <td>0.289524</td>\n",
              "      <td>1.441325</td>\n",
              "      <td>0.110097</td>\n",
              "      <td>1.803934</td>\n",
              "      <td>0.017651</td>\n",
              "      <td>0.845246</td>\n",
              "      <td>3607.387348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgb_default</th>\n",
              "      <td>0.795503</td>\n",
              "      <td>0.309512</td>\n",
              "      <td>0.650814</td>\n",
              "      <td>0.128083</td>\n",
              "      <td>0.146990</td>\n",
              "      <td>0.003018</td>\n",
              "      <td>0.834545</td>\n",
              "      <td>0.154738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "metric            acc  brier_score  cross_entropy       ece  fit_time  \\\n",
              "method                                                                  \n",
              "logistic     0.776886     0.292556       0.612036  0.082374  0.067362   \n",
              "xgb          0.806110     0.289524       1.441325  0.110097  1.803934   \n",
              "xgb_default  0.795503     0.309512       0.650814  0.128083  0.146990   \n",
              "\n",
              "metric       inference_time       roc         time  \n",
              "method                                              \n",
              "logistic           0.000214  0.822176  1099.557547  \n",
              "xgb                0.017651  0.845246  3607.387348  \n",
              "xgb_default        0.003018  0.834545     0.154738  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.df.T.groupby(['metric']).mean().T.groupby('method').mean() #.rank().T.groupby('method').mean() #.T.groupby('metric').mean().T.rank(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Animal</th>\n",
              "      <th>Number_legs</th>\n",
              "      <th>default_rank</th>\n",
              "      <th>max_rank</th>\n",
              "      <th>desc_rank</th>\n",
              "      <th>NA_bottom</th>\n",
              "      <th>pct_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>penguin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dog</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spider</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>snake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Animal  Number_legs  default_rank  max_rank  desc_rank  NA_bottom  \\\n",
              "0      cat          4.0           2.5       3.0        2.5        2.5   \n",
              "1  penguin          2.0           1.0       1.0        4.0        1.0   \n",
              "2      dog          4.0           2.5       3.0        2.5        2.5   \n",
              "3   spider          8.0           4.0       4.0        1.0        4.0   \n",
              "4    snake          NaN           NaN       NaN        NaN        5.0   \n",
              "\n",
              "   pct_rank  \n",
              "0     0.625  \n",
              "1     0.250  \n",
              "2     0.625  \n",
              "3     1.000  \n",
              "4       NaN  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
        "                                   'spider', 'snake'],\n",
        "                        'Number_legs': [4, 2, 4, 8, np.nan]})\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "df['default_rank'] = df['Number_legs'].rank()\n",
        "df['max_rank'] = df['Number_legs'].rank(method='max')\n",
        "df['desc_rank'] = df['Number_legs'].rank(ascending=False)\n",
        "\n",
        "df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
        "df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
        "df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FrozenList([['acc', 'brier_score', 'cross_entropy', 'ece', 'roc', 'time'], ['AirlinesCodrnaAdult', 'BNG(anneal,1000,10)', 'BNG(anneal,1000,5)', 'BNG(anneal,10000,10)', 'BNG(anneal,5000,10)', 'BNG(anneal,5000,5)', 'BNG(anneal.ORIG,1000,10)', 'BNG(anneal.ORIG,1000,5)', 'Higgs', 'Hyperplane_10_1E-3', 'Hyperplane_10_1E-4', 'MagicTelescope', 'MiniBooNE', 'bank-marketing', 'california', 'covertype', 'credit', 'electricity', 'eye_movements', 'house_16H', 'jannis', 'jungle_chess_2pcs_endgame_panther_elephant', 'kdd_ipums_la_97-small', 'microaggregation2', 'phoneme', 'pol', 'wine']])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns.levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['roc', 'cross_entropy', 'acc', 'brier_score', 'ece', 'time'], dtype='object', name='metric')\n"
          ]
        }
      ],
      "source": [
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "results = {\"methods\": [] ,\"datasets\" : []} #,\"seeds\": [] }'roc': [], 'cross_entropy': [], 'acc': [], 'brier_score': [], 'ece': [] \n",
        "metric_results = {}\n",
        "for metric in metrics:\n",
        "    metric_results[metric] = {**results, **{\"score\": []}}\n",
        "\n",
        "for (\n",
        "    metric,\n",
        "    method,\n",
        "    dataset,\n",
        "    seed) in product(\n",
        "        metrics,\n",
        "        methods,\n",
        "        datasets,\n",
        "        seeds\n",
        "    ):\n",
        "    if metric in metric_results:\n",
        "        \n",
        "        metric_results[metric][\"score\"].append(df.loc[(method, seed), (metric, dataset)])\n",
        "        # other_metrics = [met for met in metrics if met in results and met != metric]\n",
        "        # for other_metric in other_metrics:\n",
        "        #     results[other_metric].append(np.nan)\n",
        "        metric_results[metric][\"methods\"].append(method)\n",
        "        metric_results[metric][\"datasets\"].append(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(len(results[\"datasets\"]))\n",
        "dfs = []\n",
        "for metric in metric_results:\n",
        "    print(metric_results[metric])\n",
        "    break\n",
        "    # dfs.append(pd.DataFrame(metric_results[metric]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>roc</th>\n",
              "      <th>cross_entropy</th>\n",
              "      <th>acc</th>\n",
              "      <th>brier_score</th>\n",
              "      <th>ece</th>\n",
              "      <th>methods</th>\n",
              "      <th>datasets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.782412</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>decision_tree</td>\n",
              "      <td>MagicTelescope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.841181</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>decision_tree</td>\n",
              "      <td>kdd_ipums_la_97-small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.595672</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>decision_tree</td>\n",
              "      <td>microaggregation2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.696735</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>decision_tree</td>\n",
              "      <td>credit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.726597</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>decision_tree</td>\n",
              "      <td>covertype</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        roc  cross_entropy  acc  brier_score  ece        methods  \\\n",
              "0  0.782412            NaN  NaN          NaN  NaN  decision_tree   \n",
              "1  0.841181            NaN  NaN          NaN  NaN  decision_tree   \n",
              "2  0.595672            NaN  NaN          NaN  NaN  decision_tree   \n",
              "3  0.696735            NaN  NaN          NaN  NaN  decision_tree   \n",
              "4  0.726597            NaN  NaN          NaN  NaN  decision_tree   \n",
              "\n",
              "                datasets  \n",
              "0         MagicTelescope  \n",
              "1  kdd_ipums_la_97-small  \n",
              "2      microaggregation2  \n",
              "3                 credit  \n",
              "4              covertype  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# grouped_df = df.groupby([\"metric\"], axis=1)\n",
        "# # for metric in [\"roc\", \"cross_entropy\", \"acc\", \"brier_score\", \"ece\"]:\n",
        "# #     print(grouped_df[\"metric\"])\n",
        "# for key, item in grouped_df:\n",
        "#     print(grouped_df.get_group(key), \"\\n\\n\")\n",
        "new_df = df.droplevel(0)\n",
        "\n",
        "columns = new_df.columns\n",
        "# move dataset which is an index to a column\n",
        "new_df = new_df.reset_index()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>metric</th>\n",
              "      <th>seed</th>\n",
              "      <th colspan=\"9\" halign=\"left\">roc</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"10\" halign=\"left\">time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dataset</th>\n",
              "      <th></th>\n",
              "      <th>MagicTelescope</th>\n",
              "      <th>kdd_ipums_la_97-small</th>\n",
              "      <th>microaggregation2</th>\n",
              "      <th>credit</th>\n",
              "      <th>covertype</th>\n",
              "      <th>BNG(anneal,10000,10)</th>\n",
              "      <th>Hyperplane_10_1E-4</th>\n",
              "      <th>BNG(anneal,1000,10)</th>\n",
              "      <th>BNG(anneal.ORIG,1000,5)</th>\n",
              "      <th>...</th>\n",
              "      <th>jungle_chess_2pcs_endgame_panther_elephant</th>\n",
              "      <th>Higgs</th>\n",
              "      <th>BNG(anneal,1000,5)</th>\n",
              "      <th>pol</th>\n",
              "      <th>bank-marketing</th>\n",
              "      <th>electricity</th>\n",
              "      <th>AirlinesCodrnaAdult</th>\n",
              "      <th>phoneme</th>\n",
              "      <th>BNG(anneal,5000,10)</th>\n",
              "      <th>eye_movements</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>545</td>\n",
              "      <td>0.782412</td>\n",
              "      <td>0.841181</td>\n",
              "      <td>0.595672</td>\n",
              "      <td>0.696735</td>\n",
              "      <td>0.726597</td>\n",
              "      <td>0.528036</td>\n",
              "      <td>0.763146</td>\n",
              "      <td>0.508719</td>\n",
              "      <td>0.512843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.355518</td>\n",
              "      <td>0.446817</td>\n",
              "      <td>0.420937</td>\n",
              "      <td>0.215281</td>\n",
              "      <td>0.215589</td>\n",
              "      <td>0.224699</td>\n",
              "      <td>0.222294</td>\n",
              "      <td>0.323657</td>\n",
              "      <td>0.257108</td>\n",
              "      <td>0.303802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>545</td>\n",
              "      <td>0.932046</td>\n",
              "      <td>0.935325</td>\n",
              "      <td>0.755082</td>\n",
              "      <td>0.852535</td>\n",
              "      <td>0.875508</td>\n",
              "      <td>0.611405</td>\n",
              "      <td>0.930383</td>\n",
              "      <td>0.541617</td>\n",
              "      <td>0.525379</td>\n",
              "      <td>...</td>\n",
              "      <td>1.155980</td>\n",
              "      <td>0.673221</td>\n",
              "      <td>2.052475</td>\n",
              "      <td>0.627228</td>\n",
              "      <td>0.514952</td>\n",
              "      <td>0.527702</td>\n",
              "      <td>0.569372</td>\n",
              "      <td>0.486907</td>\n",
              "      <td>2.127459</td>\n",
              "      <td>0.604081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>545</td>\n",
              "      <td>0.842083</td>\n",
              "      <td>0.933905</td>\n",
              "      <td>0.689300</td>\n",
              "      <td>0.814789</td>\n",
              "      <td>0.665893</td>\n",
              "      <td>0.515501</td>\n",
              "      <td>0.940687</td>\n",
              "      <td>0.485922</td>\n",
              "      <td>0.483152</td>\n",
              "      <td>...</td>\n",
              "      <td>1.043188</td>\n",
              "      <td>1.027906</td>\n",
              "      <td>1.192532</td>\n",
              "      <td>1.069844</td>\n",
              "      <td>0.952714</td>\n",
              "      <td>0.953843</td>\n",
              "      <td>1.055812</td>\n",
              "      <td>1.144558</td>\n",
              "      <td>1.275809</td>\n",
              "      <td>1.006918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>545</td>\n",
              "      <td>0.889420</td>\n",
              "      <td>0.822186</td>\n",
              "      <td>0.759091</td>\n",
              "      <td>0.714959</td>\n",
              "      <td>0.826003</td>\n",
              "      <td>0.562016</td>\n",
              "      <td>0.940189</td>\n",
              "      <td>0.609052</td>\n",
              "      <td>0.513810</td>\n",
              "      <td>...</td>\n",
              "      <td>2.208635</td>\n",
              "      <td>6.011692</td>\n",
              "      <td>1.314823</td>\n",
              "      <td>3.000965</td>\n",
              "      <td>0.825624</td>\n",
              "      <td>5.132117</td>\n",
              "      <td>0.936474</td>\n",
              "      <td>2.120451</td>\n",
              "      <td>1.489000</td>\n",
              "      <td>0.913519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>545</td>\n",
              "      <td>0.931711</td>\n",
              "      <td>0.941083</td>\n",
              "      <td>0.749405</td>\n",
              "      <td>0.844759</td>\n",
              "      <td>0.881157</td>\n",
              "      <td>0.648699</td>\n",
              "      <td>0.928386</td>\n",
              "      <td>0.593278</td>\n",
              "      <td>0.622719</td>\n",
              "      <td>...</td>\n",
              "      <td>0.546699</td>\n",
              "      <td>1.932822</td>\n",
              "      <td>1.187811</td>\n",
              "      <td>0.809283</td>\n",
              "      <td>0.933947</td>\n",
              "      <td>1.070518</td>\n",
              "      <td>0.974401</td>\n",
              "      <td>0.627058</td>\n",
              "      <td>1.061212</td>\n",
              "      <td>1.345927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 163 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "metric  seed            roc                                                    \\\n",
              "dataset      MagicTelescope kdd_ipums_la_97-small microaggregation2    credit   \n",
              "0        545       0.782412              0.841181          0.595672  0.696735   \n",
              "1        545       0.932046              0.935325          0.755082  0.852535   \n",
              "2        545       0.842083              0.933905          0.689300  0.814789   \n",
              "3        545       0.889420              0.822186          0.759091  0.714959   \n",
              "4        545       0.931711              0.941083          0.749405  0.844759   \n",
              "\n",
              "metric                                                                         \\\n",
              "dataset covertype BNG(anneal,10000,10) Hyperplane_10_1E-4 BNG(anneal,1000,10)   \n",
              "0        0.726597             0.528036           0.763146            0.508719   \n",
              "1        0.875508             0.611405           0.930383            0.541617   \n",
              "2        0.665893             0.515501           0.940687            0.485922   \n",
              "3        0.826003             0.562016           0.940189            0.609052   \n",
              "4        0.881157             0.648699           0.928386            0.593278   \n",
              "\n",
              "metric                           ...  \\\n",
              "dataset BNG(anneal.ORIG,1000,5)  ...   \n",
              "0                      0.512843  ...   \n",
              "1                      0.525379  ...   \n",
              "2                      0.483152  ...   \n",
              "3                      0.513810  ...   \n",
              "4                      0.622719  ...   \n",
              "\n",
              "metric                                        time            \\\n",
              "dataset jungle_chess_2pcs_endgame_panther_elephant     Higgs   \n",
              "0                                         0.355518  0.446817   \n",
              "1                                         1.155980  0.673221   \n",
              "2                                         1.043188  1.027906   \n",
              "3                                         2.208635  6.011692   \n",
              "4                                         0.546699  1.932822   \n",
              "\n",
              "metric                                                           \\\n",
              "dataset BNG(anneal,1000,5)       pol bank-marketing electricity   \n",
              "0                 0.420937  0.215281       0.215589    0.224699   \n",
              "1                 2.052475  0.627228       0.514952    0.527702   \n",
              "2                 1.192532  1.069844       0.952714    0.953843   \n",
              "3                 1.314823  3.000965       0.825624    5.132117   \n",
              "4                 1.187811  0.809283       0.933947    1.070518   \n",
              "\n",
              "metric                                                                   \n",
              "dataset AirlinesCodrnaAdult   phoneme BNG(anneal,5000,10) eye_movements  \n",
              "0                  0.222294  0.323657            0.257108      0.303802  \n",
              "1                  0.569372  0.486907            2.127459      0.604081  \n",
              "2                  1.055812  1.144558            1.275809      1.006918  \n",
              "3                  0.936474  2.120451            1.489000      0.913519  \n",
              "4                  0.974401  0.627058            1.061212      1.345927  \n",
              "\n",
              "[5 rows x 163 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df\n",
        "# for column in columns:\n",
        "#     print(column[0])\n",
        "#     # # concate mini dfs per method\n",
        "#     mini_dfs = []\n",
        "#     for column in columns:\n",
        "#         t_1_df = df[[\"dataset\", column]].copy()\n",
        "#         t_1_df[\"method\"] = column\n",
        "#         t_1_df.columns = [\"Dataset\", f\"{optimization_metric}\", \"method\"]\n",
        "#         mini_dfs.append(t_1_df)\n",
        "#     df = pd.concat(mini_dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2041377/2556087799.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_all_df[new_all_df[\"dataset\"] == dataset][\"hist_gradient_boosting\"] = new_df[new_df[\"dataset\"] == dataset][\"hist_gradient_boosting\"]\n"
          ]
        }
      ],
      "source": [
        "for dataset in new_all_df[\"dataset\"]:\n",
        "    new_all_df[new_all_df[\"dataset\"] == dataset][\"hist_gradient_boosting\"] = new_df[new_df[\"dataset\"] == dataset][\"hist_gradient_boosting\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>method</th>\n",
              "      <th>metric</th>\n",
              "      <th>dataset</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>hist_gradient_boosting</th>\n",
              "      <th>logistic</th>\n",
              "      <th>mlp</th>\n",
              "      <th>rf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>acc</td>\n",
              "      <td>BNG(anneal.ORIG,1000,5)</td>\n",
              "      <td>0.788896</td>\n",
              "      <td>0.860772</td>\n",
              "      <td>0.779876</td>\n",
              "      <td>0.863592</td>\n",
              "      <td>0.855612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acc</td>\n",
              "      <td>BNG(anneal,10000,10)</td>\n",
              "      <td>0.904264</td>\n",
              "      <td>0.949792</td>\n",
              "      <td>0.844164</td>\n",
              "      <td>0.959844</td>\n",
              "      <td>0.939888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acc</td>\n",
              "      <td>BNG(anneal.ORIG,1000,10)</td>\n",
              "      <td>0.702440</td>\n",
              "      <td>0.797880</td>\n",
              "      <td>0.759652</td>\n",
              "      <td>0.802424</td>\n",
              "      <td>0.796516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>acc</td>\n",
              "      <td>microaggregation2</td>\n",
              "      <td>0.504400</td>\n",
              "      <td>0.627800</td>\n",
              "      <td>0.563200</td>\n",
              "      <td>0.630600</td>\n",
              "      <td>0.617800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acc</td>\n",
              "      <td>BNG(anneal,5000,5)</td>\n",
              "      <td>0.903568</td>\n",
              "      <td>0.944952</td>\n",
              "      <td>0.845636</td>\n",
              "      <td>0.958804</td>\n",
              "      <td>0.939572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>acc</td>\n",
              "      <td>BNG(anneal,1000,10)</td>\n",
              "      <td>0.734844</td>\n",
              "      <td>0.833288</td>\n",
              "      <td>0.762644</td>\n",
              "      <td>0.849896</td>\n",
              "      <td>0.806292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>acc</td>\n",
              "      <td>Hyperplane_10_1E-4</td>\n",
              "      <td>0.806580</td>\n",
              "      <td>0.902320</td>\n",
              "      <td>0.910852</td>\n",
              "      <td>0.911668</td>\n",
              "      <td>0.896124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>acc</td>\n",
              "      <td>Hyperplane_10_1E-3</td>\n",
              "      <td>0.604312</td>\n",
              "      <td>0.696092</td>\n",
              "      <td>0.695632</td>\n",
              "      <td>0.698104</td>\n",
              "      <td>0.689192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>acc</td>\n",
              "      <td>BNG(anneal,1000,5)</td>\n",
              "      <td>0.792488</td>\n",
              "      <td>0.867040</td>\n",
              "      <td>0.766548</td>\n",
              "      <td>0.890404</td>\n",
              "      <td>0.848216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>acc</td>\n",
              "      <td>BNG(anneal,5000,10)</td>\n",
              "      <td>0.865968</td>\n",
              "      <td>0.919516</td>\n",
              "      <td>0.815200</td>\n",
              "      <td>0.936140</td>\n",
              "      <td>0.914472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>acc</td>\n",
              "      <td>jungle_chess_2pcs_endgame_panther_elephant</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.920918</td>\n",
              "      <td>0.999150</td>\n",
              "      <td>0.999150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "method metric                                     dataset  decision_tree  \\\n",
              "0         acc                     BNG(anneal.ORIG,1000,5)       0.788896   \n",
              "1         acc                        BNG(anneal,10000,10)       0.904264   \n",
              "2         acc                    BNG(anneal.ORIG,1000,10)       0.702440   \n",
              "3         acc                           microaggregation2       0.504400   \n",
              "4         acc                          BNG(anneal,5000,5)       0.903568   \n",
              "5         acc                         BNG(anneal,1000,10)       0.734844   \n",
              "6         acc                          Hyperplane_10_1E-4       0.806580   \n",
              "7         acc                          Hyperplane_10_1E-3       0.604312   \n",
              "8         acc                          BNG(anneal,1000,5)       0.792488   \n",
              "9         acc                         BNG(anneal,5000,10)       0.865968   \n",
              "10        acc  jungle_chess_2pcs_endgame_panther_elephant       1.000000   \n",
              "\n",
              "method  hist_gradient_boosting  logistic       mlp        rf  \n",
              "0                     0.860772  0.779876  0.863592  0.855612  \n",
              "1                     0.949792  0.844164  0.959844  0.939888  \n",
              "2                     0.797880  0.759652  0.802424  0.796516  \n",
              "3                     0.627800  0.563200  0.630600  0.617800  \n",
              "4                     0.944952  0.845636  0.958804  0.939572  \n",
              "5                     0.833288  0.762644  0.849896  0.806292  \n",
              "6                     0.902320  0.910852  0.911668  0.896124  \n",
              "7                     0.696092  0.695632  0.698104  0.689192  \n",
              "8                     0.867040  0.766548  0.890404  0.848216  \n",
              "9                     0.919516  0.815200  0.936140  0.914472  \n",
              "10                    1.000000  0.920918  0.999150  0.999150  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_all_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_df = new_df.reset_index().drop([\"metric\", \"index\"], axis=1)\n",
        "\n",
        "# plot_df = plot_df.replace({})\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>method</th>\n",
              "      <th>dataset</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>hist_gradient_boosting</th>\n",
              "      <th>logistic</th>\n",
              "      <th>mlp</th>\n",
              "      <th>rf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BNG(anneal.ORIG,1000,5)</td>\n",
              "      <td>0.788896</td>\n",
              "      <td>0.860772</td>\n",
              "      <td>0.779876</td>\n",
              "      <td>0.863592</td>\n",
              "      <td>0.855612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BNG(anneal,10000,10)</td>\n",
              "      <td>0.904264</td>\n",
              "      <td>0.949792</td>\n",
              "      <td>0.844164</td>\n",
              "      <td>0.959844</td>\n",
              "      <td>0.939888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BNG(anneal.ORIG,1000,10)</td>\n",
              "      <td>0.702440</td>\n",
              "      <td>0.797880</td>\n",
              "      <td>0.759652</td>\n",
              "      <td>0.802424</td>\n",
              "      <td>0.796516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>microaggregation2</td>\n",
              "      <td>0.504400</td>\n",
              "      <td>0.627800</td>\n",
              "      <td>0.563200</td>\n",
              "      <td>0.630600</td>\n",
              "      <td>0.617800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BNG(anneal,5000,5)</td>\n",
              "      <td>0.903568</td>\n",
              "      <td>0.944952</td>\n",
              "      <td>0.845636</td>\n",
              "      <td>0.958804</td>\n",
              "      <td>0.939572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BNG(anneal,1000,10)</td>\n",
              "      <td>0.734844</td>\n",
              "      <td>0.833288</td>\n",
              "      <td>0.762644</td>\n",
              "      <td>0.849896</td>\n",
              "      <td>0.806292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hyperplane_10_1E-4</td>\n",
              "      <td>0.806580</td>\n",
              "      <td>0.902320</td>\n",
              "      <td>0.910852</td>\n",
              "      <td>0.911668</td>\n",
              "      <td>0.896124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hyperplane_10_1E-3</td>\n",
              "      <td>0.604312</td>\n",
              "      <td>0.696092</td>\n",
              "      <td>0.695632</td>\n",
              "      <td>0.698104</td>\n",
              "      <td>0.689192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BNG(anneal,1000,5)</td>\n",
              "      <td>0.792488</td>\n",
              "      <td>0.867040</td>\n",
              "      <td>0.766548</td>\n",
              "      <td>0.890404</td>\n",
              "      <td>0.848216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BNG(anneal,5000,10)</td>\n",
              "      <td>0.865968</td>\n",
              "      <td>0.919516</td>\n",
              "      <td>0.815200</td>\n",
              "      <td>0.936140</td>\n",
              "      <td>0.914472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>jungle_chess_2pcs_endgame_panther_elephant</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.920918</td>\n",
              "      <td>0.999150</td>\n",
              "      <td>0.999150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "method                                     dataset  decision_tree  \\\n",
              "0                          BNG(anneal.ORIG,1000,5)       0.788896   \n",
              "1                             BNG(anneal,10000,10)       0.904264   \n",
              "2                         BNG(anneal.ORIG,1000,10)       0.702440   \n",
              "3                                microaggregation2       0.504400   \n",
              "4                               BNG(anneal,5000,5)       0.903568   \n",
              "5                              BNG(anneal,1000,10)       0.734844   \n",
              "6                               Hyperplane_10_1E-4       0.806580   \n",
              "7                               Hyperplane_10_1E-3       0.604312   \n",
              "8                               BNG(anneal,1000,5)       0.792488   \n",
              "9                              BNG(anneal,5000,10)       0.865968   \n",
              "10      jungle_chess_2pcs_endgame_panther_elephant       1.000000   \n",
              "\n",
              "method  hist_gradient_boosting  logistic       mlp        rf  \n",
              "0                     0.860772  0.779876  0.863592  0.855612  \n",
              "1                     0.949792  0.844164  0.959844  0.939888  \n",
              "2                     0.797880  0.759652  0.802424  0.796516  \n",
              "3                     0.627800  0.563200  0.630600  0.617800  \n",
              "4                     0.944952  0.845636  0.958804  0.939572  \n",
              "5                     0.833288  0.762644  0.849896  0.806292  \n",
              "6                     0.902320  0.910852  0.911668  0.896124  \n",
              "7                     0.696092  0.695632  0.698104  0.689192  \n",
              "8                     0.867040  0.766548  0.890404  0.848216  \n",
              "9                     0.919516  0.815200  0.936140  0.914472  \n",
              "10                    1.000000  0.920918  0.999150  0.999150  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1850x1050 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "methods = [\"rf\", \"mlp\", \"hist_gradient_boosting\", \"decision_tree\", \"logistic\"]\n",
        "colors = [\"red\", \"green\", \"brown\", \"blue\", \"yellow\"]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "\n",
        "for i, method in enumerate(methods):\n",
        "    plot_df.plot(kind=\"scatter\", x=\"dataset\", y=method, label=method, ax=ax, color=colors[i]) #.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperplane_10_1E-3\n",
            "Hyperplane_10_1E-4\n",
            "AirlinesCodrnaAdult\n",
            "BNG(anneal,1000,5)\n",
            "BNG(anneal,1000,10)\n",
            "BNG(anneal,5000,5)\n",
            "BNG(anneal,5000,10)\n",
            "BNG(anneal,10000,10)\n",
            "BNG(anneal.ORIG,1000,5)\n",
            "BNG(anneal.ORIG,1000,10)\n",
            "jungle_chess_2pcs_endgame_panther_elephant\n",
            "microaggregation2\n"
          ]
        }
      ],
      "source": [
        "all_dataset_ids_numerical = [\n",
        "    # 41986, 41988, 41989, 1053, 40996, 40997, 4134, 41000, 554, 41002, 44, 1590, 44089, 44090, 44091, 60, 1596, 41039, 1110, 44120, 1113, 44121, 44122, 44123, 44124, 44125, 1119, 44126, 44127, 44128, 44129, 44130, 44131, 150, 152, 153, 1181, 159, 160, 1183, 1185, 180, 1205, 182, 1209, 41146, 41147, 1212, 1214, 1216, 1218, 1219, 1222, 41671, 41162, 1226, 41163, 41164, 41166, 720, 41168, 41169, 725, 1240, 1241, 1242, 734, 735, 42206, 737, 40685, 246, 42742, 761, 250, 251, 252, 42746, 254, 42750, 256, 257, 258, 261, 266, 267, 269, 271, 279, 803, 816, 819, 823, 833, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 846, 847, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1368, 351, 357, 871, 42343, 1393, 1394, 1395, 42395, 4541, 42435, 1476, 1477, 1478, 1486, 976, 979, 40923, 23517, 1503, 43489, 1507, 42468, 42477, 41972, 1526, 41982\n",
        "    # 44, 152, 153, 251, 256, 267, 269, 351, 357, 720, 725, 734, 735, 737, 761, 803, 816, 819, 823, 833, 846, 847, 871, 976, 979, 1053, 1119, 1240, 1241, 1242, 1486, 1507, 1590, 4134, 23517, 41146, 41147, 41162, 42206, 42343, 42395, 42435, 42477, 42742, 60, 150, 159, 160, 180, 182, 250, 252, 254, 261, 266, 271, 279, 554, 1110, 1113, 1183, 1185, 1209, 1214, 1222, 1226, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1368, 1393, 1394, 1395, 1476, 1477, 1478, 1503, 1526, 1596, 4541, 40685, 40923, 40996, 40997, 41000, 41002, 41039, 41163, 41164, 41166, 41168, 41169, 41671, 41972, 41982, 41986, 41988, 41989, 42468, 42746, 44089, 44090, 44091, 44120, 44121, 44122, 44123, 44124, 44125, 44126, 44127, 44128, 44129, 44130, 44131\n",
        "    152, 153, 1240, 1352, 1353, 1355, 1356, 1359, 1361, 1362, 41000, 41671\n",
        "]\n",
        "for task_id in all_dataset_ids_numerical:\n",
        "    # print(f\"Running {task_id}\")\n",
        "    try:\n",
        "        dataset = openml.datasets.get_dataset(task_id, download_data=False)\n",
        "        print(dataset.name)\n",
        "    except Exception as e:\n",
        "        print(repr(e))\n",
        "        continue\n",
        "    # print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[44127,\n",
              " 737,\n",
              " 871,\n",
              " 1526,\n",
              " 44091,\n",
              " 720,\n",
              " 803,\n",
              " 923,\n",
              " 44160,\n",
              " 819,\n",
              " 725,\n",
              " 816,\n",
              " 42192,\n",
              " 42193,\n",
              " 43892,\n",
              " 44126,\n",
              " 847,\n",
              " 735,\n",
              " 41146,\n",
              " 44124,\n",
              " 43607,\n",
              " 1568,\n",
              " 26,\n",
              " 959,\n",
              " 43923,\n",
              " 43938,\n",
              " 44125,\n",
              " 976,\n",
              " 1507,\n",
              " 44130,\n",
              " 761,\n",
              " 44157,\n",
              " 44089,\n",
              " 44090,\n",
              " 823,\n",
              " 24,\n",
              " 43922,\n",
              " 60,\n",
              " 979,\n",
              " 42493,\n",
              " 40997,\n",
              " 40998,\n",
              " 41000,\n",
              " 43904,\n",
              " 44123,\n",
              " 182,\n",
              " 1053,\n",
              " 43890,\n",
              " 44186,\n",
              " 44,\n",
              " 833,\n",
              " 44122,\n",
              " 41002,\n",
              " 41003,\n",
              " 41006,\n",
              " 44162,\n",
              " 44120,\n",
              " 846,\n",
              " 1222,\n",
              " 4534,\n",
              " 44156,\n",
              " 251,\n",
              " 41671,\n",
              " 993,\n",
              " 881,\n",
              " 1119,\n",
              " 734,\n",
              " 40685,\n",
              " 981,\n",
              " 43920,\n",
              " 42477,\n",
              " 43898,\n",
              " 179,\n",
              " 1590,\n",
              " 1461,\n",
              " 41440,\n",
              " 42734,\n",
              " 43439,\n",
              " 42345,\n",
              " 1476,\n",
              " 1477,\n",
              " 41169,\n",
              " 41972,\n",
              " 23517,\n",
              " 43903,\n",
              " 43044,\n",
              " 41162,\n",
              " 40672,\n",
              " 44131,\n",
              " 279,\n",
              " 44161,\n",
              " 44128,\n",
              " 42344,\n",
              " 1503,\n",
              " 1486,\n",
              " 1169,\n",
              " 41672,\n",
              " 351,\n",
              " 1241,\n",
              " 350,\n",
              " 41168,\n",
              " 1219,\n",
              " 4541,\n",
              " 1478,\n",
              " 180,\n",
              " 44121,\n",
              " 41164,\n",
              " 4134,\n",
              " 1226,\n",
              " 42750,\n",
              " 357,\n",
              " 1242,\n",
              " 41166,\n",
              " 152,\n",
              " 153,\n",
              " 159,\n",
              " 160,\n",
              " 1112,\n",
              " 1209,\n",
              " 266,\n",
              " 267,\n",
              " 1185,\n",
              " 42468,\n",
              " 1216,\n",
              " 1205,\n",
              " 1214,\n",
              " 43489,\n",
              " 258,\n",
              " 246,\n",
              " 261,\n",
              " 42732,\n",
              " 269,\n",
              " 41163,\n",
              " 1113,\n",
              " 42206,\n",
              " 257,\n",
              " 44159,\n",
              " 44129,\n",
              " 1218,\n",
              " 154,\n",
              " 1393,\n",
              " 1394,\n",
              " 1395,\n",
              " 256,\n",
              " 150,\n",
              " 1596,\n",
              " 1240,\n",
              " 41147,\n",
              " 42742,\n",
              " 1183,\n",
              " 1351,\n",
              " 1352,\n",
              " 1353,\n",
              " 1354,\n",
              " 1355,\n",
              " 1356,\n",
              " 1357,\n",
              " 1358,\n",
              " 1359,\n",
              " 1360,\n",
              " 1361,\n",
              " 1362,\n",
              " 1363,\n",
              " 1364,\n",
              " 1365,\n",
              " 1366,\n",
              " 1368,\n",
              " 42343,\n",
              " 42395,\n",
              " 42435,\n",
              " 271,\n",
              " 1181,\n",
              " 1212,\n",
              " 254,\n",
              " 554,\n",
              " 40996,\n",
              " 41982,\n",
              " 252,\n",
              " 42132,\n",
              " 250,\n",
              " 41986,\n",
              " 41988,\n",
              " 40923,\n",
              " 41039,\n",
              " 41989,\n",
              " 1110,\n",
              " 42746,\n",
              " 40517,\n",
              " 274]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "all_dataset_ids_numerical = [\n",
        "    41986, 41988, 41989, 1053, 40996, 40997, 4134, 41000, 554, 41002, 44, 1590, 44089, 44090, 44091, 60, 1596, 41039, 1110, 44120, 1113, 44121, 44122, 44123, 44124, 44125, 1119, 44126, 44127, 44128, 44129, 44130, 44131, 150, 152, 153, 1181, 159, 160, 1183, 1185, 180, 1205, 182, 1209, 41146, 41147, 1212, 1214, 1216, 1218, 1219, 1222, 41671, 41162, 1226, 41163, 41164, 41166, 720, 41168, 41169, 725, 1240, 1241, 1242, 734, 735, 42206, 737, 40685, 246, 42742, 761, 250, 251, 252, 42746, 254, 42750, 256, 257, 258, 261, 266, 267, 269, 271, 279, 803, 816, 819, 823, 833, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 846, 847, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1368, 351, 357, 871, 42343, 1393, 1394, 1395, 42395, 4541, 42435, 1476, 1477, 1478, 1486, 976, 979, 40923, 23517, 1503, 43489, 1507, 42468, 42477, 41972, 1526, 41982\n",
        "]\n",
        "all_dataset_ids_categorical = [\n",
        "    24, 26, 154, 179, 274, 350, 720, 881, 923, 959, 981, 993, 1110, 1112, 1113, 1119, 1169, 1240, 1461, 1486, 1503, 1568, 1590, 4534, 4541, 40517, 40672, 40997, 40998, 41000, 41002, 41003, 41006, 41147, 41162, 41440, 41672, 42132, 42192, 42193, 42206, 42343, 42344, 42345, 42477, 42493, 42732, 42734, 42742, 42746, 42750, 43044, 43439, 43489, 43607, 43890, 43892, 43898, 43903, 43904, 43920, 43922, 43923, 43938, 44156, 44157, 44159, 44160, 44161, 44162, 44186\n",
        "]\n",
        "openml_list = openml.datasets.list_datasets(all_dataset_ids_numerical + all_dataset_ids_categorical)\n",
        "\n",
        "sorted(openml_list, key= lambda d: openml_list[d][\"NumberOfInstances\"] * openml_list[d][\"NumberOfFeatures\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44089\n",
            "44090\n",
            "44091\n",
            "44120\n",
            "44121\n",
            "44122\n",
            "44123\n",
            "44124\n",
            "44125\n",
            "44126\n",
            "44127\n",
            "44128\n",
            "44129\n",
            "44130\n",
            "44131\n",
            "\n",
            "\n",
            " Starting suite 2\n",
            "44156\n",
            "44157\n",
            "44159\n",
            "44160\n",
            "44161\n",
            "44162\n",
            "44186\n"
          ]
        }
      ],
      "source": [
        "import openml\n",
        "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
        "# SUITE_ID = 297 # Regression on numerical features\n",
        "SUITE_ID_1 = 298 # Classification on numerical features\n",
        "#SUITE_ID = 299 # Regression on numerical and categorical features\n",
        "SUITE_ID_2 = 304 # Classification on numerical and categorical features\n",
        "benchmark_suite = openml.study.get_suite(SUITE_ID_1)  # obtain the benchmark suite\n",
        "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
        "    task = openml.tasks.get_task(task_id, download_data=False)  # download the OpenML task\n",
        "    # dataset = openml.datasets.get_dataset(dataset_id=task.dataset_id)\n",
        "    print(task.dataset_id)\n",
        "print(\"\\n\\n Starting suite 2\")\n",
        "benchmark_suite = openml.study.get_suite(SUITE_ID_2)  # obtain the benchmark suite\n",
        "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
        "    task = openml.tasks.get_task(task_id, download_data=False)  # download the OpenML task\n",
        "    # dataset = openml.datasets.get_dataset(dataset_id=task.dataset_id)\n",
        "    print(task.dataset_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gf26oXt_ZSlH",
        "outputId": "9b1d2aeb-58fe-4ab9-e164-2e43ff917a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving objects:  24% (130/531), 53.82 MiB | 6.02 MiB/s\r"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/automl/TabPFN \n",
        "!cd TabPFN; git checkout b6e817b017595675c32a756d1b2fb352a8e800c0\n",
        "!pip install \"./TabPFN\"\n",
        "# !pip install -r TabPFN/requirements.txt\n",
        "# !git clone https://github.com/noahho/TabPFNResults\n",
        "# !cd TabPFNResults; git checkout c40dc9ff41aa345c1a355ca2e32e06eee534eb82 \n",
        "!pip install -U torchmetrics seaborn matplotlib\n",
        "raise Exception(\"restart the notebook please\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2BDPDmxZ7zN"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1DghTkraHxL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "wYrkJhfOaN1N"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "import pickle\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from itertools import chain, product\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "from typing import Callable, Iterable, Sequence\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.transforms as mtransforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "import tabpfn.scripts.tabular_baselines as tb\n",
        "from tabpfn.datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
        "from tabpfn.scripts.tabular_baselines import clf_dict\n",
        "from tabpfn.scripts.tabular_evaluation import evaluate\n",
        "from tabpfn.scripts.tabular_metrics import (accuracy_metric, auc_metric,\n",
        "                                            brier_score_metric,\n",
        "                                            calculate_score, cross_entropy,\n",
        "                                            ece_metric, time_metric)\n",
        "\n",
        "from submitit import SlurmExecutor, AutoExecutor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEKwmB9paRSy"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "OZcZ4tY5aYgl"
      },
      "outputs": [],
      "source": [
        "HERE = Path(\".\").resolve().absolute()\n",
        "\n",
        "METRICS = {\n",
        "    \"roc\": auc_metric,\n",
        "    \"cross_entropy\": cross_entropy,\n",
        "    \"acc\": accuracy_metric,\n",
        "    \"brier_score\": brier_score_metric,\n",
        "    \"ece\": ece_metric,\n",
        "}\n",
        "\n",
        "PREDEFINED_RESULTS_PATH = Path(\"/work/dlclarge1/rkohli-results_tabpfn_180/\") # HERE / \"TabPFNResults\" / \"all_results\"\n",
        "PREDFINED_DATASET_PATHS = HERE / \"tabpfn\" / \"datasets\" # / \"TabPFN\" \n",
        "PREDEFINED_DATASET_COLLECTIONS = {\n",
        "    \"cc_valid\": {\n",
        "        \"ids\": open_cc_valid_dids,\n",
        "        \"path\": PREDFINED_DATASET_PATHS / \"cc_valid_datasets_multiclass.pickle\",\n",
        "    },\n",
        "    \"cc_test\": {\n",
        "        \"ids\": open_cc_dids,\n",
        "        \"path\": PREDFINED_DATASET_PATHS / \"cc_test_datasets_multiclass.pickle\",\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "LABEL_NAMES = {\n",
        "    \"transformer\": \"TabPFN\",\n",
        "    \"transformer_gpu_N_1\": \"TabPFN GPU (N_ens =  1)\",\n",
        "    \"transformer_gpu_N_4\": \"TabPFN GPU (N_ens =  4)\",\n",
        "    \"transformer_gpu_N_8\": \"TabPFN GPU (N_ens =  8)\",\n",
        "    \"transformer_gpu_N_32\": \"TabPFN GPU (N_ens = 32)\",\n",
        "    \"transformer_cpu_N_1\": \"TabPFN CPU (N_ens =  1)\",\n",
        "    \"transformer_cpu_N_4\": \"TabPFN CPU (N_ens =  4)\",\n",
        "    \"transformer_cpu_N_8\": \"TabPFN CPU (N_ens =  8)\",\n",
        "    \"transformer_cpu_N_32\": \"TabPFN CPU (N_ens = 32)\",\n",
        "    \"autogluon\": \"Autogluon\",\n",
        "    \"autosklearn2\": \"Autosklearn2\",\n",
        "    \"gp_default\": \"default GP (RBF)\",\n",
        "    \"gradient_boosting\": \"tuned Grad. Boost.\",\n",
        "    \"gradient_boosting_default\": \"default Grad. Boost.\",\n",
        "    \"lightgbm\": \"tuned LGBM\",\n",
        "    \"lightgbm_default\": \"default LGBM\",\n",
        "    \"gp\": \"tuned GP (RBF)\",\n",
        "    \"logistic\": \"tuned Log. Regr.\",\n",
        "    \"knn\": \"tuned KNN\",\n",
        "    \"catboost\": \"tuned Catboost\",\n",
        "    \"catboost_default\": \"default Catboost\",\n",
        "    \"xgb\": \"tuned XGB\",\n",
        "    \"xgb_default\": \"default XGB\",\n",
        "    \"catboost_gpu\": \"tuned Catboost (GPU)\",\n",
        "    \"catboost_default_gpu\": \"default Catboost (GPU)\",\n",
        "    \"xgb_gpu\": \"tuned XGB (GPU)\",\n",
        "    \"xgb_default_gpu\": \"default XGB (GPU)\",\n",
        "    \"svm\": \"tuned SVM\",\n",
        "    \"svm_default\": \"default SVM\",\n",
        "    \"random_forest\": \"tuned Random Forest\",\n",
        "    \"rf_default_n_estimators_10\": \"Rand. Forest (N_est =  10)\",\n",
        "    \"rf_default_n_estimators_32\": \"Rand. Forest (N_est =  32)\",\n",
        "    \"rf_default\": \"Rand. Forest (N_est = 100)\",\n",
        "    \"autogluon\": \"AutoGluon\",\n",
        "    \"autosklearn\": \"AutoSklearn\"\n",
        "}\n",
        "FAMILY_NAMES = {\n",
        "    \"gp\": \"GP\",\n",
        "    \"knn\": \"KNN\",\n",
        "    \"lightgbm\": \"LGBM\",\n",
        "    \"logistic\": \"Log. Regr.\",\n",
        "    \"rf\": \"RF\",\n",
        "    \"svm\": \"SVM\",\n",
        "    \"transformer_cpu\": \"TabPFN CPU\",\n",
        "    \"transformer_gpu\": \"TabPFN GPU\",\n",
        "    \"xgb\": \"XGB CPU\",\n",
        "    \"xgb_gpu\": \"XGB GPU\",\n",
        "    \"catboost\": \"CatBoost CPU\",\n",
        "    \"catboost_gpu\": \"CatBoost GPU\",\n",
        "    \"autogluon\": \"AutoGluon\",\n",
        "    \"autosklearn\": \"AutoSklearn\",\n",
        "    \"autosklearn2\": \"AutoSklearn2\",\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1yWWRsHaySz"
      },
      "source": [
        "# Available Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HH75JAQ6a1WI"
      },
      "outputs": [],
      "source": [
        "# Predefined methods with `no_tune={}` inidicating they are not tuned\n",
        "METHODS = {\n",
        "    # svm\n",
        "    \"svm\": tb.svm_metric,\n",
        "    \"svm_default\": partial(tb.svm_metric, no_tune={}),\n",
        "    # # gradient boosting\n",
        "    # \"gradient_boosting\": tb.gradient_boosting_metric,\n",
        "    \"gradient_boosting_default\": partial(tb.gradient_boosting_metric, no_tune={}),\n",
        "    # gp\n",
        "    \"gp\": clf_dict[\"gp\"],\n",
        "    \"gp_default\": partial(\n",
        "        clf_dict[\"gp\"],\n",
        "        no_tune={\"params_y_scale\": 0.1, \"params_length_scale\": 0.1},\n",
        "    ),\n",
        "    # autogluon\n",
        "    \"autogluon\": clf_dict[\"autogluon\"],\n",
        "    # autosklearn\n",
        "    # \"autosklearn\": clf_dict[\"autosklearn\"],\n",
        "    # lightgbm\n",
        "    \"lightgbm\": clf_dict[\"lightgbm\"],\n",
        "    \"lightgbm_default\": partial(clf_dict[\"lightgbm\"], no_tune={}),\n",
        "    # catboost\n",
        "    \"catboost\": clf_dict[\"catboost\"],\n",
        "    \"catboost_default\": partial(clf_dict[\"catboost\"], no_tune={}),\n",
        "    # \"catboost_gpu\": partial(clf_dict[\"catboost\"], gpu_id=0),\n",
        "    # \"catboost_default_gpu\": partial(clf_dict[\"catboost\"], no_tune={}, gpu_id=0),\n",
        "    # xgb\n",
        "    \"xgb\": clf_dict[\"xgb\"],\n",
        "    \"xgb_default\": partial(clf_dict[\"xgb\"], no_tune={}),\n",
        "    \"xgb_gpu\": partial(clf_dict[\"xgb\"], gpu_id=0),\n",
        "    \"xgb_default_gpu\": partial(clf_dict[\"xgb\"], gpu_id=0, no_tune={}),\n",
        "    # random forest\n",
        "    \"random_forest\": clf_dict[\"random_forest\"],\n",
        "    \"rf_default\": partial(clf_dict[\"random_forest\"], no_tune={}),\n",
        "    \"rf_default_n_estimators_10\": partial(\n",
        "        clf_dict[\"random_forest\"], no_tune={\"n_estimators\": 10}\n",
        "    ),\n",
        "    \"rf_default_n_estimators_32\": partial(\n",
        "        clf_dict[\"random_forest\"], no_tune={\"n_estimators\": 32}\n",
        "    ),\n",
        "    # knn\n",
        "    \"knn\": clf_dict[\"knn\"],\n",
        "    # logistic classification\n",
        "    \"logistic\": clf_dict[\"logistic\"],\n",
        "    # Transformers\n",
        "    \"transformer_cpu_N_1\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cpu\", N_ensemble_configurations=1\n",
        "    ),\n",
        "    \"transformer_cpu_N_4\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cpu\", N_ensemble_configurations=4\n",
        "    ),\n",
        "    \"transformer_cpu_N_8\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cpu\", N_ensemble_configurations=8\n",
        "    ),\n",
        "    \"transformer_cpu_N_32\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cpu\", N_ensemble_configurations=32\n",
        "    ),\n",
        "    \"transformer_gpu_N_1\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cuda\", N_ensemble_configurations=1\n",
        "    ),\n",
        "    \"transformer_gpu_N_4\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cuda\", N_ensemble_configurations=4\n",
        "    ),\n",
        "    \"transformer_gpu_N_8\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cuda\", N_ensemble_configurations=8\n",
        "    ),\n",
        "    \"transformer_gpu_N_32\": partial(\n",
        "        clf_dict[\"transformer\"], device=\"cuda\", N_ensemble_configurations=32\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGvNN4magua"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo8L6DUDa-4t"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "fsgEIwmNa-B3"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Dataset:\n",
        "    \"\"\"Small helper class just to name entries in the loaded pickled datasets.\"\"\"\n",
        "\n",
        "    name: str\n",
        "    X: torch.Tensor\n",
        "    y: torch.Tensor\n",
        "    categorical_columns: list[int]\n",
        "    attribute_names: list[str]\n",
        "    # Seems to be some things about how the dataset was constructed\n",
        "    info: dict\n",
        "    # Only 'multiclass' is known?\n",
        "    task_type: str\n",
        "\n",
        "    @property\n",
        "    def categorical(self) -> bool:\n",
        "        return len(self.categorical_columns) == len(self.attribute_names)\n",
        "\n",
        "    @property\n",
        "    def numerical(self) -> bool:\n",
        "        return len(self.categorical_columns) == 0\n",
        "\n",
        "    @property\n",
        "    def mixed(self) -> bool:\n",
        "        return not self.numerical and not self.categorical\n",
        "\n",
        "    @classmethod\n",
        "    def fetch(\n",
        "        self,\n",
        "        identifier: str | int | list[int],\n",
        "        only: Callable | None = None,\n",
        "    ) -> list[Dataset]:\n",
        "        if isinstance(identifier, str) and identifier in PREDEFINED_DATASET_COLLECTIONS:\n",
        "            datasets = Dataset.from_predefined(identifier)\n",
        "        elif isinstance(identifier, int):\n",
        "            identifier = [identifier]\n",
        "            datasets = Dataset.from_openml(identifier)\n",
        "        elif isinstance(identifier, list):\n",
        "            datasets = Dataset.from_openml(identifier)\n",
        "        else:\n",
        "            raise ValueError(identifier)\n",
        "\n",
        "        if only:\n",
        "            return list(filter(only, datasets))\n",
        "        else:\n",
        "            return datasets\n",
        "\n",
        "    @classmethod\n",
        "    def from_pickle(self, path: Path, task_types: str) -> list[Dataset]:\n",
        "        with path.open(\"rb\") as f:\n",
        "            raw = pickle.load(f)\n",
        "\n",
        "        return [Dataset(*entry, task_type=task_types) for entry in raw]  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def from_predefined(self, name: str) -> list[Dataset]:\n",
        "        assert name in PREDEFINED_DATASET_COLLECTIONS\n",
        "        path = PREDEFINED_DATASET_COLLECTIONS[name][\"path\"]\n",
        "\n",
        "        return Dataset.from_pickle(path, task_types=\"multiclass\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_openml(\n",
        "        self,\n",
        "        dataset_id: int | list[int],\n",
        "        filter_for_nan: bool = False,\n",
        "        min_samples: int = 100,\n",
        "        max_samples: int = 2_000,\n",
        "        num_feats: int = 100,\n",
        "        return_capped: bool = False,\n",
        "        shuffled: bool = True,\n",
        "        multiclass: bool = True,\n",
        "    ) -> list[Dataset]:\n",
        "        # TODO: should be parametrized, defaults taken from ipy notebook\n",
        "        if not isinstance(dataset_id, list):\n",
        "            dataset_id = [dataset_id]\n",
        "\n",
        "        datasets, _ = load_openml_list(\n",
        "            dataset_id,\n",
        "            filter_for_nan=filter_for_nan,\n",
        "            num_feats=num_feats,\n",
        "            min_samples=min_samples,\n",
        "            max_samples=max_samples,\n",
        "            return_capped=return_capped,\n",
        "            shuffled=shuffled,\n",
        "            multiclass=multiclass,\n",
        "        )\n",
        "        return [\n",
        "            Dataset(  # type: ignore\n",
        "                *entry,\n",
        "                task_type=\"multiclass\" if multiclass else \"binary\",\n",
        "            )\n",
        "            for entry in datasets\n",
        "        ]\n",
        "\n",
        "    def as_list(self) -> list:\n",
        "        \"\"\"How the internals expect a dataset to look like.\"\"\"\n",
        "        return [\n",
        "            self.name,\n",
        "            self.X,\n",
        "            self.y,\n",
        "            self.categorical_columns,\n",
        "            self.attribute_names,\n",
        "            self.info,\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn9O2_qVbOQT"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yd3mucXybZAd"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Results:\n",
        "    # Big ass predefined dictionary\n",
        "    df: pd.DataFrame\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(\n",
        "        self,\n",
        "        d: dict,\n",
        "        datasets: list[Dataset],\n",
        "        recorded_metrics: list[str],\n",
        "        *,\n",
        "        dropna: bool = True,\n",
        "    ) -> Results:\n",
        "        # TODO: we could extract dataset_names for the dict but it's not ordered well\n",
        "        #   for that. Likewise for the recorded_metrics\n",
        "        #\n",
        "        # We do a lot of parsing here to massage things into a nice table\n",
        "        # Extract all the times listed in the keys\n",
        "        pattern = re.compile(\n",
        "            r\"(?P<method>\\w+)\"\n",
        "            r\"_time_(?P<time>\\d+(\\.\\d+)?)\"\n",
        "            r\"(_)?(?P<metric>\\w+)\"\n",
        "            r\"_split_(?P<split>\\d+)\"\n",
        "        )\n",
        "\n",
        "        groups = []\n",
        "        for key in d:\n",
        "            match = re.match(pattern, key)\n",
        "            if not match:\n",
        "                raise ValueError(key)\n",
        "\n",
        "            groups.append(match.groupdict())\n",
        "\n",
        "        matches = pd.DataFrame(groups)\n",
        "\n",
        "        # The unique, methods, times, metrics and splits present\n",
        "        methods = list(matches[\"method\"].unique())\n",
        "        times = list(matches[\"time\"].astype(float).unique())\n",
        "        metrics = list(matches[\"metric\"].unique())\n",
        "        splits = list(matches[\"split\"].astype(int).unique())\n",
        "\n",
        "        # Next we extract all the eval_positions\n",
        "        _eval_positions = set()\n",
        "        for v in d.values():\n",
        "            _eval_positions.update(v[\"eval_positions\"])\n",
        "        eval_positions = sorted(_eval_positions)\n",
        "\n",
        "        # Dataset names...\n",
        "        dataset_names = sorted([d.name for d in datasets])\n",
        "\n",
        "        # We flatten out the fit_time and inference_time of best_config\n",
        "        for (k, v), pos, dataset in product(d.items(), eval_positions, datasets):\n",
        "            old_best_configs_key = f\"{dataset.name}_best_configs_at_{pos}\"\n",
        "\n",
        "            best_config_key = f\"{dataset.name}_best_config\"\n",
        "            inference_time_key = f\"{dataset.name}_inference_time_at_{pos}\"\n",
        "            fit_time_key = f\"{dataset.name}_fit_time_at_{pos}\"\n",
        "\n",
        "            # If there is a best config\n",
        "            if any(v.get(old_best_configs_key, [])):\n",
        "                assert len(v[old_best_configs_key]) == 1\n",
        "\n",
        "                best_config = v[old_best_configs_key][0]\n",
        "\n",
        "                v[inference_time_key] = best_config.get(\"inference_time\", np.nan)\n",
        "                v[fit_time_key] = best_config.get(\"fit_time\", np.nan)\n",
        "                v[best_config_key] = best_config.copy()\n",
        "                del v[old_best_configs_key]\n",
        "            else:\n",
        "                v[inference_time_key] = np.nan\n",
        "                v[fit_time_key] = np.nan\n",
        "                v[best_config_key] = np.nan\n",
        "\n",
        "        index = pd.MultiIndex.from_product(\n",
        "            [methods, metrics, times, eval_positions, splits],\n",
        "            names=[\n",
        "                \"method\",\n",
        "                \"optimization_metric\",\n",
        "                \"optimization_time\",\n",
        "                \"eval_position\",\n",
        "                \"split\",\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        metrics = recorded_metrics + [\"time\", \"inference_time\", \"fit_time\"]\n",
        "        columns = pd.MultiIndex.from_product(\n",
        "            [metrics, dataset_names],\n",
        "            names=[\"metric\", \"dataset\"],\n",
        "        )\n",
        "\n",
        "        df = pd.DataFrame(columns=columns, index=index)\n",
        "        df.sort_index(inplace=True)\n",
        "\n",
        "        for k, v in d.items():\n",
        "            match = re.match(pattern, k)\n",
        "            if match is None:\n",
        "                raise ValueError(k)\n",
        "\n",
        "            method = match.group(\"method\")\n",
        "            time = float(match.group(\"time\"))\n",
        "            opt_metric = match.group(\"metric\")\n",
        "            split = int(match.group(\"split\"))\n",
        "\n",
        "            for dataset, metric, pos in product(dataset_names, metrics, eval_positions):\n",
        "                row = (method, opt_metric, time, int(pos), split)\n",
        "                col = (metric, dataset)\n",
        "\n",
        "                value = v.get(f\"{dataset}_{metric}_at_{pos}\", np.nan)\n",
        "\n",
        "                df.loc[row, col] = value\n",
        "\n",
        "        # Drop full NaN rows\n",
        "        if dropna:\n",
        "            df = df[df.any(axis=1)]\n",
        "\n",
        "        return Results(df)\n",
        "\n",
        "    def at(\n",
        "        self,\n",
        "        *,\n",
        "        method: str | list[str] | None = None,\n",
        "        optimization_metric: str | list[str] | None = None,\n",
        "        optimization_time: float | list[float] | None = None,\n",
        "        split: int | list[int] | None = None,\n",
        "        eval_position: int | list[int] | None = None,\n",
        "        dataset: str | list[str] | None = None,\n",
        "        metric: str | list[str] | None = None,\n",
        "    ) -> Results:\n",
        "        \"\"\"Use this for slicing in to the dataframe to get what you need\"\"\"\n",
        "        df = self.df\n",
        "        items = {\n",
        "            \"method\": method,\n",
        "            \"optimization_time\": optimization_time,\n",
        "            \"optimization_metric\": optimization_metric,\n",
        "            \"split\": split,\n",
        "            \"eval_position\": eval_position,\n",
        "        }\n",
        "        for name, item in items.items():\n",
        "            if item is None:\n",
        "                continue\n",
        "            idx: list = item if isinstance(item, list) else [item]\n",
        "            df = df[df.index.get_level_values(name).isin(idx)]\n",
        "            if not isinstance(item, list):\n",
        "                df = df.droplevel(name, axis=\"index\")\n",
        "\n",
        "        if dataset:\n",
        "            _dataset = dataset if isinstance(dataset, list) else [dataset]\n",
        "            df = df.T.loc[df.T.index.get_level_values(\"dataset\").isin(_dataset)].T\n",
        "            if not isinstance(dataset, list):\n",
        "                df = df.droplevel(\"dataset\", axis=\"columns\")\n",
        "\n",
        "        if metric:\n",
        "            _metric = metric if isinstance(metric, list) else [metric]\n",
        "            df = df.T.loc[df.T.index.get_level_values(\"metric\").isin(_metric)].T\n",
        "            if not isinstance(metric, list):\n",
        "                df = df.droplevel(\"metric\", axis=\"columns\")\n",
        "\n",
        "        return Results(df)\n",
        "\n",
        "    @property\n",
        "    def methods(self) -> list[str]:\n",
        "        return list(self.df.index.get_level_values(\"method\").unique())\n",
        "\n",
        "    @property\n",
        "    def optimization_metrics(self) -> list[str]:\n",
        "        return list(self.df.index.get_level_values(\"optimization_metric\").unique())\n",
        "\n",
        "    @property\n",
        "    def optimization_times(self) -> list[float]:\n",
        "        return list(self.df.index.get_level_values(\"optimization_time\").unique())\n",
        "\n",
        "    @property\n",
        "    def eval_positions(self) -> list[int]:\n",
        "        return list(self.df.index.get_level_values(\"eval_position\").unique())\n",
        "\n",
        "    @property\n",
        "    def datasets(self) -> list[str]:\n",
        "        return list(self.df.columns.get_level_values(\"dataset\").unique())\n",
        "\n",
        "    @property\n",
        "    def metrics(self) -> list[str]:\n",
        "        return list(self.df.columns.get_level_values(\"metric\").unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u59iTmjlbiL9"
      },
      "source": [
        "### Plotter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Author: Hassan Ismail Fawaz <hassan.ismail-fawaz@uha.fr>\n",
        "#         Germain Forestier <germain.forestier@uha.fr>\n",
        "#         Jonathan Weber <jonathan.weber@uha.fr>\n",
        "#         Lhassane Idoumghar <lhassane.idoumghar@uha.fr>\n",
        "#         Pierre-Alain Muller <pierre-alain.muller@uha.fr>\n",
        "# License: GPL3\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "# import Orange\n",
        "\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
        "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
        "\n",
        "import operator\n",
        "import math\n",
        "from scipy.stats import wilcoxon\n",
        "from scipy.stats import friedmanchisquare\n",
        "import networkx\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "ALGORITHM_COLUMN_NAME = 'method'\n",
        "PERFORMANCE_METRIC_COLUMN_NAME = 'roc_auc'\n",
        "TASK_COLUMN_NAME = 'Dataset'\n",
        "\n",
        "\n",
        "# inspired from orange3 https://docs.orange.biolab.si/3/data-mining-library/reference/evaluation.cd.html\n",
        "def graph_ranks(ax, avranks, names, p_values, cd=None, cdmethod=None, lowv=None, highv=None,\n",
        "                width=6, textspace=1, reverse=False, filename=None, labels=False, **kwargs):\n",
        "    \"\"\"\n",
        "    Draws a CD graph, which is used to display  the differences in methods'\n",
        "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
        "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
        "\n",
        "    Needs matplotlib to work.\n",
        "\n",
        "    The image is ploted on `plt` imported using\n",
        "    `import matplotlib.pyplot as plt`.\n",
        "\n",
        "    Args:\n",
        "        avranks (list of float): average ranks of methods.\n",
        "        names (list of str): names of methods.\n",
        "        cd (float): Critical difference used for statistically significance of\n",
        "            difference between methods.\n",
        "        cdmethod (int, optional): the method that is compared with other methods\n",
        "            If omitted, show pairwise comparison of methods\n",
        "        lowv (int, optional): the lowest shown rank\n",
        "        highv (int, optional): the highest shown rank\n",
        "        width (int, optional): default width in inches (default: 6)\n",
        "        textspace (int, optional): space on figure sides (in inches) for the\n",
        "            method names (default: 1)\n",
        "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
        "            right (default: `False`)\n",
        "        filename (str, optional): output file name (with extension). If not\n",
        "            given, the function does not write a file.\n",
        "        labels (bool, optional): if set to `True`, the calculated avg rank\n",
        "        values will be displayed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import matplotlib\n",
        "        import matplotlib.pyplot as plt\n",
        "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
        "\n",
        "    width = float(width)\n",
        "    textspace = float(textspace)\n",
        "\n",
        "    def nth(l, n):\n",
        "        \"\"\"\n",
        "        Returns only nth elemnt in a list.\n",
        "        \"\"\"\n",
        "        n = lloc(l, n)\n",
        "        return [a[n] for a in l]\n",
        "\n",
        "    def lloc(l, n):\n",
        "        \"\"\"\n",
        "        List location in list of list structure.\n",
        "        Enable the use of negative locations:\n",
        "        -1 is the last element, -2 second last...\n",
        "        \"\"\"\n",
        "        if n < 0:\n",
        "            return len(l[0]) + n\n",
        "        else:\n",
        "            return n\n",
        "\n",
        "    def mxrange(lr):\n",
        "        \"\"\"\n",
        "        Multiple xranges. Can be used to traverse matrices.\n",
        "        This function is very slow due to unknown number of\n",
        "        parameters.\n",
        "\n",
        "        >>> mxrange([3,5])\n",
        "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
        "\n",
        "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
        "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
        "\n",
        "        \"\"\"\n",
        "        if not len(lr):\n",
        "            yield ()\n",
        "        else:\n",
        "            # it can work with single numbers\n",
        "            index = lr[0]\n",
        "            if isinstance(index, int):\n",
        "                index = [index]\n",
        "            for a in range(*index):\n",
        "                for b in mxrange(lr[1:]):\n",
        "                    yield tuple([a] + list(b))\n",
        "\n",
        "    def print_figure(fig, *args, **kwargs):\n",
        "        canvas = FigureCanvasAgg(fig)\n",
        "        canvas.print_figure(*args, **kwargs)\n",
        "\n",
        "    sums = avranks\n",
        "\n",
        "    nnames = names\n",
        "    ssums = sums\n",
        "\n",
        "    if lowv is None:\n",
        "        lowv = min(1, int(math.floor(min(ssums))))\n",
        "    if highv is None:\n",
        "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
        "\n",
        "    cline = 0.4\n",
        "\n",
        "    k = len(sums)\n",
        "\n",
        "    lines = None\n",
        "\n",
        "    linesblank = 0\n",
        "    scalewidth = width - 2 * textspace\n",
        "\n",
        "    def rankpos(rank):\n",
        "        if not reverse:\n",
        "            a = rank - lowv\n",
        "        else:\n",
        "            a = highv - rank\n",
        "        return textspace + scalewidth / (highv - lowv) * a\n",
        "\n",
        "    distanceh = 0.25\n",
        "\n",
        "    cline += distanceh\n",
        "\n",
        "    # calculate height needed height of an image\n",
        "    minnotsignificant = max(2 * 0.2, linesblank)\n",
        "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
        "\n",
        "    # fig = plt.figure(figsize=(width, height))\n",
        "    # fig.set_facecolor('white')\n",
        "    # ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    hf = 1. / height  # height factor\n",
        "    wf = 1. / width\n",
        "\n",
        "    def hfl(l):\n",
        "        return [a * hf for a in l]\n",
        "\n",
        "    def wfl(l):\n",
        "        return [a * wf for a in l]\n",
        "\n",
        "    # Upper left corner is (0,0).\n",
        "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(1, 0)\n",
        "\n",
        "    def line(l, color='k', **kwargs):\n",
        "        \"\"\"\n",
        "        Input is a list of pairs of points.\n",
        "        \"\"\"\n",
        "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
        "\n",
        "    def text(x, y, s, *args, **kwargs):\n",
        "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
        "\n",
        "    line([(textspace, cline), (width - textspace, cline)], linewidth=2)\n",
        "\n",
        "    bigtick = 0.3\n",
        "    smalltick = 0.15\n",
        "    linewidth = 2.0\n",
        "    linewidth_sign = 4.0\n",
        "\n",
        "    tick = None\n",
        "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
        "        tick = smalltick\n",
        "        if a == int(a):\n",
        "            tick = bigtick\n",
        "        line([(rankpos(a), cline - tick / 2),\n",
        "              (rankpos(a), cline)],\n",
        "             linewidth=2)\n",
        "\n",
        "    for a in range(lowv, highv + 1):\n",
        "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
        "             ha=\"center\", va=\"bottom\", size=16)\n",
        "\n",
        "    k = len(ssums)\n",
        "\n",
        "    def filter_names(name):\n",
        "        return name\n",
        "\n",
        "    space_between_names = 0.24\n",
        "\n",
        "    for i in range(math.ceil(k / 2)):\n",
        "        chei = cline + minnotsignificant + i * space_between_names\n",
        "        line([(rankpos(ssums[i]), cline),\n",
        "              (rankpos(ssums[i]), chei),\n",
        "              (textspace - 0.1, chei)],\n",
        "             linewidth=linewidth)\n",
        "        if labels:\n",
        "            text(textspace + 0.3, chei - 0.075, format(ssums[i], '.2f'), ha=\"right\", va=\"center\", size=10)\n",
        "        text(textspace - 0.2, chei, filter_names(nnames[i]), ha=\"right\", va=\"center\", size=16)\n",
        "\n",
        "    for i in range(math.ceil(k / 2), k):\n",
        "        chei = cline + minnotsignificant + (k - i - 1) * space_between_names\n",
        "        line([(rankpos(ssums[i]), cline),\n",
        "              (rankpos(ssums[i]), chei),\n",
        "              (textspace + scalewidth + 0.1, chei)],\n",
        "             linewidth=linewidth)\n",
        "        if labels:\n",
        "            text(textspace + scalewidth - 0.3, chei - 0.075, format(ssums[i], '.2f'), ha=\"left\", va=\"center\", size=10)\n",
        "        text(textspace + scalewidth + 0.2, chei, filter_names(nnames[i]),\n",
        "             ha=\"left\", va=\"center\", size=16)\n",
        "\n",
        "    # no-significance lines\n",
        "    def draw_lines(lines, side=0.05, height=0.1):\n",
        "        start = cline + 0.2\n",
        "\n",
        "        for l, r in lines:\n",
        "            line([(rankpos(ssums[l]) - side, start),\n",
        "                  (rankpos(ssums[r]) + side, start)],\n",
        "                 linewidth=linewidth_sign)\n",
        "            start += height\n",
        "            print('drawing: ', l, r)\n",
        "\n",
        "    # draw_lines(lines)\n",
        "    start = cline + 0.2\n",
        "    side = -0.02\n",
        "    height = 0.1\n",
        "\n",
        "    # draw no significant lines\n",
        "    # get the cliques\n",
        "    cliques = form_cliques(p_values, nnames)\n",
        "    i = 1\n",
        "    achieved_half = False\n",
        "    # print(nnames)\n",
        "    for clq in cliques:\n",
        "        if len(clq) == 1:\n",
        "            continue\n",
        "        # print(clq)\n",
        "        min_idx = np.array(clq).min()\n",
        "        max_idx = np.array(clq).max()\n",
        "        if min_idx >= len(nnames) / 2 and achieved_half == False:\n",
        "            start = cline + 0.25\n",
        "            achieved_half = True\n",
        "        line([(rankpos(ssums[min_idx]) - side, start),\n",
        "              (rankpos(ssums[max_idx]) + side, start)],\n",
        "             linewidth=linewidth_sign)\n",
        "        start += height\n",
        "    return ax\n",
        "\n",
        "def form_cliques(p_values, nnames):\n",
        "    \"\"\"\n",
        "    This method forms the cliques\n",
        "    \"\"\"\n",
        "    # first form the numpy matrix data\n",
        "    m = len(nnames)\n",
        "    g_data = np.zeros((m, m), dtype=np.int64)\n",
        "    for p in p_values:\n",
        "        if p[3] == False:\n",
        "            i = np.where(nnames == p[0])[0][0]\n",
        "            j = np.where(nnames == p[1])[0][0]\n",
        "            min_i = min(i, j)\n",
        "            max_j = max(i, j)\n",
        "            g_data[min_i, max_j] = 1\n",
        "\n",
        "    g = networkx.Graph(g_data)\n",
        "    return networkx.find_cliques(g)\n",
        "\n",
        "def wilcoxon_holm(df_perf, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Applies the wilcoxon signed rank test between each pair of algorithm and then use Holm\n",
        "    to reject the null's hypothesis\n",
        "    \"\"\"\n",
        "    print(pd.unique(df_perf[ALGORITHM_COLUMN_NAME]))\n",
        "    # count the number of tested datasets per classifier\n",
        "    df_counts = pd.DataFrame({'count': df_perf.groupby(\n",
        "        [ALGORITHM_COLUMN_NAME]).size()}).reset_index()\n",
        "    # get the maximum number of tested datasets\n",
        "    max_nb_datasets = df_counts['count'].max()\n",
        "    # get the list of classifiers who have been tested on nb_max_datasets\n",
        "    classifiers = list(df_counts.loc[df_counts['count'] == max_nb_datasets]\n",
        "                       [ALGORITHM_COLUMN_NAME])\n",
        "    # test the null hypothesis using friedman before doing a post-hoc analysis\n",
        "    \n",
        "    try:\n",
        "        friedman_p_value = friedmanchisquare(*(\n",
        "            np.array(df_perf.loc[df_perf[ALGORITHM_COLUMN_NAME] == c][PERFORMANCE_METRIC_COLUMN_NAME])\n",
        "            for c in classifiers))[1]\n",
        "        if friedman_p_value >= alpha:\n",
        "            # then the null hypothesis over the entire classifiers cannot be rejected\n",
        "            # open('null_hypethesis_rejected.txt', 'w').write('the null hypothesis over the entire classifiers cannot be rejected')\n",
        "            exit()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # get the number of classifiers\n",
        "    m = len(classifiers)\n",
        "    # init array that contains the p-values calculated by the Wilcoxon signed rank test\n",
        "    p_values = []\n",
        "    # loop through the algorithms to compare pairwise\n",
        "    better_classifiers = []\n",
        "    for i in range(m - 1):\n",
        "        # get the name of classifier one\n",
        "        classifier_1 = classifiers[i]\n",
        "        # get the performance of classifier one\n",
        "        perf_1 = np.array(df_perf.loc[df_perf[ALGORITHM_COLUMN_NAME] == classifier_1][PERFORMANCE_METRIC_COLUMN_NAME]\n",
        "                          , dtype=np.float64)\n",
        "        for j in range(i + 1, m):\n",
        "            # get the name of the second classifier\n",
        "            classifier_2 = classifiers[j]\n",
        "            # get the performance of classifier one\n",
        "            perf_2 = np.array(df_perf.loc[df_perf[ALGORITHM_COLUMN_NAME] == classifier_2]\n",
        "                              [PERFORMANCE_METRIC_COLUMN_NAME], dtype=np.float64)\n",
        "            diff_perf = perf_1-perf_2\n",
        "            wins = sum(diff_perf>0)\n",
        "            tie = sum(diff_perf==0)\n",
        "            loss = sum(diff_perf<0)\n",
        "            if wins > loss:\n",
        "                winner = classifier_1\n",
        "            else:\n",
        "                winner = classifier_2\n",
        "            # calculate the p_value\n",
        "            p_value = np.around(wilcoxon(perf_1, perf_2, zero_method='pratt')[1], decimals=4)\n",
        "            # appen to the list\n",
        "            p_values.append((classifier_1, classifier_2, p_value, False))\n",
        "            better_classifiers.append(\n",
        "                {'classifier_1': classifier_1,\n",
        "                'classifier_2': classifier_2,\n",
        "                'p_value': p_value,\n",
        "                'winner': winner,\n",
        "                'wins': wins,\n",
        "                'tie': tie,\n",
        "                'loss': loss})\n",
        "\n",
        "    # get the number of hypothesis\n",
        "    k = len(p_values)\n",
        "    # sort the list in acsending manner of p-value\n",
        "    p_values.sort(key=operator.itemgetter(2))\n",
        "    better_classifiers.sort(key=operator.itemgetter('p_value'))\n",
        "    better_classifiers = pd.DataFrame(better_classifiers)\n",
        "    # get_according_to_thesis(better_classifiers).T.to_csv(f\"{out_dir}/cd_comparison_pairwise_{setname}_display.csv\")\n",
        "    # loop through the hypothesis\n",
        "    for i in range(k):\n",
        "        # correct alpha with holm\n",
        "        new_alpha = float(alpha / (k - i))\n",
        "        # test if significant after holm's correction of alpha\n",
        "        if p_values[i][2] <= new_alpha:\n",
        "            p_values[i] = (p_values[i][0], p_values[i][1], p_values[i][2], p_values[i][2] <= new_alpha)\n",
        "        else:\n",
        "            # stop\n",
        "            break\n",
        "    # compute the average ranks to be returned (useful for drawing the cd diagram)\n",
        "    # sort the dataframe of performances\n",
        "    sorted_df_perf = df_perf.loc[df_perf[ALGORITHM_COLUMN_NAME].isin(classifiers)]. \\\n",
        "        sort_values([ALGORITHM_COLUMN_NAME, TASK_COLUMN_NAME])\n",
        "    # get the rank data\n",
        "    rank_data = np.array(sorted_df_perf[PERFORMANCE_METRIC_COLUMN_NAME]).reshape(m, max_nb_datasets)\n",
        "\n",
        "    # create the data frame containg the accuracies\n",
        "    df_ranks = pd.DataFrame(data=rank_data, index=np.sort(classifiers), columns=\n",
        "    np.unique(sorted_df_perf[TASK_COLUMN_NAME]))\n",
        "\n",
        "    # number of wins\n",
        "    dfff = df_ranks.rank(ascending=False)\n",
        "    # print(dfff)  # [dfff == 1.0].sum(axis=1))\n",
        "    # dfff.T.to_csv(os.path.join(out_dir, \"rank_per_task.csv\"))\n",
        "    # average the ranks\n",
        "    average_ranks = df_ranks.rank(ascending=False).mean(axis=1).sort_values(ascending=False)\n",
        "    # average_ranks.T.to_csv(os.path.join(out_dir, \"average_ranks_per_task.csv\"))\n",
        "    # return the p-values and the average ranks\n",
        "    return p_values, average_ranks, max_nb_datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1LoPFCA9bjvQ"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Plotter:\n",
        "    result: Results\n",
        "\n",
        "    def cd_plot(\n",
        "        self,\n",
        "        *,\n",
        "        method = None,\n",
        "        eval_position: int = 1_000,\n",
        "        optimization_time: float = 30.0,\n",
        "        optimization_metric: str = \"roc_auc\",\n",
        "        metric: str = \"acc\",\n",
        "        legend: str = \"box\",  # box, text\n",
        "        alpha: float= 0.05,\n",
        "        highlighted_families: Sequence[str] = FAMILY_NAMES.keys(),\n",
        "        # (\n",
        "        #    \"transformer_cpu\",\n",
        "        #    \"transformer_gpu\",\n",
        "        #    \"xgb\",\n",
        "        #    \"rf\",\n",
        "        # ),\n",
        "        ax: plt.Axes,\n",
        "    ) -> plt.Axes:\n",
        "        # assert all(f in FAMILY_NAMES for f in highlighted_families)\n",
        "        r = self.result.at(\n",
        "            method=method,\n",
        "            optimization_metric=optimization_metric,\n",
        "            optimization_time=optimization_time,\n",
        "            eval_position=eval_position,\n",
        "            metric=[metric],\n",
        "        )\n",
        "\n",
        "        df = r.df.groupby([\"method\", \"split\"]).mean().groupby(\"method\").mean().T\n",
        "        # print(df.head())\n",
        "        # drop metric from multiindex\n",
        "        df = df.droplevel(0)\n",
        "        # print(df.head())\n",
        "        columns = df.columns\n",
        "        # move dataset which is an index to a column\n",
        "        df = df.reset_index()\n",
        "\n",
        "        # concate mini dfs per method\n",
        "        mini_dfs = []\n",
        "        for column in columns:\n",
        "            t_1_df = df[[\"dataset\", column]].copy()\n",
        "            t_1_df[\"method\"] = column\n",
        "            t_1_df.columns = [\"Dataset\", f\"{optimization_metric}\", \"method\"]\n",
        "            mini_dfs.append(t_1_df)\n",
        "        df = pd.concat(mini_dfs)\n",
        "\n",
        "        p_values, average_ranks, num_datasets = wilcoxon_holm(df_perf=df, alpha=alpha)\n",
        "\n",
        "        labels = [\n",
        "            (\n",
        "                LABEL_NAMES[method],\n",
        "            )\n",
        "            for method in r.methods]\n",
        "\n",
        "        ax = graph_ranks(ax, [round(float(value), 2) for value in list(average_ranks.values)], average_ranks.keys(), p_values,\n",
        "                    cd=None, reverse=True, width=9, textspace=1.5, labels=labels)\n",
        "        \n",
        "        return ax\n",
        "\n",
        "    def overall_plot(\n",
        "        self,\n",
        "        *,\n",
        "        eval_position: int = 1_000,\n",
        "        optimization_time: float = 30.0,\n",
        "        optimization_metric: str = \"roc_auc\",\n",
        "        metric: str = \"acc\",\n",
        "        legend: str = \"box\",  # box, text\n",
        "        highlighted_families: Sequence[str] = FAMILY_NAMES.keys(),\n",
        "        # (\n",
        "        #    \"transformer_cpu\",\n",
        "        #    \"transformer_gpu\",\n",
        "        #    \"xgb\",\n",
        "        #    \"rf\",\n",
        "        # ),\n",
        "        ax: plt.Axes,\n",
        "    ) -> plt.Axes:\n",
        "        assert all(f in FAMILY_NAMES for f in highlighted_families)\n",
        "        quantile_pairs = [(0.05, 0.95), (0.25, 0.75)]\n",
        "        quantile_mark = [(0.05, 0.95), (0.25, 0.75)]\n",
        "        quantiles = sorted(set(chain.from_iterable(quantile_pairs)))\n",
        "\n",
        "        s_point = 50\n",
        "        s_median = 100\n",
        "        alpha_point = 0.1\n",
        "        alpha_family_join = 0.1\n",
        "        q_alpha = {0: 0.2, 0.05: 0.3, 0.25: 0.5}\n",
        "        q_linewidth = {0: 1, 0.05: 2, 0.25: 3}\n",
        "\n",
        "        r = self.result.at(\n",
        "            optimization_metric=optimization_metric,\n",
        "            optimization_time=optimization_time,\n",
        "            eval_position=eval_position,\n",
        "            metric=[metric, \"time\"],\n",
        "        )\n",
        "\n",
        "        # metric        acc       time\n",
        "        # method split\n",
        "        # gp     0      0.786164  39.354000\n",
        "        #        1      0.786164  38.317375\n",
        "        # ...           ...        ...\n",
        "        # xgb    19     0.794751   0.148113\n",
        "        #        20     0.794751   0.148113\n",
        "        df = r.df.groupby([\"method\", \"split\"]).mean().T.groupby(\"metric\").mean().T\n",
        "\n",
        "        # For dataset cross dataset aggregation\n",
        "        # df = r.df.unstack(level=\"method\").mean().unstack(\"metric\").reset_index()\n",
        "\n",
        "        #          | time                               metric\n",
        "        # quantile | 0, 0.05, 0.25, 0.75, 0.95, 1, 0, 0.05, 0.25, 0.75, 0.95, 1\n",
        "        # ---------------------------------------------------------------------\n",
        "        # gp       |\n",
        "        # ...      |\n",
        "        # xgb      |\n",
        "        qs = df.groupby(\"method\").quantile(quantiles).unstack()\n",
        "        qs.columns.names = [qs.columns.names[0], \"quantiles\"]\n",
        "\n",
        "        #        | acc time\n",
        "        # method |\n",
        "        # gp     |\n",
        "        # ...    |\n",
        "        # xgb    |\n",
        "        medians = df.groupby(\"method\").agg({metric: \"median\", \"time\": \"median\"})\n",
        "\n",
        "        families = set(map(Plotter.family, r.methods))\n",
        "\n",
        "        palette = {\n",
        "            h: c for h, c in zip(families, sns.color_palette(n_colors=len(families)))\n",
        "        }\n",
        "\n",
        "        # Tiny feint blobs for all points\n",
        "        # methods = df.index.get_level_values(\"method\")\n",
        "        # df[\"family\"] = [self.family(m) for m in method_list]\n",
        "        # df[\"style\"] = self.styles(method_list)\n",
        "        # sns.scatterplot(\n",
        "        # data=df,\n",
        "        # x=\"time\",\n",
        "        # y=metric,\n",
        "        # hue=hue,\n",
        "        # style=style,\n",
        "        # alpha=alpha_point,\n",
        "        # ax=ax,\n",
        "        # legend=False,\n",
        "        # palette=palette,\n",
        "        # s=s_point,\n",
        "        # )\n",
        "\n",
        "        # Quantiles\n",
        "        # For each (method, quantile) we draw a H on both the time and metric axis\n",
        "        # time\n",
        "        times = qs[\"time\"]\n",
        "        metric_values = qs[metric]\n",
        "        for method, (q_low, q_high) in product(qs.index, quantile_pairs):\n",
        "\n",
        "            x = medians.loc[method][\"time\"]\n",
        "            time_low = times[q_low].loc[method]\n",
        "            time_high = times[q_high].loc[method]\n",
        "\n",
        "            y = medians.loc[method][metric]\n",
        "            metric_low = metric_values[q_low].loc[method]\n",
        "            metric_high = metric_values[q_high].loc[method]\n",
        "\n",
        "            family = Plotter.family(method)\n",
        "\n",
        "            # Time\n",
        "            time_marker = \"|\" if (q_low, q_high) in quantile_mark else None\n",
        "            ax.plot(\n",
        "                [time_low, time_high],\n",
        "                [y, y],\n",
        "                c=palette[family],\n",
        "                alpha=q_alpha[q_low],\n",
        "                linewidth=q_linewidth[q_low],\n",
        "                marker=time_marker,\n",
        "            )\n",
        "\n",
        "            # Metric\n",
        "            metric_marker = \"_\" if (q_low, q_high) in quantile_mark else None\n",
        "            ax.plot(\n",
        "                [x, x],\n",
        "                [metric_low, metric_high],\n",
        "                c=palette[family],\n",
        "                alpha=q_alpha[q_low],\n",
        "                linewidth=q_linewidth[q_low],\n",
        "                marker=metric_marker,\n",
        "            )\n",
        "\n",
        "        # Big blob for medians\n",
        "        medians[\"family\"] = [Plotter.family(i) for i in medians.index]\n",
        "        markers = self.markers(sorted(medians.index, key=lambda x: LABEL_NAMES[x]))\n",
        "\n",
        "        for key, group in medians.groupby(\"method\"):\n",
        "            sns.scatterplot(\n",
        "                data=group,\n",
        "                x=\"time\",\n",
        "                y=metric,\n",
        "                hue=\"family\",\n",
        "                ax=ax,\n",
        "                palette=palette,\n",
        "                s=s_median,\n",
        "                marker=markers[key],\n",
        "            )\n",
        "\n",
        "        # https://matplotlib.org/stable/gallery/misc/transoffset.html#sphx-glr-gallery-misc-transoffset-py\n",
        "        text_offset = mtransforms.offset_copy(ax.transData, x=10, y=20, units=\"dots\")\n",
        "        for family, group in medians.groupby(\"family\"):\n",
        "            if family not in highlighted_families:\n",
        "                continue\n",
        "            # Sort by the time axis\n",
        "            xs, ys = zip(*sorted(zip(group[\"time\"], group[metric])))\n",
        "            ax.plot(xs, ys, c=palette[family], linestyle=\"--\", alpha=alpha_family_join)\n",
        "\n",
        "            l_xs = len(xs)\n",
        "            mid_x, mid_y = xs[l_xs // 2], ys[l_xs // 2]\n",
        "            ax.text(\n",
        "                mid_x,\n",
        "                mid_y,\n",
        "                FAMILY_NAMES[family],\n",
        "                transform=text_offset,\n",
        "                c=palette[family],\n",
        "                fontweight=\"bold\",\n",
        "            )\n",
        "\n",
        "        ax.set_xscale(\"log\")\n",
        "        ticks = {0.5: \"0.5s\", 1: \"1s\", 5: \"5s\", 15: \"15s\", 30: \"30s\", 60: \"1min\", 300: \"5min\", 900: \"15min\", 1800: \"30min\", 3600: \"1hr\"}\n",
        "        ax.set_xticks(list(ticks.keys()))\n",
        "        ax.set_xticklabels(list(ticks.values()))\n",
        "\n",
        "        # We unfortunatly have to create a manual legend just due to seaborn not being\n",
        "        # very flexible in that respect\n",
        "        family_methods = sorted([(self.family(m), m) for m in set(medians.index)])\n",
        "\n",
        "        items = [\n",
        "            (\n",
        "                family,\n",
        "                LABEL_NAMES[method],\n",
        "                Line2D(\n",
        "                    [],\n",
        "                    [],\n",
        "                    color=palette[family],\n",
        "                    marker=markers[method],\n",
        "                    linestyle=\"\",\n",
        "                ),\n",
        "            )\n",
        "            for family, method in family_methods\n",
        "        ]\n",
        "        # Sort just by family and label\n",
        "        _, labels, handles = zip(*sorted(items, key=lambda x: x[:2]))\n",
        "\n",
        "        # create a legend only using the items\n",
        "        ax.legend(\n",
        "            handles,\n",
        "            labels,\n",
        "            title=\"Method\",\n",
        "            fontsize=10,\n",
        "        )\n",
        "\n",
        "        ax.set_xlabel(\"Time taken (s)\")\n",
        "        ax.set_ylabel(metric)\n",
        "\n",
        "        return ax\n",
        "\n",
        "    @classmethod\n",
        "    def family(cls, method: str) -> str:\n",
        "        for f in FAMILY_NAMES:\n",
        "            if method.startswith(f):\n",
        "                return f\n",
        "\n",
        "        # Exceptions\n",
        "        if \"random_forest\" in method:\n",
        "            return \"rf\"\n",
        "\n",
        "        return method\n",
        "\n",
        "    @classmethod\n",
        "    def markers(cls, methods: Iterable[str]) -> dict[str, str]:\n",
        "        markers = [\"o\", \"v\", \"s\", \"D\", \"8\", \"X\", \"*\"]\n",
        "        styles: dict[str, str] = {}\n",
        "\n",
        "        counter: Counter[str] = Counter()\n",
        "        for method in methods:\n",
        "            family = cls.family(method)\n",
        "            idx = counter[family]\n",
        "            styles[method] = markers[idx]\n",
        "            counter[family] += 1\n",
        "\n",
        "        return styles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGkHDZjfajUs"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BoschSlurmExecutor(SlurmExecutor):\n",
        "    def _make_submission_command(self, submission_file_path):\n",
        "        return [\"sbatch\", str(submission_file_path), '--bosch']\n",
        "\n",
        "\n",
        "PARTITION_TO_EXECUTER = {\n",
        "    'bosch': BoschSlurmExecutor,\n",
        "    'other': AutoExecutor\n",
        "\n",
        "}\n",
        "\n",
        "def get_executer(partition: str) -> SlurmExecutor:\n",
        "    if 'bosch' in partition:\n",
        "        key = 'bosch'\n",
        "    else:\n",
        "        key = 'other'\n",
        "    return PARTITION_TO_EXECUTER[key]\n",
        "\n",
        "\n",
        "def get_executer_params(timeout: float, partition: str, gpu: bool = False):\n",
        "    if gpu:\n",
        "        return {'timeout_min': int(timeout), 'slurm_partition': partition}\n",
        "    else:\n",
        "        return {'time': int(timeout), 'partition': partition, 'mem_per_cpu': 6000, 'nodes': 1, 'cpus_per_task': 1, 'ntasks_per_node': 1}\n",
        "\n",
        "\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    # Setting up reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BGmAtn8obSUV"
      },
      "outputs": [],
      "source": [
        "def eval_method(\n",
        "    datasets: list[Dataset],\n",
        "    label: str,\n",
        "    classifier_evaluator: Callable,\n",
        "    max_time: float | None,\n",
        "    metric_used: Callable,\n",
        "    split: int,\n",
        "    eval_positions: list[int],\n",
        "    result_path: Path,\n",
        "    append_metric: bool = True,\n",
        "    fetch_only: bool = False,\n",
        "    verbose: bool = False,\n",
        "    bptt: int = 2000,\n",
        "    overwrite: bool = False,\n",
        "):\n",
        "    \"\"\"Evaluate a given method.\"\"\"\n",
        "    if max_time is not None:\n",
        "        label += f\"_time_{float(max_time)}\"\n",
        "\n",
        "    if append_metric:\n",
        "        label += f\"_{tb.get_scoring_string(metric_used, usage='')}\"\n",
        "\n",
        "    if isinstance(classifier_evaluator, partial):\n",
        "        device = classifier_evaluator.keywords.get(\"device\", \"cpu\")\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "\n",
        "    task_type = \"multiclass\"\n",
        "    if any(d.task_type != task_type for d in datasets):\n",
        "        raise RuntimeError(\"Not sure how to handle this yet\")\n",
        "\n",
        "    return evaluate(\n",
        "        datasets=[d.as_list() for d in datasets],\n",
        "        model=classifier_evaluator,\n",
        "        method=label,\n",
        "        bptt=bptt,\n",
        "        base_path=result_path,\n",
        "        eval_positions=eval_positions,\n",
        "        device=device,\n",
        "        max_splits=1,\n",
        "        overwrite=overwrite,\n",
        "        save=True,\n",
        "        metric_used=metric_used,\n",
        "        path_interfix=task_type,\n",
        "        fetch_only=fetch_only,\n",
        "        split_id=split,\n",
        "        verbose=verbose,\n",
        "        max_time=max_time,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def do_evaluations(args: argparse.Namespace, datasets: list[Dataset]) -> Results:\n",
        "    results = {}\n",
        "    for method, metric, time, split in product(\n",
        "        args.methods,\n",
        "        args.optimization_metrics,\n",
        "        args.times,\n",
        "        range(1, args.splits+1),\n",
        "    ):\n",
        "        metric_f = METRICS[metric]\n",
        "        metric_name = tb.get_scoring_string(metric_f, usage=\"\")\n",
        "        key = f\"{method}_time_{time}{metric_name}_split_{split}\"\n",
        "\n",
        "        print(f\"Running {key}\")\n",
        "        results[key] = eval_method(\n",
        "            datasets=datasets,\n",
        "            label=method,\n",
        "            result_path=args.result_path,\n",
        "            classifier_evaluator=METHODS[method],\n",
        "            eval_positions=args.eval_positions,  # It's a constant basically\n",
        "            fetch_only=args.fetch_only,\n",
        "            verbose=args.verbose,\n",
        "            max_time=time,\n",
        "            metric_used=metric_f,\n",
        "            split=split,\n",
        "            overwrite=args.overwrite,\n",
        "        )\n",
        "\n",
        "    datasets_as_list = [d.as_list() for d in datasets]\n",
        "\n",
        "    # This will update the results in place\n",
        "    for metric in args.recorded_metrics:\n",
        "        metric_f = METRICS[metric]\n",
        "        calculate_score(\n",
        "            metric=metric_f,\n",
        "            name=metric,\n",
        "            global_results=results,\n",
        "            ds=datasets_as_list,\n",
        "            eval_positions=args.eval_positions,\n",
        "        )\n",
        "\n",
        "    # We also get the times\n",
        "    calculate_score(\n",
        "        metric=time_metric,\n",
        "        name=\"time\",\n",
        "        global_results=results,\n",
        "        ds=datasets_as_list,\n",
        "        eval_positions=args.eval_positions,\n",
        "    )\n",
        "\n",
        "    return Results.from_dict(\n",
        "        results,\n",
        "        datasets=datasets,\n",
        "        recorded_metrics=args.recorded_metrics + [\"time\"],\n",
        "    )\n",
        "\n",
        "\n",
        "def do_plot(\n",
        "    result: Results,\n",
        "    title_prefix: str,\n",
        "    fig_name: str,\n",
        "    path: Path,\n",
        "    figsize: tuple[int, int] = (12, 10),\n",
        "    dpi: int = 120,\n",
        "    extension: str = \"png\",\n",
        "    eval_position: int = 1_000,\n",
        "    shift_legend: bool = True,\n",
        ") -> None:\n",
        "    for metric, opt_time, opt_metric in zip(\n",
        "        [m for m in result.metrics if \"time\" not in m],\n",
        "        result.optimization_times,\n",
        "        result.optimization_metrics,\n",
        "    ):\n",
        "        fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=dpi)\n",
        "        Plotter(result).overall_plot(\n",
        "            optimization_metric=opt_metric,\n",
        "            optimization_time=opt_time,\n",
        "            eval_position=eval_position,\n",
        "            metric=metric,\n",
        "            ax=axes,\n",
        "        )\n",
        "        axes.set_title(f\"{title_prefix} [opt_time={opt_time}, opt_metric={opt_metric}]\")\n",
        "\n",
        "        if shift_legend:\n",
        "            sns.move_legend(axes, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "\n",
        "        stem = f\"{fig_name}_opt_metric_{opt_metric}_opt_time_{opt_time}_metric_{metric}\"\n",
        "        fig.savefig(path / f\"{stem}.{extension}\", bbox_inches=\"tight\")\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def do_cd_plot(\n",
        "    result: Results,\n",
        "    title_prefix: str,\n",
        "    fig_name: str,\n",
        "    path: Path,\n",
        "    figsize: tuple[int, int] = (12, 10),\n",
        "    dpi: int = 120,\n",
        "    extension: str = \"png\",\n",
        "    eval_position: int = 1_000,\n",
        "    shift_legend: bool = True,\n",
        "    methods = None\n",
        ") -> None:\n",
        "    for metric, opt_time, opt_metric in zip(\n",
        "        [m for m in result.metrics if \"time\" not in m],\n",
        "        result.optimization_times,\n",
        "        result.optimization_metrics,\n",
        "    ):\n",
        "        fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=dpi)\n",
        "        Plotter(result).cd_plot(\n",
        "            method=methods,\n",
        "            optimization_metric=opt_metric,\n",
        "            optimization_time=opt_time,\n",
        "            eval_position=eval_position,\n",
        "            metric=metric,\n",
        "            ax=axes,\n",
        "        )\n",
        "        axes.set_title(f\"{title_prefix} [opt_time={opt_time}, opt_metric={opt_metric}]\")\n",
        "\n",
        "        # if shift_legend:\n",
        "        #     sns.move_legend(axes, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "\n",
        "        stem = f\"{fig_name}_opt_metric_{opt_metric}_opt_time_{opt_time}_metric_{metric}\"\n",
        "        fig.savefig(path / f\"{stem}.{extension}\", bbox_inches=\"tight\")\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg38YaXFapKW"
      },
      "source": [
        "<a name=\"experiment\"></a>\n",
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2HDcmVzb0GH",
        "outputId": "851a5ddd-d64d-451a-a1c6-cbd4dad43526"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "# For your own custom evaluation, please comment out the one from below\n",
        "# args = Namespace(\n",
        "#     result_path=HERE, # Where to store results - HERE/results\n",
        "#     gpu=True,  # Whether a GPU is accessible\n",
        "#     times=[30], # How much optimization time is given to methods requiring it\n",
        "#     splits=5, # How many splits to run\n",
        "#     validation_datasets=[13, 59, 4], # \"cc_valid\" or list of openml ids\n",
        "#     test_datasets=[973, 1596, 40981], # \"cc_test\" or list of openml ids\n",
        "#     optimization_metrics=[\"roc\"], # [\"roc\", \"cross_entropy\", \"acc\", \"brier_score\", \"ece\"]m\n",
        "#     recorded_metrics=[\"roc\", \"cross_entropy\", \"acc\", \"brier_score\", \"ece\"], # Same as above\n",
        "#     methods=[\"rf_default\", \"transformer_gpu_N_8\"], # See keys of METHODS in Constants section\n",
        "#     fetch_only=False, # Will only fetch results and not compute anything\n",
        "#     bptt=2_000, # Transformer sequence length\n",
        "#     eval_positions=[1_000], # Leave as is\n",
        "#     overwrite=False, # Will overwrite results\n",
        "#     plot=True, # Do plots\n",
        "#     plot_directory=HERE/ \"plots\",  # Where to store plots\n",
        "#     figsize=(12, 10),  # The figure size for matplotlib\n",
        "#     dpi=120,  # The DPI for figures by matplotlib\n",
        "#     extension=\"png\", # The extension for saving figures\n",
        "#     verbose=True,\n",
        "\n",
        "#     # Use this to use the predefined results from experiments\n",
        "#     # See the commented out block below\n",
        "#     load_predefined_results=False,\n",
        "#     predefined_results_path=None,\n",
        "# )\n",
        "\n",
        "# This was used for generating the full overview plots,\n",
        "# Comment out to use the above\n",
        "args = Namespace(\n",
        "    result_path=Path(\"/work/dlclarge1/rkohli-results_tabpfn_180/\"), # HERE,\n",
        "    gpu=True,\n",
        "    times=[3600.0],\n",
        "    splits=5,\n",
        "    validation_datasets=\"cc_valid\",\n",
        "    test_datasets=\"cc_test\",\n",
        "    optimization_metrics=[\"roc\"],\n",
        "    recorded_metrics=[\"roc\", \"cross_entropy\", \"acc\", \"brier_score\", \"ece\"],\n",
        "    methods=list(METHODS.keys()),\n",
        "    fetch_only=True,\n",
        "    bptt=2_000,\n",
        "    eval_positions=[1_000],\n",
        "    overwrite=False,\n",
        "    plot=True,\n",
        "    plot_directory=HERE/ \"plots_noah\",\n",
        "    figsize=(12, 10),\n",
        "    chunk_size=10,\n",
        "    dpi=120,\n",
        "    extension=\"png\",\n",
        "    verbose=False,\n",
        "    load_predefined_results=False,\n",
        "    predefined_results_path=HERE, # / \"TabPFNResults\" / \"all_results\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Namespace(bptt=2000, chunk_size=10, dpi=120, eval_positions=[1000], extension='png', fetch_only=True, figsize=(12, 10), gpu=True, load_predefined_results=False, methods=['svm', 'svm_default', 'gradient_boosting_default', 'gp', 'gp_default', 'autogluon', 'lightgbm', 'lightgbm_default', 'catboost', 'catboost_default', 'xgb', 'xgb_default', 'xgb_gpu', 'xgb_default_gpu', 'random_forest', 'rf_default', 'rf_default_n_estimators_10', 'rf_default_n_estimators_32', 'knn', 'logistic', 'transformer_cpu_N_1', 'transformer_cpu_N_4', 'transformer_cpu_N_8', 'transformer_cpu_N_32', 'transformer_gpu_N_1', 'transformer_gpu_N_4', 'transformer_gpu_N_8', 'transformer_gpu_N_32'], optimization_metrics=['roc'], overwrite=False, plot=True, plot_directory=PosixPath('/home/rkohli/TabPFN/plots_noah'), predefined_results_path=PosixPath('/home/rkohli/TabPFN'), recorded_metrics=['roc', 'cross_entropy', 'acc', 'brier_score', 'ece'], result_path=PosixPath('/work/dlclarge1/rkohli-results_tabpfn_180'), splits=5, test_datasets='cc_test', times=[3600.0], validation_datasets='cc_valid', verbose=False)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running svm_time_3600.0roc_auc_split_1\n",
            "Execution failed: ('svm_time_3600.0_roc_auc', 'titanic')\n",
            "Running svm_time_3600.0roc_auc_split_2\n",
            "Execution failed: ('svm_time_3600.0_roc_auc', 'titanic')\n",
            "Running svm_time_3600.0roc_auc_split_3\n",
            "Execution failed: ('svm_time_3600.0_roc_auc', 'titanic')\n",
            "Running svm_time_3600.0roc_auc_split_4\n",
            "Running svm_time_3600.0roc_auc_split_5\n",
            "Running svm_default_time_3600.0roc_auc_split_1\n",
            "Running svm_default_time_3600.0roc_auc_split_2\n",
            "Running svm_default_time_3600.0roc_auc_split_3\n",
            "Running svm_default_time_3600.0roc_auc_split_4\n",
            "Running svm_default_time_3600.0roc_auc_split_5\n",
            "Running gradient_boosting_default_time_3600.0roc_auc_split_1\n",
            "Running gradient_boosting_default_time_3600.0roc_auc_split_2\n",
            "Running gradient_boosting_default_time_3600.0roc_auc_split_3\n",
            "Running gradient_boosting_default_time_3600.0roc_auc_split_4\n",
            "Running gradient_boosting_default_time_3600.0roc_auc_split_5\n",
            "Running gp_time_3600.0roc_auc_split_1\n",
            "Running gp_time_3600.0roc_auc_split_2\n",
            "Running gp_time_3600.0roc_auc_split_3\n",
            "Running gp_time_3600.0roc_auc_split_4\n",
            "Running gp_time_3600.0roc_auc_split_5\n",
            "Running gp_default_time_3600.0roc_auc_split_1\n",
            "Running gp_default_time_3600.0roc_auc_split_2\n",
            "Running gp_default_time_3600.0roc_auc_split_3\n",
            "Running gp_default_time_3600.0roc_auc_split_4\n",
            "Running gp_default_time_3600.0roc_auc_split_5\n",
            "Running autogluon_time_3600.0roc_auc_split_1\n",
            "Running autogluon_time_3600.0roc_auc_split_2\n",
            "Running autogluon_time_3600.0roc_auc_split_3\n",
            "Running autogluon_time_3600.0roc_auc_split_4\n",
            "Running autogluon_time_3600.0roc_auc_split_5\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'balance-scale')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'mfeat-fourier')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'breast-w')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'mfeat-karhunen')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'mfeat-morphological')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'mfeat-zernike')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'cmc')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'credit-approval')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'credit-g')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'diabetes')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'tic-tac-toe')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'vehicle')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'eucalyptus')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'analcatdata_authorship')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'analcatdata_dmft')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'pc4')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'pc3')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'kc2')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'pc1')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'banknote-authentication')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'blood-transfusion-service-center')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'ilpd')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'qsar-biodeg')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'wdbc')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'cylinder-bands')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'dresses-sales')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'MiceProtein')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'car')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'steel-plates-fault')\n",
            "Execution failed: ('autogluon_time_3600.0_roc_auc', 'climate-model-simulation-crashes')\n",
            "Running lightgbm_time_3600.0roc_auc_split_1\n",
            "Running lightgbm_time_3600.0roc_auc_split_2\n",
            "Running lightgbm_time_3600.0roc_auc_split_3\n",
            "Running lightgbm_time_3600.0roc_auc_split_4\n",
            "Running lightgbm_time_3600.0roc_auc_split_5\n",
            "Running lightgbm_default_time_3600.0roc_auc_split_1\n",
            "Running lightgbm_default_time_3600.0roc_auc_split_2\n",
            "Running lightgbm_default_time_3600.0roc_auc_split_3\n",
            "Running lightgbm_default_time_3600.0roc_auc_split_4\n",
            "Running lightgbm_default_time_3600.0roc_auc_split_5\n",
            "Running catboost_time_3600.0roc_auc_split_1\n",
            "Running catboost_time_3600.0roc_auc_split_2\n",
            "Running catboost_time_3600.0roc_auc_split_3\n",
            "Running catboost_time_3600.0roc_auc_split_4\n",
            "Running catboost_time_3600.0roc_auc_split_5\n",
            "Running catboost_default_time_3600.0roc_auc_split_1\n",
            "Running catboost_default_time_3600.0roc_auc_split_2\n",
            "Running catboost_default_time_3600.0roc_auc_split_3\n",
            "Running catboost_default_time_3600.0roc_auc_split_4\n",
            "Running catboost_default_time_3600.0roc_auc_split_5\n",
            "Running xgb_time_3600.0roc_auc_split_1\n",
            "Running xgb_time_3600.0roc_auc_split_2\n",
            "Running xgb_time_3600.0roc_auc_split_3\n",
            "Running xgb_time_3600.0roc_auc_split_4\n",
            "Running xgb_time_3600.0roc_auc_split_5\n",
            "Running xgb_default_time_3600.0roc_auc_split_1\n",
            "Running xgb_default_time_3600.0roc_auc_split_2\n",
            "Running xgb_default_time_3600.0roc_auc_split_3\n",
            "Running xgb_default_time_3600.0roc_auc_split_4\n",
            "Running xgb_default_time_3600.0roc_auc_split_5\n",
            "Running xgb_gpu_time_3600.0roc_auc_split_1\n",
            "Running xgb_gpu_time_3600.0roc_auc_split_2\n",
            "Running xgb_gpu_time_3600.0roc_auc_split_3\n",
            "Running xgb_gpu_time_3600.0roc_auc_split_4\n",
            "Running xgb_gpu_time_3600.0roc_auc_split_5\n",
            "Running xgb_default_gpu_time_3600.0roc_auc_split_1\n",
            "Running xgb_default_gpu_time_3600.0roc_auc_split_2\n",
            "Running xgb_default_gpu_time_3600.0roc_auc_split_3\n",
            "Running xgb_default_gpu_time_3600.0roc_auc_split_4\n",
            "Running xgb_default_gpu_time_3600.0roc_auc_split_5\n",
            "Running random_forest_time_3600.0roc_auc_split_1\n",
            "Running random_forest_time_3600.0roc_auc_split_2\n",
            "Running random_forest_time_3600.0roc_auc_split_3\n",
            "Running random_forest_time_3600.0roc_auc_split_4\n",
            "Running random_forest_time_3600.0roc_auc_split_5\n",
            "Running rf_default_time_3600.0roc_auc_split_1\n",
            "Running rf_default_time_3600.0roc_auc_split_2\n",
            "Running rf_default_time_3600.0roc_auc_split_3\n",
            "Running rf_default_time_3600.0roc_auc_split_4\n",
            "Running rf_default_time_3600.0roc_auc_split_5\n",
            "Running rf_default_n_estimators_10_time_3600.0roc_auc_split_1\n",
            "Running rf_default_n_estimators_10_time_3600.0roc_auc_split_2\n",
            "Running rf_default_n_estimators_10_time_3600.0roc_auc_split_3\n",
            "Running rf_default_n_estimators_10_time_3600.0roc_auc_split_4\n",
            "Running rf_default_n_estimators_10_time_3600.0roc_auc_split_5\n",
            "Running rf_default_n_estimators_32_time_3600.0roc_auc_split_1\n",
            "Running rf_default_n_estimators_32_time_3600.0roc_auc_split_2\n",
            "Running rf_default_n_estimators_32_time_3600.0roc_auc_split_3\n",
            "Running rf_default_n_estimators_32_time_3600.0roc_auc_split_4\n",
            "Running rf_default_n_estimators_32_time_3600.0roc_auc_split_5\n",
            "Running knn_time_3600.0roc_auc_split_1\n",
            "Running knn_time_3600.0roc_auc_split_2\n",
            "Running knn_time_3600.0roc_auc_split_3\n",
            "Running knn_time_3600.0roc_auc_split_4\n",
            "Running knn_time_3600.0roc_auc_split_5\n",
            "Running logistic_time_3600.0roc_auc_split_1\n",
            "Running logistic_time_3600.0roc_auc_split_2\n",
            "Running logistic_time_3600.0roc_auc_split_3\n",
            "Running logistic_time_3600.0roc_auc_split_4\n",
            "Running logistic_time_3600.0roc_auc_split_5\n",
            "Running transformer_cpu_N_1_time_3600.0roc_auc_split_1\n",
            "Running transformer_cpu_N_1_time_3600.0roc_auc_split_2\n",
            "Running transformer_cpu_N_1_time_3600.0roc_auc_split_3\n",
            "Running transformer_cpu_N_1_time_3600.0roc_auc_split_4\n",
            "Running transformer_cpu_N_1_time_3600.0roc_auc_split_5\n",
            "Running transformer_cpu_N_4_time_3600.0roc_auc_split_1\n",
            "Running transformer_cpu_N_4_time_3600.0roc_auc_split_2\n",
            "Running transformer_cpu_N_4_time_3600.0roc_auc_split_3\n",
            "Running transformer_cpu_N_4_time_3600.0roc_auc_split_4\n",
            "Running transformer_cpu_N_4_time_3600.0roc_auc_split_5\n",
            "Running transformer_cpu_N_8_time_3600.0roc_auc_split_1\n",
            "Running transformer_cpu_N_8_time_3600.0roc_auc_split_2\n",
            "Running transformer_cpu_N_8_time_3600.0roc_auc_split_3\n",
            "Running transformer_cpu_N_8_time_3600.0roc_auc_split_4\n",
            "Running transformer_cpu_N_8_time_3600.0roc_auc_split_5\n",
            "Running transformer_cpu_N_32_time_3600.0roc_auc_split_1\n",
            "Running transformer_cpu_N_32_time_3600.0roc_auc_split_2\n",
            "Running transformer_cpu_N_32_time_3600.0roc_auc_split_3\n",
            "Running transformer_cpu_N_32_time_3600.0roc_auc_split_4\n",
            "Running transformer_cpu_N_32_time_3600.0roc_auc_split_5\n",
            "Running transformer_gpu_N_1_time_3600.0roc_auc_split_1\n",
            "Running transformer_gpu_N_1_time_3600.0roc_auc_split_2\n",
            "Running transformer_gpu_N_1_time_3600.0roc_auc_split_3\n",
            "Running transformer_gpu_N_1_time_3600.0roc_auc_split_4\n",
            "Running transformer_gpu_N_1_time_3600.0roc_auc_split_5\n",
            "Running transformer_gpu_N_4_time_3600.0roc_auc_split_1\n",
            "Running transformer_gpu_N_4_time_3600.0roc_auc_split_2\n",
            "Running transformer_gpu_N_4_time_3600.0roc_auc_split_3\n",
            "Running transformer_gpu_N_4_time_3600.0roc_auc_split_4\n",
            "Running transformer_gpu_N_4_time_3600.0roc_auc_split_5\n",
            "Running transformer_gpu_N_8_time_3600.0roc_auc_split_1\n",
            "Running transformer_gpu_N_8_time_3600.0roc_auc_split_2\n",
            "Running transformer_gpu_N_8_time_3600.0roc_auc_split_3\n",
            "Running transformer_gpu_N_8_time_3600.0roc_auc_split_4\n",
            "Running transformer_gpu_N_8_time_3600.0roc_auc_split_5\n",
            "Running transformer_gpu_N_32_time_3600.0roc_auc_split_1\n",
            "Running transformer_gpu_N_32_time_3600.0roc_auc_split_2\n",
            "Running transformer_gpu_N_32_time_3600.0roc_auc_split_3\n",
            "Running transformer_gpu_N_32_time_3600.0roc_auc_split_4\n",
            "Running transformer_gpu_N_32_time_3600.0roc_auc_split_5\n",
            "Error calculating metric with all elements of input should be between 0 and 1, <class 'RuntimeError'> at monks-problems-2 1000 cross_entropy\n",
            "Error calculating metric with all elements of input should be between 0 and 1, <class 'RuntimeError'> at monks-problems-2 1000 cross_entropy\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'float' object is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [13], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m all_datasets \u001b[39m=\u001b[39m all_datasets\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mload_predefined_results:\n\u001b[0;32m---> 16\u001b[0m     result \u001b[39m=\u001b[39m do_evaluations(args, all_datasets)\n\u001b[1;32m     17\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     headers \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "Cell \u001b[0;32mIn [9], line 102\u001b[0m, in \u001b[0;36mdo_evaluations\u001b[0;34m(args, datasets)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m# We also get the times\u001b[39;00m\n\u001b[1;32m     94\u001b[0m calculate_score(\n\u001b[1;32m     95\u001b[0m     metric\u001b[39m=\u001b[39mtime_metric,\n\u001b[1;32m     96\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     eval_positions\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39meval_positions,\n\u001b[1;32m    100\u001b[0m )\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m Results\u001b[39m.\u001b[39;49mfrom_dict(\n\u001b[1;32m    103\u001b[0m     results,\n\u001b[1;32m    104\u001b[0m     datasets\u001b[39m=\u001b[39;49mdatasets,\n\u001b[1;32m    105\u001b[0m     recorded_metrics\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mrecorded_metrics \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    106\u001b[0m )\n",
            "Cell \u001b[0;32mIn [5], line 61\u001b[0m, in \u001b[0;36mResults.from_dict\u001b[0;34m(self, d, datasets, recorded_metrics, dropna)\u001b[0m\n\u001b[1;32m     58\u001b[0m fit_time_key \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_fit_time_at_\u001b[39m\u001b[39m{\u001b[39;00mpos\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39m# If there is a best config\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39;49m(v\u001b[39m.\u001b[39;49mget(old_best_configs_key, [])):\n\u001b[1;32m     62\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(v[old_best_configs_key]) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m     best_config \u001b[39m=\u001b[39m v[old_best_configs_key][\u001b[39m0\u001b[39m]\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# We need to create some directories for this to work\n",
        "out_dir = os.path.join(args.result_path, \"results\", \"tabular\", \"multiclass\") #, f\"{time.time()}\")\n",
        "os.makedirs(out_dir, exist_ok=True\n",
        ")\n",
        "# We ignore the flags datasets\n",
        "filter_f = lambda d: d.name != \"flags\"  # noqa: ignore\n",
        "\n",
        "valid_datasets = Dataset.fetch(args.validation_datasets, only=filter_f)\n",
        "test_datasets = Dataset.fetch(args.test_datasets, only=filter_f)\n",
        "\n",
        "all_datasets = valid_datasets + test_datasets\n",
        "all_datasets = all_datasets\n",
        "\n",
        "if not args.load_predefined_results:\n",
        "    result = do_evaluations(args, all_datasets)\n",
        "else:\n",
        "    headers = [\"metric\", \"dataset\"]\n",
        "    indices = [\n",
        "        \"method\",\n",
        "        \"optimization_metric\",\n",
        "        \"optimization_time\",\n",
        "        \"eval_position\",\n",
        "        \"split\",\n",
        "    ]\n",
        "\n",
        "    if Path(\"predefined_results.csv\").exists():\n",
        "        df = pd.read_csv(\n",
        "            \"predefined_results.csv\",\n",
        "            index_col=list(range(len(indices))),\n",
        "            header=list(range(len(headers))),\n",
        "        )\n",
        "        result = Results(df)\n",
        "    else:\n",
        "\n",
        "        def read(_path: Path) -> dict:\n",
        "            return np.load(_path, allow_pickle=True)\n",
        "            # with _path.open(\"rb\") as f:\n",
        "            #     return pickle.load(f)\n",
        "\n",
        "        def store_results(path):\n",
        "            result = Results.from_dict(\n",
        "                d,\n",
        "                datasets=all_datasets,\n",
        "                recorded_metrics=args.recorded_metrics,\n",
        "            )\n",
        "            result.df.to_csv(path, index=True)\n",
        "            return\n",
        "\n",
        "        d = {}\n",
        "        for i, path in enumerate(args.predefined_results_path.iterdir()):\n",
        "            if path.is_file():\n",
        "                d[path.stem] = read(path)\n",
        "            if i%1000 == 0:\n",
        "                store_results()\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Dataset(name='balance-scale', X=tensor([[3., 2., 3., 5.],\n",
              "         [5., 1., 5., 1.],\n",
              "         [3., 1., 5., 4.],\n",
              "         ...,\n",
              "         [1., 3., 5., 5.],\n",
              "         [2., 3., 1., 2.],\n",
              "         [3., 4., 3., 4.]]), y=tensor([2, 1, 2, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 2, 0, 1, 2,\n",
              "         2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2,\n",
              "         0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2,\n",
              "         2, 0, 2, 2, 0, 2, 2, 1, 0, 1, 0, 2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2, 2, 0,\n",
              "         0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 2, 2, 0,\n",
              "         0, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 0,\n",
              "         2, 1, 0, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 1, 0,\n",
              "         0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0,\n",
              "         2, 2, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 1, 2, 2, 0, 2,\n",
              "         1, 2, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 1, 0, 2, 2, 2, 2, 2,\n",
              "         0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 1, 2, 2, 0,\n",
              "         2, 0, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0,\n",
              "         2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0,\n",
              "         2, 1, 2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0,\n",
              "         2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0,\n",
              "         2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0,\n",
              "         2, 2, 2, 2, 0, 2, 2, 0, 1, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0,\n",
              "         0, 2, 1, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 0, 2,\n",
              "         0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2,\n",
              "         0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 0, 2, 2, 2, 2, 0,\n",
              "         2, 0, 0, 1, 1, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 0, 0, 2, 0,\n",
              "         2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 1,\n",
              "         0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 1, 0, 2,\n",
              "         0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 1, 2, 0, 0, 2, 0, 0, 1, 1, 0, 2, 2,\n",
              "         0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 1, 2,\n",
              "         0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 2, 0,\n",
              "         1]), categorical_columns=[], attribute_names=['left-weight', 'left-distance', 'right-weight', 'right-distance'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='mfeat-fourier', X=tensor([[0.3077, 0.4342, 0.1115,  ..., 0.2850, 0.1370, 0.3309],\n",
              "         [0.2148, 0.1033, 0.0970,  ..., 0.3759, 0.2402, 0.1891],\n",
              "         [0.1161, 0.3121, 0.4420,  ..., 0.1511, 0.2295, 0.1496],\n",
              "         ...,\n",
              "         [0.1101, 0.2335, 0.2145,  ..., 0.4250, 0.1006, 0.3126],\n",
              "         [0.0202, 0.1191, 0.0520,  ..., 0.3978, 0.0245, 0.4261],\n",
              "         [0.3034, 0.5447, 0.3953,  ..., 0.4705, 0.2011, 0.1726]]), y=tensor([3, 8, 4,  ..., 0, 0, 1]), categorical_columns=[], attribute_names=['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16', 'att17', 'att18', 'att19', 'att20', 'att21', 'att22', 'att23', 'att24', 'att25', 'att26', 'att27', 'att28', 'att29', 'att30', 'att31', 'att32', 'att33', 'att34', 'att35', 'att36', 'att37', 'att38', 'att39', 'att40', 'att41', 'att42', 'att43', 'att44', 'att45', 'att46', 'att47', 'att48', 'att49', 'att50', 'att51', 'att52', 'att53', 'att54', 'att55', 'att56', 'att57', 'att58', 'att59', 'att60', 'att61', 'att62', 'att63', 'att64', 'att65', 'att66', 'att67', 'att68', 'att69', 'att70', 'att71', 'att72', 'att73', 'att74', 'att75', 'att76'], info={'samples_capped': True, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='breast-w', X=tensor([[ 6.,  1.,  3.,  ...,  3.,  1.,  1.],\n",
              "         [ 1.,  1.,  1.,  ...,  3.,  1.,  1.],\n",
              "         [ 4.,  3.,  2.,  ...,  2.,  1.,  1.],\n",
              "         ...,\n",
              "         [10.,  6.,  4.,  ...,  3.,  2.,  3.],\n",
              "         [ 2.,  1.,  1.,  ...,  3.,  1.,  1.],\n",
              "         [ 1.,  1.,  1.,  ...,  2.,  1.,  1.]]), y=tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "         1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "         1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "         1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0]), categorical_columns=[], attribute_names=['Clump_Thickness', 'Cell_Size_Uniformity', 'Cell_Shape_Uniformity', 'Marginal_Adhesion', 'Single_Epi_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='mfeat-karhunen', X=tensor([[ 12.3358,   0.2142,  -0.0793,  ...,  -0.6163,  -0.0500,  -2.8782],\n",
              "         [ -0.7177,   5.0454,  -6.1753,  ...,  -1.4802,  -0.4498,  -0.0452],\n",
              "         [ -2.8011,   9.0533,  -7.0451,  ...,  -1.3115,   1.3530,   1.7104],\n",
              "         ...,\n",
              "         [-13.4309,  -4.2887,   5.1719,  ...,  -0.7230,  -0.1826,  -0.0251],\n",
              "         [-10.7186,  -7.6993,   8.0360,  ...,   1.1938,   0.2797,   0.0666],\n",
              "         [  0.9623,  -5.5073,  -1.4111,  ...,  -0.0588,   0.7226,  -0.1598]]), y=tensor([3, 8, 4,  ..., 0, 0, 1]), categorical_columns=[], attribute_names=['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16', 'att17', 'att18', 'att19', 'att20', 'att21', 'att22', 'att23', 'att24', 'att25', 'att26', 'att27', 'att28', 'att29', 'att30', 'att31', 'att32', 'att33', 'att34', 'att35', 'att36', 'att37', 'att38', 'att39', 'att40', 'att41', 'att42', 'att43', 'att44', 'att45', 'att46', 'att47', 'att48', 'att49', 'att50', 'att51', 'att52', 'att53', 'att54', 'att55', 'att56', 'att57', 'att58', 'att59', 'att60', 'att61', 'att62', 'att63', 'att64'], info={'samples_capped': True, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='mfeat-morphological', X=tensor([[0.0000e+00, 3.0000e+00, 0.0000e+00, 1.4314e+02, 1.5462e+00, 5.3385e+03],\n",
              "         [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.2298e+02, 1.1431e+00, 1.7218e+03],\n",
              "         [1.0000e+00, 3.0000e+00, 3.0000e+00, 1.4686e+02, 1.5494e+00, 4.9521e+03],\n",
              "         ...,\n",
              "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 1.3402e+02, 1.3451e+00, 1.8718e+03],\n",
              "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 1.3782e+02, 1.2931e+00, 1.9450e+03],\n",
              "         [0.0000e+00, 2.0000e+00, 0.0000e+00, 1.3442e+02, 1.3746e+00, 3.4324e+03]]), y=tensor([3, 8, 4,  ..., 0, 0, 1]), categorical_columns=[], attribute_names=['att1', 'att2', 'att3', 'att4', 'att5', 'att6'], info={'samples_capped': True, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='mfeat-zernike', X=tensor([[4.0876e-02, 3.2603e+00, 2.9871e+01,  ..., 1.6659e+02, 6.0641e+01,\n",
              "          4.9928e+02],\n",
              "         [3.6634e-03, 2.4461e-01, 4.5904e+00,  ..., 1.4237e+01, 4.8205e+01,\n",
              "          6.9221e+02],\n",
              "         [5.4763e-02, 5.7092e-01, 1.5894e+01,  ..., 1.2222e+02, 4.0009e+01,\n",
              "          5.2954e+02],\n",
              "         ...,\n",
              "         [5.0235e-02, 2.5542e+00, 2.7116e+01,  ..., 2.6854e+01, 5.8513e+01,\n",
              "          5.2331e+02],\n",
              "         [1.5835e-02, 1.5605e+00, 2.9927e+01,  ..., 3.7140e+00, 6.3221e+01,\n",
              "          5.8996e+02],\n",
              "         [1.0780e-01, 1.1972e+00, 2.4534e+01,  ..., 1.9985e+02, 4.7529e+01,\n",
              "          5.3309e+02]]), y=tensor([3, 8, 4,  ..., 0, 0, 1]), categorical_columns=[], attribute_names=['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16', 'att17', 'att18', 'att19', 'att20', 'att21', 'att22', 'att23', 'att24', 'att25', 'att26', 'att27', 'att28', 'att29', 'att30', 'att31', 'att32', 'att33', 'att34', 'att35', 'att36', 'att37', 'att38', 'att39', 'att40', 'att41', 'att42', 'att43', 'att44', 'att45', 'att46', 'att47'], info={'samples_capped': True, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='cmc', X=tensor([[49.,  2.,  3.,  ...,  0.,  3.,  0.],\n",
              "         [45.,  0.,  1.,  ...,  2.,  2.,  1.],\n",
              "         [33.,  3.,  3.,  ...,  2.,  3.,  0.],\n",
              "         ...,\n",
              "         [21.,  2.,  3.,  ...,  1.,  2.,  0.],\n",
              "         [28.,  3.,  3.,  ...,  0.,  2.,  0.],\n",
              "         [25.,  3.,  3.,  ...,  1.,  3.,  0.]]), y=tensor([0, 0, 0,  ..., 0, 0, 0]), categorical_columns=[1, 2, 4, 5, 6, 7, 8], attribute_names=['Wifes_age', 'Wifes_education', 'Husbands_education', 'Number_of_children_ever_born', 'Wifes_religion', 'Wifes_now_working%3F', 'Husbands_occupation', 'Standard-of-living_index', 'Media_exposure'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='credit-approval', X=tensor([[0.0000e+00, 3.5170e+01, 4.5000e+00,  ..., 2.0000e+00, 7.1100e+02,\n",
              "          0.0000e+00],\n",
              "         [0.0000e+00, 3.6420e+01, 7.5000e-01,  ..., 0.0000e+00, 2.4000e+02,\n",
              "          3.0000e+00],\n",
              "         [0.0000e+00, 2.2500e+01, 1.2500e-01,  ..., 0.0000e+00, 2.0000e+02,\n",
              "          7.0000e+01],\n",
              "         ...,\n",
              "         [0.0000e+00, 4.4830e+01, 7.0000e+00,  ..., 0.0000e+00, 1.6000e+02,\n",
              "          2.0000e+00],\n",
              "         [0.0000e+00, 2.5000e+01, 1.2500e+01,  ..., 2.0000e+00, 2.0000e+01,\n",
              "          0.0000e+00],\n",
              "         [1.0000e+00, 3.3250e+01, 3.0000e+00,  ..., 0.0000e+00, 1.8000e+02,\n",
              "          0.0000e+00]]), y=tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "         1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "         0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "         1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "         1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "         0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "         1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "         0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "         0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "         1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
              "         1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "         0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "         0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "         0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "         1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "         0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1]), categorical_columns=[0, 3, 4, 5, 6, 8, 9, 11, 12], attribute_names=['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='credit-g', X=tensor([[ 1., 48.,  0.,  ...,  1.,  0.,  0.],\n",
              "         [ 3., 12.,  0.,  ...,  1.,  0.,  0.],\n",
              "         [ 3., 48.,  4.,  ...,  1.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0., 36.,  2.,  ...,  1.,  1.,  0.],\n",
              "         [ 0., 12.,  2.,  ...,  1.,  0.,  0.],\n",
              "         [ 0., 24.,  2.,  ...,  1.,  0.,  0.]]), y=tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "         1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "         0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "         0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "         0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "         0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "         0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "         0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]), categorical_columns=[0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19], attribute_names=['checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings_status', 'employment', 'installment_commitment', 'personal_status', 'other_parties', 'residence_since', 'property_magnitude', 'age', 'other_payment_plans', 'housing', 'existing_credits', 'job', 'num_dependents', 'own_telephone', 'foreign_worker'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='diabetes', X=tensor([[3.0000e+00, 1.2500e+02, 5.8000e+01,  ..., 3.1600e+01, 1.5100e-01,\n",
              "          2.4000e+01],\n",
              "         [2.0000e+00, 1.0000e+02, 7.0000e+01,  ..., 4.0500e+01, 6.7700e-01,\n",
              "          2.5000e+01],\n",
              "         [6.0000e+00, 1.0300e+02, 6.6000e+01,  ..., 2.4300e+01, 2.4900e-01,\n",
              "          2.9000e+01],\n",
              "         ...,\n",
              "         [1.0000e+00, 7.9000e+01, 7.5000e+01,  ..., 3.2000e+01, 3.9600e-01,\n",
              "          2.2000e+01],\n",
              "         [6.0000e+00, 8.5000e+01, 7.8000e+01,  ..., 3.1200e+01, 3.8200e-01,\n",
              "          4.2000e+01],\n",
              "         [9.0000e+00, 1.5200e+02, 7.8000e+01,  ..., 3.4200e+01, 8.9300e-01,\n",
              "          3.3000e+01]]), y=tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "         0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "         0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "         0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "         0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "         1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]), categorical_columns=[], attribute_names=['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='tic-tac-toe', X=tensor([[1., 1., 1.,  ..., 0., 2., 0.],\n",
              "         [0., 1., 2.,  ..., 0., 2., 2.],\n",
              "         [1., 0., 1.,  ..., 2., 1., 0.],\n",
              "         ...,\n",
              "         [2., 2., 2.,  ..., 0., 0., 1.],\n",
              "         [2., 1., 1.,  ..., 2., 2., 2.],\n",
              "         [1., 2., 1.,  ..., 2., 2., 0.]]), y=tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "         1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "         0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "         0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "         0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "         0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "         1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "         1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "         0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "         1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "         1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "         1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "         1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "         1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "         1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "         1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "         0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "         1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "         1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "         0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "         1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "         0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "         1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]), categorical_columns=[0, 1, 2, 3, 4, 5, 6, 7, 8], attribute_names=['top-left-square', 'top-middle-square', 'top-right-square', 'middle-left-square', 'middle-middle-square', 'middle-right-square', 'bottom-left-square', 'bottom-middle-square', 'bottom-right-square'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='vehicle', X=tensor([[ 92.,  41.,  66.,  ...,  19., 182., 184.],\n",
              "         [ 98.,  47., 109.,  ...,  33., 194., 208.],\n",
              "         [ 96.,  46.,  88.,  ...,  11., 192., 199.],\n",
              "         ...,\n",
              "         [ 89.,  42.,  89.,  ...,  23., 187., 199.],\n",
              "         [ 84.,  39.,  90.,  ...,  38., 190., 198.],\n",
              "         [ 97.,  45.,  91.,  ...,  20., 197., 205.]]), y=tensor([3, 1, 3, 1, 3, 2, 2, 3, 0, 3, 2, 3, 1, 3, 0, 2, 2, 1, 1, 0, 3, 1, 2, 2,\n",
              "         1, 3, 3, 2, 2, 0, 1, 0, 0, 0, 2, 1, 2, 0, 3, 2, 3, 2, 3, 2, 3, 2, 0, 3,\n",
              "         1, 3, 2, 1, 1, 1, 0, 0, 3, 0, 3, 3, 1, 2, 2, 1, 0, 3, 3, 3, 2, 2, 3, 3,\n",
              "         3, 3, 1, 1, 0, 3, 1, 0, 0, 1, 3, 3, 0, 1, 0, 3, 3, 3, 3, 2, 2, 2, 2, 2,\n",
              "         2, 1, 0, 0, 1, 2, 3, 3, 1, 0, 3, 2, 0, 2, 3, 3, 1, 2, 2, 1, 0, 1, 3, 3,\n",
              "         3, 2, 3, 2, 2, 2, 2, 0, 1, 0, 0, 0, 0, 2, 2, 1, 1, 2, 1, 0, 3, 3, 0, 2,\n",
              "         2, 1, 2, 0, 2, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 3, 0, 1,\n",
              "         0, 2, 1, 0, 1, 1, 1, 3, 0, 0, 1, 3, 1, 2, 1, 1, 1, 0, 0, 0, 2, 2, 3, 2,\n",
              "         0, 0, 1, 2, 1, 1, 1, 3, 2, 2, 2, 0, 3, 2, 0, 0, 2, 2, 3, 1, 3, 1, 3, 0,\n",
              "         2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2, 2, 0, 0, 2,\n",
              "         1, 0, 1, 0, 0, 3, 1, 2, 3, 0, 1, 2, 1, 1, 0, 2, 2, 2, 3, 0, 2, 2, 2, 2,\n",
              "         3, 0, 0, 3, 2, 0, 2, 2, 0, 1, 3, 0, 0, 3, 0, 2, 1, 2, 1, 2, 0, 0, 2, 0,\n",
              "         3, 3, 0, 0, 2, 2, 1, 1, 1, 3, 1, 0, 2, 0, 1, 3, 0, 1, 3, 1, 0, 1, 1, 0,\n",
              "         0, 0, 3, 2, 3, 1, 3, 2, 1, 0, 2, 0, 2, 0, 3, 1, 3, 3, 3, 3, 2, 1, 1, 3,\n",
              "         3, 2, 3, 0, 3, 0, 0, 2, 2, 2, 1, 0, 2, 2, 2, 3, 3, 3, 1, 2, 1, 3, 0, 1,\n",
              "         2, 0, 0, 3, 3, 1, 1, 0, 0, 1, 1, 0, 3, 2, 3, 0, 0, 2, 2, 2, 0, 0, 2, 1,\n",
              "         2, 2, 1, 0, 2, 2, 2, 3, 0, 1, 2, 3, 3, 1, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0,\n",
              "         2, 1, 0, 2, 2, 3, 0, 2, 3, 3, 2, 3, 1, 0, 2, 3, 2, 1, 3, 1, 3, 2, 3, 3,\n",
              "         1, 2, 1, 0, 2, 1, 1, 0, 2, 1, 3, 1, 3, 3, 0, 3, 1, 2, 1, 0, 2, 1, 0, 0,\n",
              "         2, 2, 2, 2, 2, 2, 3, 3, 2, 0, 2, 2, 1, 2, 2, 0, 1, 3, 1, 1, 2, 1, 0, 0,\n",
              "         2, 3, 3, 0, 3, 0, 3, 3, 3, 2, 1, 0, 3, 2, 0, 1, 3, 3, 1, 2, 0, 1, 1, 3,\n",
              "         3, 0, 2, 0, 2, 2, 1, 2, 1, 2, 3, 1, 3, 3, 0, 2, 3, 0, 0, 3, 3, 2, 3, 0,\n",
              "         2, 2, 0, 0, 3, 1, 3, 1, 2, 0, 1, 2, 0, 3, 3, 3, 1, 0, 2, 2, 1, 2, 1, 3,\n",
              "         3, 3, 1, 0, 3, 1, 1, 1, 0, 3, 3, 1, 1, 0, 0, 1, 2, 3, 3, 0, 2, 1, 3, 3,\n",
              "         1, 1, 2, 3, 0, 1, 0, 2, 1, 1, 1, 3, 0, 2, 0, 0, 0, 3, 3, 1, 1, 0, 1, 0,\n",
              "         3, 1, 1, 1, 1, 1, 1, 3, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 3, 3, 1, 2, 3, 1,\n",
              "         1, 2, 3, 0, 2, 1, 3, 0, 1, 3, 1, 1, 2, 2, 0, 1, 2, 2, 2, 1, 0, 3, 1, 0,\n",
              "         1, 2, 0, 0, 0, 1, 3, 0, 2, 2, 0, 1, 1, 3, 1, 2, 1, 2, 0, 0, 0, 3, 0, 1,\n",
              "         3, 0, 2, 3, 2, 0, 2, 3, 0, 2, 2, 2, 0, 3, 1, 3, 0, 1, 0, 3, 3, 0, 2, 2,\n",
              "         3, 3, 3, 1, 1, 3, 0, 3, 0, 2, 0, 1, 0, 1, 2, 2, 2, 0, 3, 2, 2, 1, 0, 0,\n",
              "         1, 1, 2, 1, 1, 2, 2, 0, 2, 0, 0, 0, 3, 0, 1, 3, 3, 2, 2, 0, 2, 3, 1, 3,\n",
              "         3, 0, 0, 2, 0, 1, 0, 0, 3, 3, 1, 0, 1, 3, 3, 0, 2, 1, 0, 1, 1, 2, 1, 2,\n",
              "         3, 3, 3, 0, 0, 3, 3, 3, 2, 1, 1, 2, 0, 2, 3, 1, 2, 1, 3, 0, 1, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 3, 3, 0, 3, 1, 1, 1, 2, 2, 0, 2, 1, 0, 3, 1, 2, 1,\n",
              "         0, 3, 2, 2, 1, 2, 0, 3, 3, 0, 3, 3, 3, 3, 0, 2, 1, 0, 1, 0, 2, 3, 3, 1,\n",
              "         1, 0, 2, 3, 0, 3]), categorical_columns=[], attribute_names=['COMPACTNESS', 'CIRCULARITY', 'DISTANCE_CIRCULARITY', 'RADIUS_RATIO', 'PR.AXIS_ASPECT_RATIO', 'MAX.LENGTH_ASPECT_RATIO', 'SCATTER_RATIO', 'ELONGATEDNESS', 'PR.AXIS_RECTANGULARITY', 'MAX.LENGTH_RECTANGULARITY', 'SCALED_VARIANCE_MAJOR', 'SCALED_VARIANCE_MINOR', 'SCALED_RADIUS_OF_GYRATION', 'SKEWNESS_ABOUT_MAJOR', 'SKEWNESS_ABOUT_MINOR', 'KURTOSIS_ABOUT_MAJOR', 'KURTOSIS_ABOUT_MINOR', 'HOLLOWS_RATIO'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='eucalyptus', X=tensor([[ 3.0000,  2.0000,  3.0000,  ...,  4.0000,  4.5000,  4.0000],\n",
              "         [13.0000,  3.0000,  0.0000,  ...,     nan,     nan,     nan],\n",
              "         [ 6.0000,  2.0000,  4.0000,  ...,  3.3000,  3.3000,  3.3000],\n",
              "         ...,\n",
              "         [ 2.0000,  3.0000,  2.0000,  ...,  4.0000,  4.0000,  3.0000],\n",
              "         [ 4.0000,  2.0000,  4.0000,  ...,  3.5000,  4.5000,  4.0000],\n",
              "         [ 7.0000,  1.0000,  2.0000,  ...,  2.5000,  2.5000,  2.0000]]), y=tensor([0, 0, 1, 1, 0, 3, 0, 3, 0, 3, 0, 3, 3, 3, 4, 0, 0, 3, 4, 2, 2, 4, 2, 2,\n",
              "         3, 1, 4, 0, 0, 2, 1, 0, 0, 0, 3, 1, 3, 3, 3, 0, 4, 2, 3, 3, 1, 2, 0, 1,\n",
              "         3, 2, 4, 3, 4, 4, 1, 0, 4, 1, 2, 3, 2, 1, 2, 1, 4, 2, 0, 3, 0, 4, 0, 3,\n",
              "         1, 3, 4, 3, 0, 4, 4, 0, 1, 3, 2, 3, 0, 3, 0, 1, 1, 0, 1, 0, 3, 0, 1, 0,\n",
              "         3, 2, 0, 2, 1, 3, 4, 3, 1, 0, 2, 1, 3, 2, 3, 3, 2, 3, 1, 3, 0, 3, 2, 3,\n",
              "         1, 0, 0, 0, 3, 3, 3, 2, 0, 4, 0, 4, 3, 3, 4, 2, 0, 4, 0, 1, 1, 3, 3, 2,\n",
              "         0, 2, 3, 3, 3, 3, 3, 4, 4, 1, 3, 4, 3, 3, 0, 0, 3, 0, 0, 4, 3, 1, 1, 3,\n",
              "         3, 3, 4, 0, 3, 4, 3, 0, 4, 2, 1, 2, 4, 3, 3, 1, 4, 2, 2, 3, 3, 2, 3, 3,\n",
              "         3, 2, 2, 0, 1, 1, 0, 2, 3, 1, 4, 4, 3, 0, 1, 3, 4, 1, 3, 3, 0, 2, 3, 2,\n",
              "         3, 4, 2, 3, 0, 0, 1, 4, 0, 2, 0, 2, 3, 1, 3, 1, 3, 2, 3, 0, 2, 2, 3, 1,\n",
              "         1, 2, 3, 3, 2, 4, 2, 0, 4, 1, 1, 4, 1, 3, 3, 1, 0, 3, 4, 0, 3, 0, 0, 0,\n",
              "         3, 2, 3, 0, 3, 3, 0, 0, 2, 0, 0, 4, 2, 2, 1, 2, 0, 3, 1, 2, 1, 1, 1, 3,\n",
              "         0, 0, 1, 2, 0, 2, 3, 0, 3, 3, 1, 0, 0, 0, 0, 1, 4, 2, 1, 1, 3, 4, 3, 3,\n",
              "         4, 2, 4, 4, 3, 0, 0, 0, 4, 0, 2, 3, 0, 2, 0, 0, 2, 0, 3, 0, 1, 0, 3, 0,\n",
              "         0, 3, 3, 4, 2, 4, 1, 1, 3, 0, 3, 1, 0, 4, 3, 3, 0, 0, 3, 1, 3, 4, 2, 0,\n",
              "         3, 4, 3, 1, 1, 1, 0, 1, 4, 0, 0, 4, 0, 3, 3, 0, 1, 2, 0, 1, 3, 0, 3, 0,\n",
              "         0, 2, 2, 0, 2, 4, 4, 2, 1, 3, 2, 2, 3, 2, 4, 3, 1, 1, 3, 2, 3, 4, 0, 1,\n",
              "         4, 4, 1, 0, 3, 0, 2, 3, 0, 3, 4, 4, 0, 0, 2, 4, 2, 2, 0, 3, 2, 0, 3, 2,\n",
              "         4, 3, 3, 2, 4, 4, 3, 3, 3, 2, 2, 2, 3, 1, 0, 0, 0, 4, 0, 0, 4, 0, 4, 3,\n",
              "         3, 0, 0, 3, 0, 0, 3, 1, 1, 4, 3, 0, 0, 3, 0, 1, 1, 4, 2, 3, 3, 3, 0, 0,\n",
              "         3, 3, 1, 2, 2, 4, 2, 2, 1, 2, 2, 2, 3, 0, 2, 3, 2, 3, 3, 3, 2, 4, 3, 2,\n",
              "         2, 1, 3, 3, 2, 4, 3, 3, 4, 3, 3, 4, 2, 0, 0, 3, 0, 2, 3, 3, 3, 0, 0, 4,\n",
              "         3, 1, 4, 3, 0, 4, 0, 3, 2, 0, 4, 3, 2, 3, 0, 0, 1, 4, 3, 0, 2, 2, 4, 3,\n",
              "         0, 0, 3, 3, 1, 4, 0, 3, 0, 1, 0, 4, 3, 1, 2, 4, 3, 3, 3, 1, 3, 1, 3, 3,\n",
              "         0, 4, 0, 0, 3, 3, 4, 3, 2, 3, 2, 2, 3, 1, 0, 0, 2, 1, 0, 1, 3, 0, 4, 0,\n",
              "         2, 0, 1, 2, 3, 2, 0, 4, 3, 3, 0, 4, 3, 1, 0, 2, 3, 0, 1, 0, 2, 2, 3, 3,\n",
              "         4, 3, 3, 2, 0, 4, 4, 2, 0, 0, 2, 1, 0, 3, 2, 2, 3, 1, 2, 4, 3, 0, 2, 2,\n",
              "         2, 1, 4, 0, 2, 3, 2, 4, 3, 1, 0, 2, 4, 1, 3, 3, 2, 4, 3, 0, 0, 0, 4, 1,\n",
              "         0, 0, 4, 3, 0, 4, 3, 0, 3, 0, 3, 2, 4, 3, 2, 2, 3, 0, 2, 1, 0, 0, 0, 1,\n",
              "         1, 1, 1, 4, 0, 2, 1, 2, 0, 0, 4, 2, 2, 2, 3, 0, 1, 0, 1, 3, 3, 1, 3, 4,\n",
              "         0, 3, 4, 2, 1, 3, 3, 3, 4, 1, 0, 4, 3, 3, 3, 3]), categorical_columns=[0, 2, 3, 4, 9], attribute_names=['Abbrev', 'Rep', 'Locality', 'Map_Ref', 'Latitude', 'Altitude', 'Rainfall', 'Frosts', 'Year', 'Sp', 'PMCno', 'DBH', 'Ht', 'Surv', 'Vig', 'Ins_res', 'Stem_Fm', 'Crown_Fm', 'Brnch_Fm'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='analcatdata_authorship', X=tensor([[22., 11.,  0.,  ..., 13.,  6.,  4.],\n",
              "         [28.,  8.,  0.,  ..., 10.,  5.,  4.],\n",
              "         [26.,  7.,  0.,  ..., 15.,  8.,  6.],\n",
              "         ...,\n",
              "         [18.,  8.,  0.,  ...,  4.,  1.,  4.],\n",
              "         [25., 13.,  1.,  ..., 10.,  3.,  6.],\n",
              "         [28., 13.,  3.,  ...,  3.,  3.,  1.]]), y=tensor([0, 0, 0, 0, 1, 2, 3, 1, 3, 0, 1, 1, 1, 2, 3, 1, 3, 1, 1, 1, 0, 0, 0, 1,\n",
              "         0, 1, 1, 1, 0, 2, 2, 1, 1, 0, 0, 0, 1, 0, 1, 3, 3, 0, 3, 0, 0, 0, 0, 0,\n",
              "         0, 3, 1, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 3, 1, 1, 1, 0, 0,\n",
              "         1, 3, 1, 3, 3, 0, 1, 0, 0, 1, 0, 3, 0, 2, 1, 1, 3, 3, 1, 3, 0, 0, 1, 0,\n",
              "         3, 0, 0, 0, 1, 0, 3, 1, 2, 1, 0, 0, 1, 3, 3, 3, 0, 1, 0, 0, 0, 3, 1, 3,\n",
              "         0, 3, 0, 1, 1, 0, 0, 1, 3, 3, 1, 1, 0, 0, 0, 1, 1, 0, 3, 0, 1, 3, 1, 3,\n",
              "         1, 2, 0, 1, 3, 1, 0, 3, 1, 1, 0, 0, 0, 2, 3, 0, 3, 0, 1, 0, 3, 1, 1, 0,\n",
              "         2, 1, 0, 0, 2, 3, 2, 2, 0, 3, 1, 0, 1, 1, 3, 0, 0, 1, 3, 0, 2, 0, 1, 1,\n",
              "         3, 1, 0, 3, 0, 0, 3, 0, 3, 0, 1, 2, 0, 3, 1, 3, 3, 0, 1, 0, 1, 3, 3, 1,\n",
              "         1, 0, 3, 0, 1, 0, 0, 0, 0, 3, 3, 0, 1, 0, 0, 0, 0, 3, 0, 1, 1, 0, 1, 1,\n",
              "         2, 3, 0, 3, 0, 2, 0, 1, 0, 3, 0, 1, 0, 1, 3, 1, 1, 3, 1, 1, 0, 1, 2, 0,\n",
              "         0, 3, 1, 0, 0, 1, 3, 0, 1, 0, 1, 0, 3, 1, 0, 3, 0, 3, 1, 0, 1, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 3, 0, 1, 0, 1, 3, 0, 0, 1, 1, 1, 1, 3, 3, 3, 1, 0,\n",
              "         0, 0, 1, 0, 0, 3, 1, 0, 0, 1, 2, 0, 3, 0, 0, 1, 1, 1, 3, 3, 1, 0, 0, 3,\n",
              "         1, 0, 1, 1, 1, 0, 3, 0, 1, 1, 1, 0, 1, 0, 1, 1, 3, 2, 0, 1, 0, 3, 0, 1,\n",
              "         1, 0, 1, 0, 2, 0, 0, 2, 1, 0, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 3, 0, 1, 0,\n",
              "         0, 1, 3, 0, 3, 3, 3, 3, 1, 0, 0, 1, 0, 0, 2, 3, 3, 1, 0, 0, 0, 0, 0, 3,\n",
              "         3, 0, 0, 3, 1, 3, 2, 0, 0, 1, 0, 3, 3, 0, 1, 0, 0, 0, 1, 3, 0, 0, 1, 1,\n",
              "         0, 2, 0, 3, 1, 1, 0, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 3, 2, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 3, 0, 3, 0, 3, 3, 1, 0, 3, 3, 3, 1, 1, 0, 1, 0, 1, 1,\n",
              "         0, 3, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 3, 2, 3, 0, 2, 3, 0, 1, 0, 2, 1,\n",
              "         1, 3, 1, 0, 1, 1, 3, 1, 0, 1, 3, 0, 0, 2, 3, 0, 3, 0, 3, 1, 2, 0, 1, 2,\n",
              "         3, 1, 1, 3, 1, 1, 1, 3, 3, 0, 0, 0, 1, 3, 0, 0, 3, 0, 1, 0, 0, 1, 1, 1,\n",
              "         0, 0, 3, 3, 0, 0, 0, 0, 2, 3, 1, 0, 1, 1, 0, 0, 0, 1, 1, 3, 1, 2, 1, 1,\n",
              "         3, 1, 1, 1, 3, 1, 0, 2, 0, 1, 0, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 3, 3,\n",
              "         1, 1, 0, 0, 1, 3, 0, 0, 0, 3, 2, 0, 1, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 1,\n",
              "         3, 1, 3, 1, 3, 1, 3, 0, 0, 0, 0, 1, 3, 0, 3, 1, 3, 0, 1, 3, 0, 1, 1, 1,\n",
              "         0, 0, 0, 2, 0, 3, 1, 0, 2, 1, 1, 1, 0, 0, 1, 2, 3, 3, 0, 2, 3, 1, 0, 3,\n",
              "         0, 0, 2, 1, 1, 0, 2, 3, 3, 0, 0, 0, 0, 1, 0, 3, 2, 3, 3, 1, 1, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 2, 3, 3, 0, 1, 0, 3, 1, 3, 0, 1, 0, 1, 1, 2, 3, 0, 1, 1,\n",
              "         0, 1, 1, 3, 0, 1, 1, 3, 3, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 3, 1, 1, 1, 1,\n",
              "         3, 1, 0, 3, 3, 1, 1, 0, 0, 3, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 3, 3, 2,\n",
              "         1, 0, 3, 0, 0, 3, 0, 0, 1, 1, 0, 3, 2, 3, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         0, 3, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 3, 0, 1, 1, 1, 1, 3, 3, 1, 0, 0, 0,\n",
              "         1, 0, 2, 0, 0, 1, 0, 1, 0, 0, 3, 3, 1, 0, 1, 2, 0, 3, 0, 3, 3, 1, 0, 0,\n",
              "         1]), categorical_columns=[], attribute_names=['a', 'all', 'also', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', 'do', 'down', 'even', 'every', 'for', 'from', 'had', 'has', 'have', 'her', 'his', 'if', 'in', 'into', 'is', 'it', 'its', 'may', 'more', 'must', 'my', 'no', 'not', 'now', 'of', 'on', 'one', 'only', 'or', 'our', 'should', 'so', 'some', 'such', 'than', 'that', 'the', 'their', 'then', 'there', 'things', 'this', 'to', 'up', 'upon', 'was', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'would', 'your', 'BookID'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='analcatdata_dmft', X=tensor([[1., 1., 0., 1.],\n",
              "         [3., 0., 1., 2.],\n",
              "         [0., 0., 0., 1.],\n",
              "         ...,\n",
              "         [4., 2., 1., 2.],\n",
              "         [0., 0., 0., 1.],\n",
              "         [0., 1., 0., 1.]]), y=tensor([0, 0, 0, 5, 2, 4, 5, 5, 1, 3, 2, 2, 0, 4, 0, 2, 4, 0, 3, 0, 3, 1, 5, 2,\n",
              "         1, 0, 2, 3, 2, 3, 4, 3, 3, 2, 4, 2, 2, 1, 0, 3, 0, 3, 0, 5, 4, 4, 1, 5,\n",
              "         4, 5, 1, 1, 3, 1, 4, 0, 1, 0, 2, 4, 4, 3, 3, 5, 4, 1, 5, 1, 1, 3, 5, 4,\n",
              "         5, 2, 0, 2, 4, 3, 3, 0, 0, 4, 4, 1, 5, 1, 2, 2, 2, 5, 4, 4, 5, 3, 5, 0,\n",
              "         0, 2, 3, 1, 2, 0, 1, 4, 0, 3, 3, 5, 4, 3, 5, 4, 1, 0, 0, 4, 3, 1, 0, 5,\n",
              "         4, 1, 3, 3, 4, 5, 3, 4, 3, 5, 1, 3, 2, 2, 1, 1, 0, 1, 4, 1, 1, 5, 1, 4,\n",
              "         0, 3, 5, 5, 1, 5, 2, 3, 0, 1, 0, 4, 0, 0, 4, 4, 4, 5, 3, 4, 3, 4, 3, 2,\n",
              "         1, 2, 4, 2, 4, 3, 2, 5, 5, 0, 4, 0, 3, 3, 5, 5, 3, 2, 0, 2, 2, 2, 0, 2,\n",
              "         4, 3, 2, 4, 2, 2, 2, 0, 4, 2, 1, 2, 4, 4, 3, 1, 2, 4, 2, 2, 3, 3, 2, 5,\n",
              "         0, 1, 4, 3, 3, 3, 4, 4, 3, 1, 1, 2, 4, 3, 1, 5, 2, 5, 4, 3, 4, 5, 1, 3,\n",
              "         3, 1, 5, 1, 1, 4, 3, 4, 0, 1, 2, 4, 4, 4, 1, 1, 1, 0, 3, 0, 5, 3, 0, 3,\n",
              "         3, 5, 3, 2, 0, 3, 0, 4, 4, 5, 0, 5, 0, 3, 3, 0, 0, 1, 1, 1, 1, 5, 1, 2,\n",
              "         2, 3, 2, 0, 3, 5, 1, 0, 5, 2, 3, 0, 4, 4, 1, 5, 5, 0, 0, 1, 3, 2, 5, 1,\n",
              "         2, 5, 0, 1, 4, 5, 0, 1, 0, 3, 1, 5, 1, 0, 3, 2, 4, 2, 3, 2, 0, 1, 0, 1,\n",
              "         3, 2, 2, 0, 0, 0, 2, 5, 0, 1, 0, 5, 0, 4, 4, 4, 4, 5, 2, 3, 1, 3, 3, 4,\n",
              "         0, 2, 4, 2, 0, 3, 5, 5, 3, 4, 0, 0, 0, 4, 3, 3, 2, 3, 5, 1, 5, 3, 4, 4,\n",
              "         4, 0, 3, 3, 4, 3, 4, 0, 2, 5, 0, 2, 3, 4, 0, 2, 5, 4, 4, 4, 1, 5, 3, 1,\n",
              "         3, 4, 0, 5, 4, 5, 2, 1, 4, 3, 4, 4, 0, 2, 3, 1, 2, 3, 5, 4, 2, 3, 5, 5,\n",
              "         3, 1, 2, 4, 4, 5, 5, 2, 5, 1, 2, 1, 1, 4, 0, 0, 0, 4, 4, 5, 1, 3, 2, 3,\n",
              "         5, 0, 2, 3, 5, 5, 5, 0, 1, 5, 4, 0, 1, 4, 2, 2, 5, 5, 0, 3, 5, 2, 2, 5,\n",
              "         5, 5, 1, 5, 4, 0, 1, 0, 3, 5, 3, 3, 3, 3, 1, 4, 3, 4, 4, 4, 1, 3, 3, 2,\n",
              "         3, 5, 2, 2, 2, 3, 4, 0, 3, 5, 2, 2, 3, 0, 1, 0, 0, 3, 4, 4, 2, 0, 5, 5,\n",
              "         2, 2, 4, 2, 3, 3, 0, 1, 1, 2, 2, 2, 4, 1, 5, 1, 3, 3, 3, 5, 1, 1, 3, 3,\n",
              "         2, 5, 2, 4, 2, 4, 0, 3, 0, 3, 3, 3, 4, 4, 1, 5, 5, 3, 0, 2, 1, 2, 2, 2,\n",
              "         5, 3, 0, 3, 0, 2, 1, 3, 3, 4, 4, 1, 5, 3, 5, 1, 3, 4, 5, 0, 2, 0, 2, 1,\n",
              "         5, 2, 3, 4, 2, 1, 5, 2, 1, 1, 1, 0, 0, 0, 3, 0, 3, 3, 2, 1, 1, 1, 0, 4,\n",
              "         3, 3, 5, 5, 0, 3, 3, 4, 4, 5, 2, 0, 4, 3, 4, 3, 5, 2, 2, 0, 4, 1, 0, 5,\n",
              "         3, 3, 5, 4, 3, 2, 3, 2, 3, 4, 2, 2, 2, 3, 5, 5, 2, 1, 0, 5, 3, 5, 4, 3,\n",
              "         0, 1, 3, 3, 2, 1, 4, 2, 3, 1, 5, 0, 1, 1, 5, 5, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "         1, 1, 5, 1, 1, 4, 1, 5, 1, 2, 5, 5, 1, 4, 2, 2, 5, 0, 0, 4, 4, 1, 3, 1,\n",
              "         2, 3, 1, 3, 5, 5, 3, 4, 4, 3, 2, 0, 5, 0, 0, 1, 3, 4, 3, 5, 0, 4, 4, 1,\n",
              "         0, 1, 1, 0, 1, 1, 0, 5, 4, 3, 4, 1, 3, 4, 3, 4, 0, 4, 5, 2, 1, 1, 1, 4,\n",
              "         5, 3, 4, 4, 2, 1, 4, 3, 2, 2, 1, 0, 1, 0, 0, 5, 3, 0, 1, 3, 0, 5, 0, 5,\n",
              "         5, 3, 2, 0, 4]), categorical_columns=[0, 1, 2, 3], attribute_names=['DMFT.Begin', 'DMFT.End', 'Gender', 'Ethnic'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='pc4', X=tensor([[ 2.0000,  7.0000,  0.0000,  ..., 10.0000,  0.0000,  5.0000],\n",
              "         [ 3.0000,  3.0000,  1.0000,  ..., 10.0000,  0.0000,  6.0000],\n",
              "         [ 1.0000,  3.0000,  0.0000,  ...,  7.0000,  0.0000,  4.0000],\n",
              "         ...,\n",
              "         [ 2.0000,  1.0000,  1.0000,  ...,  9.0000, 20.0000,  5.0000],\n",
              "         [ 3.0000,  1.0000,  1.0000,  ...,  9.0000,  0.0000,  4.0000],\n",
              "         [10.0000,  4.0000,  4.0000,  ..., 33.0000, 14.2900, 19.0000]]), y=tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64), categorical_columns=[], attribute_names=['LOC_BLANK', 'BRANCH_COUNT', 'CALL_PAIRS', 'LOC_CODE_AND_COMMENT', 'LOC_COMMENTS', 'CONDITION_COUNT', 'CYCLOMATIC_COMPLEXITY', 'CYCLOMATIC_DENSITY', 'DECISION_COUNT', 'DECISION_DENSITY', 'DESIGN_COMPLEXITY', 'DESIGN_DENSITY', 'EDGE_COUNT', 'ESSENTIAL_COMPLEXITY', 'ESSENTIAL_DENSITY', 'LOC_EXECUTABLE', 'PARAMETER_COUNT', 'HALSTEAD_CONTENT', 'HALSTEAD_DIFFICULTY', 'HALSTEAD_EFFORT', 'HALSTEAD_ERROR_EST', 'HALSTEAD_LENGTH', 'HALSTEAD_LEVEL', 'HALSTEAD_PROG_TIME', 'HALSTEAD_VOLUME', 'MAINTENANCE_SEVERITY', 'MODIFIED_CONDITION_COUNT', 'MULTIPLE_CONDITION_COUNT', 'NODE_COUNT', 'NORMALIZED_CYLOMATIC_COMPLEXITY', 'NUM_OPERANDS', 'NUM_OPERATORS', 'NUM_UNIQUE_OPERANDS', 'NUM_UNIQUE_OPERATORS', 'NUMBER_OF_LINES', 'PERCENT_COMMENTS', 'LOC_TOTAL'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='pc3', X=tensor([[  2.0000,  33.0000,   6.0000,  ...,  39.0000,   5.5600,  36.0000],\n",
              "         [  1.0000,   3.0000,   2.0000,  ...,  17.0000,   0.0000,  15.0000],\n",
              "         [  8.0000,   5.0000,   1.0000,  ...,  20.0000,  45.4500,   8.0000],\n",
              "         ...,\n",
              "         [ 22.0000,  13.0000,   7.0000,  ...,  66.0000,  23.2600,  43.0000],\n",
              "         [  1.0000,  41.0000,   8.0000,  ..., 106.0000,   4.8100, 103.0000],\n",
              "         [  1.0000,   9.0000,   3.0000,  ...,  13.0000,   0.0000,  11.0000]]), y=tensor([0., 0., 0.,  ..., 1., 0., 0.], dtype=torch.float64), categorical_columns=[], attribute_names=['LOC_BLANK', 'BRANCH_COUNT', 'CALL_PAIRS', 'LOC_CODE_AND_COMMENT', 'LOC_COMMENTS', 'CONDITION_COUNT', 'CYCLOMATIC_COMPLEXITY', 'CYCLOMATIC_DENSITY', 'DECISION_COUNT', 'DECISION_DENSITY', 'DESIGN_COMPLEXITY', 'DESIGN_DENSITY', 'EDGE_COUNT', 'ESSENTIAL_COMPLEXITY', 'ESSENTIAL_DENSITY', 'LOC_EXECUTABLE', 'PARAMETER_COUNT', 'HALSTEAD_CONTENT', 'HALSTEAD_DIFFICULTY', 'HALSTEAD_EFFORT', 'HALSTEAD_ERROR_EST', 'HALSTEAD_LENGTH', 'HALSTEAD_LEVEL', 'HALSTEAD_PROG_TIME', 'HALSTEAD_VOLUME', 'MAINTENANCE_SEVERITY', 'MODIFIED_CONDITION_COUNT', 'MULTIPLE_CONDITION_COUNT', 'NODE_COUNT', 'NORMALIZED_CYLOMATIC_COMPLEXITY', 'NUM_OPERANDS', 'NUM_OPERATORS', 'NUM_UNIQUE_OPERANDS', 'NUM_UNIQUE_OPERATORS', 'NUMBER_OF_LINES', 'PERCENT_COMMENTS', 'LOC_TOTAL'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='kc2', X=tensor([[10.,  2.,  1.,  ..., 11.,  7.,  3.],\n",
              "         [ 6.,  3.,  1.,  ..., 13., 11.,  5.],\n",
              "         [ 6.,  1.,  1.,  ...,  3.,  2.,  1.],\n",
              "         ...,\n",
              "         [15.,  1.,  1.,  ..., 34., 21.,  1.],\n",
              "         [ 7.,  1.,  1.,  ...,  6.,  5.,  1.],\n",
              "         [ 8.,  1.,  1.,  ...,  5.,  5.,  1.]]), y=tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "         1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]), categorical_columns=[], attribute_names=['loc', 'v(g)', 'ev(g)', 'iv(g)', 'n', 'v', 'l', 'd', 'i', 'e', 'b', 't', 'lOCode', 'lOComment', 'lOBlank', 'lOCodeAndComment', 'uniq_Op', 'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='pc1', X=tensor([[ 6.,  4.,  4.,  ..., 18.,  8.,  7.],\n",
              "         [15.,  1.,  1.,  ..., 45., 25.,  1.],\n",
              "         [32.,  7.,  6.,  ..., 96., 86., 13.],\n",
              "         ...,\n",
              "         [17.,  4.,  1.,  ..., 45., 34.,  7.],\n",
              "         [ 8.,  1.,  1.,  ..., 15., 10.,  1.],\n",
              "         [ 4.,  1.,  1.,  ...,  9.,  6.,  1.]]), y=tensor([0., 0., 0.,  ..., 1., 0., 0.], dtype=torch.float64), categorical_columns=[], attribute_names=['loc', 'v(g)', 'ev(g)', 'iv(G)', 'N', 'V', 'L', 'D', 'I', 'E', 'B', 'T', 'lOCode', 'lOComment', 'locCodeAndComment', 'lOBlank', 'uniq_Op', 'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='banknote-authentication', X=tensor([[ 4.6160, 10.1788, -4.2185, -4.4245],\n",
              "         [-1.1005, -7.2508,  6.0139,  0.3690],\n",
              "         [ 3.8384,  6.1851, -2.0439, -0.0332],\n",
              "         ...,\n",
              "         [ 4.4069, 10.9072, -4.5775, -4.4271],\n",
              "         [ 0.1908,  9.1297, -3.7250, -5.8224],\n",
              "         [ 0.9641,  5.6160,  2.2138, -0.1250]]), y=tensor([0, 1, 0,  ..., 0, 0, 0]), categorical_columns=[], attribute_names=['V1', 'V2', 'V3', 'V4'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='blood-transfusion-service-center', X=tensor([[1.8000e+01, 2.0000e+00, 5.0000e+02, 2.3000e+01],\n",
              "         [3.0000e+00, 1.6000e+01, 4.0000e+03, 7.4000e+01],\n",
              "         [2.0000e+00, 2.0000e+00, 5.0000e+02, 1.1000e+01],\n",
              "         ...,\n",
              "         [2.0000e+00, 2.0000e+00, 5.0000e+02, 4.0000e+00],\n",
              "         [1.1000e+01, 4.0000e+00, 1.0000e+03, 1.6000e+01],\n",
              "         [1.1000e+01, 1.0000e+00, 2.5000e+02, 1.1000e+01]]), y=tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "         0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "         0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 1, 1, 1]), categorical_columns=[], attribute_names=['V1', 'V2', 'V3', 'V4'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='ilpd', X=tensor([[66.0000,  1.0000,  1.0000,  ...,  5.3000,  2.1000,  0.6000],\n",
              "         [41.0000,  1.0000,  0.9000,  ...,  6.1000,  3.0000,  0.9000],\n",
              "         [69.0000,  1.0000,  0.9000,  ...,  6.9000,  3.0000,  0.7000],\n",
              "         ...,\n",
              "         [68.0000,  1.0000,  0.7000,  ...,  5.8000,  2.9000,  1.0000],\n",
              "         [55.0000,  1.0000,  0.8000,  ...,  5.7000,  2.6000,  0.8000],\n",
              "         [75.0000,  1.0000,  1.8000,  ...,  6.1000,  2.9000,  0.9000]]), y=tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "         0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "         1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0]), categorical_columns=[1], attribute_names=['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='qsar-biodeg', X=tensor([[ 4.0000,  2.3041,  0.0000,  ...,  7.8870,  0.0000,  0.0000],\n",
              "         [ 4.8420,  3.1241,  0.0000,  ...,  8.5290,  0.0000,  0.0000],\n",
              "         [ 6.3160,  7.7233,  0.0000,  ...,  9.6730,  0.0000, 23.0000],\n",
              "         ...,\n",
              "         [ 5.3130,  3.4571,  1.0000,  ...,  9.5130,  0.0000,  0.0000],\n",
              "         [ 4.7890,  2.8739,  0.0000,  ...,  8.1210,  0.0000,  0.0000],\n",
              "         [ 4.6420,  3.1871,  0.0000,  ...,  8.0420,  0.0000,  0.0000]]), y=tensor([0, 1, 0,  ..., 1, 1, 0]), categorical_columns=[], attribute_names=['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='wdbc', X=tensor([[1.3860e+01, 1.6930e+01, 9.0960e+01,  ..., 1.6540e-01, 3.6300e-01,\n",
              "          1.0590e-01],\n",
              "         [1.2860e+01, 1.3320e+01, 8.2820e+01,  ..., 1.1550e-01, 2.3820e-01,\n",
              "          8.5530e-02],\n",
              "         [1.1160e+01, 2.1410e+01, 7.0950e+01,  ..., 4.3060e-02, 2.9760e-01,\n",
              "          7.1230e-02],\n",
              "         ...,\n",
              "         [1.2310e+01, 1.6520e+01, 7.9190e+01,  ..., 8.6600e-02, 2.6180e-01,\n",
              "          7.6090e-02],\n",
              "         [9.9040e+00, 1.8060e+01, 6.4600e+01,  ..., 9.9100e-02, 2.6140e-01,\n",
              "          1.1620e-01],\n",
              "         [1.0050e+01, 1.7530e+01, 6.4410e+01,  ..., 6.4990e-02, 2.8940e-01,\n",
              "          7.6640e-02]]), y=tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "         0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "         0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "         0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "         0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "         1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "         1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "         0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]), categorical_columns=[], attribute_names=['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='cylinder-bands', X=tensor([[4.7000e+01, 3.7365e+04, 1.0000e+00,  ..., 4.0000e+00, 1.0666e+02,\n",
              "          2.0000e+00],\n",
              "         [5.2000e+01, 4.7105e+04, 2.0000e+00,  ..., 4.0000e+00, 1.0330e+02,\n",
              "          2.0000e+00],\n",
              "         [5.5000e+01, 3.4092e+04, 2.0000e+00,  ..., 3.0000e+00, 1.0320e+02,\n",
              "          2.0000e+00],\n",
              "         ...,\n",
              "         [5.2000e+01, 4.7202e+04, 2.0000e+00,  ..., 4.0000e+00, 1.0967e+02,\n",
              "          2.0000e+00],\n",
              "         [5.2000e+01, 4.7103e+04, 2.0000e+00,  ..., 1.0000e+00, 9.6700e+01,\n",
              "          2.0000e+00],\n",
              "         [4.7000e+01, 3.6197e+04, 1.0000e+00,  ..., 4.0000e+00, 1.1430e+02,\n",
              "          2.0000e+00]]), y=tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "         0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "         1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "         0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "         0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "         1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "         0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "         0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "         1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "         1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "         0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "         1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0]), categorical_columns=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 20, 34, 36], attribute_names=['customer', 'job_number', 'grain_screened', 'ink_color', 'proof_on_ctd_ink', 'blade_mfg', 'cylinder_division', 'paper_type', 'ink_type', 'direct_steam', 'solvent_type', 'type_on_cylinder', 'press_type', 'press', 'unit_number', 'cylinder_size', 'paper_mill_location', 'plating_tank', 'proof_cut', 'viscosity', 'caliper', 'ink_temperature', 'humifity', 'roughness', 'blade_pressure', 'varnish_pct', 'press_speed', 'ink_pct', 'solvent_pct', 'ESA_Voltage', 'ESA_Amperage', 'wax', 'hardener', 'roller_durometer', 'current_density', 'anode_space_ratio', 'chrome_content'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='dresses-sales', X=tensor([[10.0000,  4.0000,  4.6000,  ...,  2.0000, 19.0000,  0.0000],\n",
              "         [ 2.0000,  4.0000,  4.4000,  ...,     nan,     nan, 11.0000],\n",
              "         [ 1.0000,  0.0000,  4.3000,  ...,     nan,  2.0000, 11.0000],\n",
              "         ...,\n",
              "         [ 2.0000,  4.0000,  4.4000,  ...,     nan,     nan, 11.0000],\n",
              "         [ 3.0000,  3.0000,  5.0000,  ...,  2.0000, 20.0000, 10.0000],\n",
              "         [12.0000,  0.0000,  4.9000,  ...,  1.0000, 19.0000, 11.0000]]), y=tensor([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "         1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "         0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "         1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]), categorical_columns=[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], attribute_names=['V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='MiceProtein', X=tensor([[0.3401, 0.5388, 0.3042,  ..., 0.1857,    nan, 1.2604],\n",
              "         [0.2100, 0.4336, 0.2979,  ..., 0.1907, 0.2399, 1.4006],\n",
              "         [0.6392, 0.8433, 0.3448,  ..., 0.1305, 0.1510, 1.5374],\n",
              "         ...,\n",
              "         [0.3414, 0.4723, 0.3213,  ...,    nan,    nan, 1.3745],\n",
              "         [0.2656, 0.4030, 0.3216,  ..., 0.2879, 0.2827, 0.9837],\n",
              "         [0.4088, 0.5340, 0.3170,  ...,    nan, 0.1834, 1.4216]]), y=tensor([6, 3, 0,  ..., 0, 2, 1]), categorical_columns=[], attribute_names=['DYRK1A_N', 'ITSN1_N', 'BDNF_N', 'NR1_N', 'NR2A_N', 'pAKT_N', 'pBRAF_N', 'pCAMKII_N', 'pCREB_N', 'pELK_N', 'pERK_N', 'pJNK_N', 'PKCA_N', 'pMEK_N', 'pNR1_N', 'pNR2A_N', 'pNR2B_N', 'pPKCAB_N', 'pRSK_N', 'AKT_N', 'BRAF_N', 'CAMKII_N', 'CREB_N', 'ELK_N', 'ERK_N', 'GSK3B_N', 'JNK_N', 'MEK_N', 'TRKA_N', 'RSK_N', 'APP_N', 'Bcatenin_N', 'SOD1_N', 'MTOR_N', 'P38_N', 'pMTOR_N', 'DSCR1_N', 'AMPKA_N', 'NR2B_N', 'pNUMB_N', 'RAPTOR_N', 'TIAM1_N', 'pP70S6_N', 'NUMB_N', 'P70S6_N', 'pGSK3B_N', 'pPKCG_N', 'CDK5_N', 'S6_N', 'ADARB1_N', 'AcetylH3K9_N', 'RRP1_N', 'BAX_N', 'ARC_N', 'ERBB4_N', 'nNOS_N', 'Tau_N', 'GFAP_N', 'GluR3_N', 'GluR4_N', 'IL1B_N', 'P3525_N', 'pCASP9_N', 'PSD95_N', 'SNCA_N', 'Ubiquitin_N', 'pGSK3B_Tyr216_N', 'SHH_N', 'BAD_N', 'BCL2_N', 'pS6_N', 'pCFOS_N', 'SYP_N', 'H3AcK18_N', 'EGR1_N', 'H3MeK4_N', 'CaNA_N'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='car', X=tensor([[0., 3., 1., 1., 1., 1.],\n",
              "         [2., 2., 3., 1., 2., 2.],\n",
              "         [2., 3., 0., 2., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 2., 2., 0., 2.],\n",
              "         [0., 1., 2., 1., 1., 2.],\n",
              "         [0., 3., 0., 1., 1., 2.]]), y=tensor([0, 3, 0,  ..., 0, 0, 1]), categorical_columns=[0, 1, 2, 3, 4, 5], attribute_names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='steel-plates-fault', X=tensor([[ 2.9300e+02,  3.1400e+02,  1.0443e+06,  ...,  2.5000e-01,\n",
              "           3.2800e-02,  8.7050e-01],\n",
              "         [ 1.4670e+03,  1.4820e+03,  1.1440e+06,  ...,  3.4780e-01,\n",
              "          -2.6270e-01,  5.7080e-01],\n",
              "         [ 7.3300e+02,  7.4500e+02,  3.9578e+06,  ...,  7.2090e-01,\n",
              "          -2.3670e-01,  8.0610e-01],\n",
              "         ...,\n",
              "         [ 6.2300e+02,  6.3100e+02,  3.0951e+05,  ...,  3.3330e-01,\n",
              "          -4.0300e-01,  2.0180e-01],\n",
              "         [ 1.6600e+02,  1.7400e+02,  3.0315e+05,  ...,  5.5560e-01,\n",
              "          -9.8000e-02,  2.5830e-01],\n",
              "         [ 1.1900e+03,  1.2010e+03,  9.0070e+03,  ...,  5.7690e-01,\n",
              "          -2.4020e-01,  4.7290e-01]]), y=tensor([0, 0, 4,  ..., 4, 6, 6]), categorical_columns=[], attribute_names=['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass'),\n",
              " Dataset(name='climate-model-simulation-crashes', X=tensor([[0.7512, 0.0552, 0.8761,  ..., 0.7781, 0.1441, 0.0132],\n",
              "         [0.2766, 0.1443, 0.8651,  ..., 0.4986, 0.9488, 0.6001],\n",
              "         [0.9495, 0.5305, 0.4653,  ..., 0.7166, 0.8197, 0.5079],\n",
              "         ...,\n",
              "         [0.2738, 0.6083, 0.1683,  ..., 0.1636, 0.8164, 0.7119],\n",
              "         [0.6266, 0.8163, 0.1618,  ..., 0.3911, 0.5673, 0.7266],\n",
              "         [0.9539, 0.3190, 0.1472,  ..., 0.7567, 0.2875, 0.4033]]), y=tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1]), categorical_columns=[], attribute_names=['vconst_corr', 'vconst_2', 'vconst_3', 'vconst_4', 'vconst_5', 'vconst_7', 'ah_corr', 'ah_bolus', 'slm_corr', 'efficiency_factor', 'tidal_mix_max', 'vertical_decay_scale', 'convect_corr', 'bckgrnd_vdc1', 'bckgrnd_vdc_ban', 'bckgrnd_vdc_eq', 'bckgrnd_vdc_psim', 'Prandtl'], info={'samples_capped': False, 'classes_capped': False, 'feats_capped': False}, task_type='multiclass')]"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_datasets = Dataset.fetch(\"cc_test\")\n",
        "test_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "if args.plot:\n",
        "    args.plot_directory.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    collections = {\n",
        "        \"All Datasets\": [d.name for d in all_datasets],\n",
        "        \"Categorical Datasets\": [d.name for d in all_datasets if d.categorical],\n",
        "        \"Numerical Datasets\": [d.name for d in all_datasets if d.numerical],\n",
        "        \"Mixed Datasets\": [d.name for d in all_datasets if d.mixed],\n",
        "        #\n",
        "        \"Validation Datasets\": [d.name for d in valid_datasets],\n",
        "        \"Categorical Validation Datasets\": [\n",
        "            d.name for d in valid_datasets if d.categorical\n",
        "        ],\n",
        "        \"Numerical Validation Datasets\": [\n",
        "            d.name for d in valid_datasets if d.numerical\n",
        "        ],\n",
        "        \"Mixed Validation Datasets\": [d.name for d in valid_datasets if d.mixed],\n",
        "        #\n",
        "        \"Test Datasets\": [d.name for d in test_datasets],\n",
        "        \"Categorical Test Datasets\": [\n",
        "            d.name for d in test_datasets if d.categorical\n",
        "        ],\n",
        "        \"Numerical Test Datasets\": [d.name for d in test_datasets if d.numerical],\n",
        "        \"Mixed Test Datasets\": [d.name for d in test_datasets if d.mixed],\n",
        "    }\n",
        "\n",
        "    for name, datasets in tqdm(collections.items(), \"Dataset Collections\"):\n",
        "        do_plot(\n",
        "            result=result.at(dataset=datasets),\n",
        "            title_prefix=f\"{name} ({len(datasets)})\",\n",
        "            fig_name=name.replace(\" \", \"_\").lower(),\n",
        "            path=args.plot_directory,\n",
        "            figsize=tuple(args.figsize),  # type: ignore\n",
        "            dpi=args.dpi,\n",
        "            extension=args.extension,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args.predefined_results_path.iterdir()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in args.predefined_results_path.iterdir():\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "global_results = {}\n",
        "overwrite=False\n",
        "\n",
        "from tabpfn.scripts import tabular_baselines as tb\n",
        "for method in METHODS.keys():\n",
        "    for max_time in [3600.0]:\n",
        "        for split_number in range(1, 6):\n",
        "            results_key = method+'_time_'+str(max_time)+tb.get_scoring_string(metric_used, usage='')+'_split_'+str(split_number)\n",
        "            global_results[results_key] = eval_method(test_datasets, 'multiclass', method, list(dids), 'test', \n",
        "                                                      eval_positions\n",
        "                                                      , fetch_only=True, \n",
        "                                                                                                                                    verbose=False, max_time=max_time,\n",
        "                                                                                                                                    metric_used=metric_used, split_number=split_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "from eval_utils import METHODS\n",
        "\n",
        "def get_len_d_names(method):\n",
        "    all_d_names = []\n",
        "    for path in glob.glob(f\"/work/dlclarge1/rkohli-results_tabpfn_180/results/tabular/multiclass/results_{method}_time_3600.0_roc_auc_*.npy\"):\n",
        "        all_d_names.append(path.split('.')[-2].split('_')[-4])\n",
        "    return len(all_d_names)\n",
        "\n",
        "for method in [\"transformer_gpu_N_1\", \"transformer_gpu_N_4\", \"transformer_gpu_N_8\", \"transformer_gpu_N_32\"]:\n",
        "    print(method, get_len_d_names(method))\n",
        "\n",
        "\n",
        "j = 0\n",
        "for file_name in os.listdir(\"/home/rkohli/TabPFN/multiclass\"):\n",
        "    if '3600.0r' in file_name:\n",
        "        j+=1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "o1DghTkraHxL",
        "LEKwmB9paRSy",
        "P1yWWRsHaySz",
        "zVGvNN4magua",
        "vo8L6DUDa-4t",
        "OGkHDZjfajUs"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tabpfn-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "eef0a540e3996571848058dd08d7595e96d7ee3adeb57778063358a991232103"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
